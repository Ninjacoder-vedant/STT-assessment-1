{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T16:39:52.261052Z",
     "iopub.status.busy": "2025-08-22T16:39:52.260782Z",
     "iopub.status.idle": "2025-08-22T16:39:52.264715Z",
     "shell.execute_reply": "2025-08-22T16:39:52.264015Z",
     "shell.execute_reply.started": "2025-08-22T16:39:52.261029Z"
    }
   },
   "source": [
    "## Install and import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T20:16:00.496658Z",
     "iopub.status.busy": "2025-09-03T20:16:00.496264Z",
     "iopub.status.idle": "2025-09-03T20:16:15.325925Z",
     "shell.execute_reply": "2025-09-03T20:16:15.325154Z",
     "shell.execute_reply.started": "2025-09-03T20:16:00.496636Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydriller\n",
      "  Downloading pydriller-2.8-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: gitpython in /usr/local/lib/python3.11/dist-packages (from pydriller) (3.1.44)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.11/dist-packages (from pydriller) (2025.2)\n",
      "Requirement already satisfied: types-pytz in /usr/local/lib/python3.11/dist-packages (from pydriller) (2025.2.0.20250516)\n",
      "Collecting lizard==1.17.10 (from pydriller)\n",
      "  Downloading lizard-1.17.10-py2.py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython->pydriller) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython->pydriller) (5.0.2)\n",
      "Downloading pydriller-2.8-py3-none-any.whl (36 kB)\n",
      "Downloading lizard-1.17.10-py2.py3-none-any.whl (66 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.0/66.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: lizard, pydriller\n",
      "Successfully installed lizard-1.17.10 pydriller-2.8\n"
     ]
    }
   ],
   "source": [
    "!pip install pydriller\n",
    "import pandas as pd\n",
    "from pydriller import Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T12:47:42.400539Z",
     "iopub.status.busy": "2025-09-06T12:47:42.400264Z",
     "iopub.status.idle": "2025-09-06T12:47:43.624761Z",
     "shell.execute_reply": "2025-09-06T12:47:43.623854Z",
     "shell.execute_reply.started": "2025-09-06T12:47:42.400519Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "analysis_df = pd.read_csv('/kaggle/input/stt-labs/final_analysis (1).csv')\n",
    "final_df = analysis_df.merge(rectified_df.drop(['Overall_diff','Unnamed: 0','Message','Filename'],axis=1),on='Hash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T12:48:18.184901Z",
     "iopub.status.busy": "2025-09-06T12:48:18.184338Z",
     "iopub.status.idle": "2025-09-06T12:48:21.132171Z",
     "shell.execute_reply": "2025-09-06T12:48:21.131627Z",
     "shell.execute_reply.started": "2025-09-06T12:48:18.184875Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "final_df.to_csv('Lab_2_analysis.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T12:54:02.954829Z",
     "iopub.status.busy": "2025-09-06T12:54:02.954555Z",
     "iopub.status.idle": "2025-09-06T12:55:14.520693Z",
     "shell.execute_reply": "2025-09-06T12:55:14.519965Z",
     "shell.execute_reply.started": "2025-09-06T12:54:02.954809Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert_score\n",
      "  Using cached bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.6.0+cu124)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.2.3)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from bert_score) (4.52.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bert_score) (1.26.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.11/dist-packages (from bert_score) (4.67.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from bert_score) (3.7.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from bert_score) (25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score) (2025.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->bert_score) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->bert_score) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->bert_score) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->bert_score) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->bert_score) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->bert_score) (2.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (4.14.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (2025.5.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.0.0->bert_score)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.0.0->bert_score)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.0.0->bert_score)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.0.0->bert_score)\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.0.0->bert_score)\n",
      "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.0.0->bert_score)\n",
      "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.0.0->bert_score)\n",
      "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.0.0->bert_score)\n",
      "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.0.0->bert_score)\n",
      "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.0.0->bert_score)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert_score) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (0.33.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (0.5.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (1.4.8)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (11.2.1)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (3.0.9)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (2025.6.15)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers>=3.0.0->bert_score) (1.1.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0.0->bert_score) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->bert_score) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->bert_score) (2022.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->bert_score) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->bert_score) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->bert_score) (2024.2.0)\n",
      "Using cached bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bert_score\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed bert_score-0.3.13 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
     ]
    }
   ],
   "source": [
    "!pip install bert_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T13:03:46.155595Z",
     "iopub.status.busy": "2025-09-06T13:03:46.155018Z",
     "iopub.status.idle": "2025-09-06T13:03:46.368667Z",
     "shell.execute_reply": "2025-09-06T13:03:46.367760Z",
     "shell.execute_reply.started": "2025-09-06T13:03:46.155568Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_36/2355735933.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def score_message_quality(model, tokenizer, diffs, messages):\n",
    "    scores = []\n",
    "    for diff, msg in zip(diffs, messages):\n",
    "        eval_prompt = f\"\"\"\n",
    "        You are evaluating commit messages.\n",
    "        Diff:\n",
    "        {diff}\n",
    "\n",
    "        Commit message:\n",
    "        {msg}\n",
    "\n",
    "        Does this commit message clearly and accurately describe the diff?\n",
    "        Give a single integer score from 1 (very poor) to 5 (excellent).\n",
    "        \"\"\"\n",
    "        inputs = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "        outputs = model.generate(**inputs, max_new_tokens=5)\n",
    "        score = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "        try:\n",
    "            score = int(score[0])  # parse first digit\n",
    "        except:\n",
    "            score = None\n",
    "        scores.append(score)\n",
    "    return scores\n",
    "score_message_quality()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T13:02:34.901208Z",
     "iopub.status.busy": "2025-09-06T13:02:34.900271Z",
     "iopub.status.idle": "2025-09-06T13:02:37.326212Z",
     "shell.execute_reply": "2025-09-06T13:02:37.325457Z",
     "shell.execute_reply.started": "2025-09-06T13:02:34.901183Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Developer Message F1: 0.4360831081867218\n",
      "Model Message F1: 0.4248778522014618\n"
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "diffs = [\n",
    "    \"\"\"def divide(a, b):\n",
    "    return a / b\"\"\"\n",
    "]\n",
    "\n",
    "# Developer's original\n",
    "dev_msgs = [\"fix divide function\"]\n",
    "\n",
    "# LLM-generated\n",
    "model_msgs = [\"Handle division by zero in divide function by returning None\"]\n",
    "\n",
    "# Use CodeBERT (12-layer model)\n",
    "# model_name = \"microsoft/codebert-base\"\n",
    "\n",
    "model_name = \"microsoft/graphcodebert-base\"\n",
    "\n",
    "P_dev, R_dev, F1_dev = score(\n",
    "    dev_msgs, diffs,\n",
    "    model_type=model_name,\n",
    "    num_layers=12,\n",
    "    rescale_with_baseline=False\n",
    ")\n",
    "\n",
    "P_model, R_model, F1_model = score(\n",
    "    model_msgs, diffs,\n",
    "    model_type=model_name,\n",
    "    num_layers=12,\n",
    "    rescale_with_baseline=False\n",
    ")\n",
    "\n",
    "print(\"Developer Message F1:\", F1_dev.mean().item())\n",
    "print(\"Model Message F1:\", F1_model.mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T13:06:34.221697Z",
     "iopub.status.busy": "2025-09-06T13:06:34.221422Z",
     "iopub.status.idle": "2025-09-06T13:07:48.516187Z",
     "shell.execute_reply": "2025-09-06T13:07:48.515474Z",
     "shell.execute_reply.started": "2025-09-06T13:06:34.221671Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (1.26.4)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (4.14.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2025.5.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=2.2->bitsandbytes)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=2.2->bitsandbytes)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=2.2->bitsandbytes)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=2.2->bitsandbytes)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=2.2->bitsandbytes)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=2.2->bitsandbytes)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.2->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2022.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->bitsandbytes) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->bitsandbytes) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\n",
      "Downloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl (61.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bitsandbytes\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed bitsandbytes-0.47.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
     ]
    }
   ],
   "source": [
    "!pip install -U bitsandbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T13:05:58.405184Z",
     "iopub.status.busy": "2025-09-06T13:05:58.404917Z",
     "iopub.status.idle": "2025-09-06T13:05:59.249420Z",
     "shell.execute_reply": "2025-09-06T13:05:59.248481Z",
     "shell.execute_reply.started": "2025-09-06T13:05:58.405162Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Using `bitsandbytes` 4-bit quantization requires the latest version of bitsandbytes: `pip install -U bitsandbytes`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_36/2156377709.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Load model in 4-bit (bnb) without unsloth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m model = AutoModelForCausalLM.from_pretrained(\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m,\u001b[0m        \u001b[0;31m# automatically places on GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_configs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text_config\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m                 \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    572\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             )\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mold_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4389\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhf_quantizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4390\u001b[0;31m             hf_quantizer.validate_environment(\n\u001b[0m\u001b[1;32m   4391\u001b[0m                 \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4392\u001b[0m                 \u001b[0mfrom_tf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrom_tf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/quantizers/quantizer_bnb_4bit.py\u001b[0m in \u001b[0;36mvalidate_environment\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m             )\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_bitsandbytes_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             raise ImportError(\n\u001b[0m\u001b[1;32m     77\u001b[0m                 \u001b[0;34m\"Using `bitsandbytes` 4-bit quantization requires the latest version of bitsandbytes: `pip install -U bitsandbytes`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             )\n",
      "\u001b[0;31mImportError\u001b[0m: Using `bitsandbytes` 4-bit quantization requires the latest version of bitsandbytes: `pip install -U bitsandbytes`"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model_name = \"unsloth/Qwen3-4B-Instruct-2507-unsloth-bnb-4bit\"\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Load model in 4-bit (bnb) without unsloth\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",        # automatically places on GPU\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# Quick test\n",
    "inputs = tokenizer(\"Hello, how are you?\", return_tensors=\"pt\").to(\"cuda\")\n",
    "outputs = model.generate(**inputs, max_new_tokens=50)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T08:48:36.047256Z",
     "iopub.status.busy": "2025-09-05T08:48:36.046983Z",
     "iopub.status.idle": "2025-09-05T08:48:36.194759Z",
     "shell.execute_reply": "2025-09-05T08:48:36.193509Z",
     "shell.execute_reply.started": "2025-09-05T08:48:36.047226Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "git version 2.34.1\n"
     ]
    }
   ],
   "source": [
    "!git --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Myers vs Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T18:23:56.401881Z",
     "iopub.status.busy": "2025-09-03T18:23:56.401317Z",
     "iopub.status.idle": "2025-09-03T18:28:38.223779Z",
     "shell.execute_reply": "2025-09-03T18:28:38.222766Z",
     "shell.execute_reply.started": "2025-09-03T18:23:56.401854Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing repository: datasets\n",
      "\n",
      "Analyzing repository: LLaMA-Factory\n",
      "\n",
      "Analyzing repository: quivr\n",
      "Consolidated dataset saved to output/consolidated_results.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pydriller import Repository\n",
    "import os\n",
    "\n",
    "def analyze_repos(repo_links, out_csv=\"consolidated_results.csv\"):\n",
    "    all_file_rows = []\n",
    "\n",
    "    for repo_link in repo_links:\n",
    "        repo_name = repo_link.split(\"/\")[-1]\n",
    "        print(f\"\\nAnalyzing repository: {repo_name}\")\n",
    "\n",
    "        # Collecting Myers diffs\n",
    "        file_rows = []\n",
    "        for commit in Repository(repo_link, only_no_merge = True).traverse_commits():\n",
    "            for mod in commit.modified_files:\n",
    "                file_rows.append({\n",
    "                    'Repository': repo_name,\n",
    "                    'Commit SHA': commit.hash,\n",
    "                    'Parent SHA': commit.parents,\n",
    "                    'Author': commit.author.name,\n",
    "                    'Commit Message': commit.msg,\n",
    "                    'Filename': mod.filename,\n",
    "                    'Old File Path': mod.old_path,\n",
    "                    'New File Path': mod.new_path,\n",
    "                    'Change Type': mod.change_type.name,\n",
    "                    'Diff_Myers': mod.diff\n",
    "                })\n",
    "\n",
    "\n",
    "        df_files = pd.DataFrame(file_rows)\n",
    "\n",
    "\n",
    "        # Collecting Histogram diffs\n",
    "        hist_diffs = []\n",
    "        for commit in Repository(repo_link, only_no_merge = True, histogram_diff=True).traverse_commits():\n",
    "            for mod in commit.modified_files:\n",
    "                hist_diffs.append(mod.diff)\n",
    "\n",
    "\n",
    "        df_files['Diff_Histogram'] = hist_diffs\n",
    "   \n",
    "        # Adding to consolidated results\n",
    "        all_file_rows.append(df_files)\n",
    "\n",
    "\n",
    "    # Concatenating all repos into one DataFrame\n",
    "    consolidated = pd.concat(all_file_rows, ignore_index=True)\n",
    "\n",
    "\n",
    "    # Saving CSV\n",
    "    os.makedirs(\"output\", exist_ok=True)\n",
    "    out_path = os.path.join(\"output\", out_csv)\n",
    "    consolidated.to_csv(out_path, index=False)\n",
    "\n",
    "\n",
    "    print(f\"Consolidated dataset saved to {out_path}\")\n",
    "    return consolidated\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    repos = [\n",
    "        \"https://github.com/huggingface/datasets\",\n",
    "        \"https://github.com/hiyouga/LLaMA-Factory\",\n",
    "        \"https://github.com/QuivrHQ/quivr\"\n",
    "    ]\n",
    "    consolidated_df = analyze_repos(repos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T18:28:44.445530Z",
     "iopub.status.busy": "2025-09-03T18:28:44.445181Z",
     "iopub.status.idle": "2025-09-03T18:28:44.544998Z",
     "shell.execute_reply": "2025-09-03T18:28:44.543415Z",
     "shell.execute_reply.started": "2025-09-03T18:28:44.445480Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "consolidated_df['Discrepancy'] = consolidated_df['Diff_Myers'] != consolidated_df['Diff_Histogram']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T18:28:48.051819Z",
     "iopub.status.busy": "2025-09-03T18:28:48.051482Z",
     "iopub.status.idle": "2025-09-03T18:28:48.106071Z",
     "shell.execute_reply": "2025-09-03T18:28:48.104969Z",
     "shell.execute_reply.started": "2025-09-03T18:28:48.051797Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Commit SHA</th>\n",
       "      <th>Parent SHA</th>\n",
       "      <th>Author</th>\n",
       "      <th>Commit Message</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Old File Path</th>\n",
       "      <th>New File Path</th>\n",
       "      <th>Diff_Myers</th>\n",
       "      <th>Diff_Histogram</th>\n",
       "      <th>Discrepancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27d9cbb35b71082a6f457d96b5967fe5e5594e72</td>\n",
       "      <td>[]</td>\n",
       "      <td>Thomas Wolf</td>\n",
       "      <td>Initial commit</td>\n",
       "      <td>.gitignore</td>\n",
       "      <td>None</td>\n",
       "      <td>.gitignore</td>\n",
       "      <td>@@ -0,0 +1,28 @@\\n+# Compiled python modules.\\...</td>\n",
       "      <td>@@ -0,0 +1,28 @@\\n+# Compiled python modules.\\...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27d9cbb35b71082a6f457d96b5967fe5e5594e72</td>\n",
       "      <td>[]</td>\n",
       "      <td>Thomas Wolf</td>\n",
       "      <td>Initial commit</td>\n",
       "      <td>AUTHORS</td>\n",
       "      <td>None</td>\n",
       "      <td>AUTHORS</td>\n",
       "      <td>@@ -0,0 +1,8 @@\\n+# This is the list of Huggin...</td>\n",
       "      <td>@@ -0,0 +1,8 @@\\n+# This is the list of Huggin...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27d9cbb35b71082a6f457d96b5967fe5e5594e72</td>\n",
       "      <td>[]</td>\n",
       "      <td>Thomas Wolf</td>\n",
       "      <td>Initial commit</td>\n",
       "      <td>CONTRIBUTING.md</td>\n",
       "      <td>None</td>\n",
       "      <td>CONTRIBUTING.md</td>\n",
       "      <td>@@ -0,0 +1,97 @@\\n+# How to Contribute\\n+\\n+Th...</td>\n",
       "      <td>@@ -0,0 +1,97 @@\\n+# How to Contribute\\n+\\n+Th...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27d9cbb35b71082a6f457d96b5967fe5e5594e72</td>\n",
       "      <td>[]</td>\n",
       "      <td>Thomas Wolf</td>\n",
       "      <td>Initial commit</td>\n",
       "      <td>LICENSE</td>\n",
       "      <td>None</td>\n",
       "      <td>LICENSE</td>\n",
       "      <td>@@ -0,0 +1,202 @@\\n+\\n+                       ...</td>\n",
       "      <td>@@ -0,0 +1,202 @@\\n+\\n+                       ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27d9cbb35b71082a6f457d96b5967fe5e5594e72</td>\n",
       "      <td>[]</td>\n",
       "      <td>Thomas Wolf</td>\n",
       "      <td>Initial commit</td>\n",
       "      <td>README.md</td>\n",
       "      <td>None</td>\n",
       "      <td>README.md</td>\n",
       "      <td>@@ -0,0 +1,268 @@\\n+# HuggingFace Datasets\\n+\\...</td>\n",
       "      <td>@@ -0,0 +1,268 @@\\n+# HuggingFace Datasets\\n+\\...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27d9cbb35b71082a6f457d96b5967fe5e5594e72</td>\n",
       "      <td>[]</td>\n",
       "      <td>Thomas Wolf</td>\n",
       "      <td>Initial commit</td>\n",
       "      <td>glue.py</td>\n",
       "      <td>None</td>\n",
       "      <td>datasets/glue.py</td>\n",
       "      <td>@@ -0,0 +1,592 @@\\n+# coding=utf-8\\n+# Copyrig...</td>\n",
       "      <td>@@ -0,0 +1,592 @@\\n+# coding=utf-8\\n+# Copyrig...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>27d9cbb35b71082a6f457d96b5967fe5e5594e72</td>\n",
       "      <td>[]</td>\n",
       "      <td>Thomas Wolf</td>\n",
       "      <td>Initial commit</td>\n",
       "      <td>aeslc.py</td>\n",
       "      <td>None</td>\n",
       "      <td>datasets/nlp/aeslc/aeslc.py</td>\n",
       "      <td>@@ -0,0 +1,119 @@\\n+# coding=utf-8\\n+# Copyrig...</td>\n",
       "      <td>@@ -0,0 +1,119 @@\\n+# coding=utf-8\\n+# Copyrig...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>27d9cbb35b71082a6f457d96b5967fe5e5594e72</td>\n",
       "      <td>[]</td>\n",
       "      <td>Thomas Wolf</td>\n",
       "      <td>Initial commit</td>\n",
       "      <td>amazon_us_reviews.py</td>\n",
       "      <td>None</td>\n",
       "      <td>datasets/nlp/amazon_us_reviews/amazon_us_revie...</td>\n",
       "      <td>@@ -0,0 +1,174 @@\\n+# coding=utf-8\\n+# Copyrig...</td>\n",
       "      <td>@@ -0,0 +1,174 @@\\n+# coding=utf-8\\n+# Copyrig...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>27d9cbb35b71082a6f457d96b5967fe5e5594e72</td>\n",
       "      <td>[]</td>\n",
       "      <td>Thomas Wolf</td>\n",
       "      <td>Initial commit</td>\n",
       "      <td>big_patent.py</td>\n",
       "      <td>None</td>\n",
       "      <td>datasets/nlp/big_patent/big_patent.py</td>\n",
       "      <td>@@ -0,0 +1,286 @@\\n+# coding=utf-8\\n+# Copyrig...</td>\n",
       "      <td>@@ -0,0 +1,286 @@\\n+# coding=utf-8\\n+# Copyrig...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>27d9cbb35b71082a6f457d96b5967fe5e5594e72</td>\n",
       "      <td>[]</td>\n",
       "      <td>Thomas Wolf</td>\n",
       "      <td>Initial commit</td>\n",
       "      <td>billsum.py</td>\n",
       "      <td>None</td>\n",
       "      <td>datasets/nlp/billsum/billsum.py</td>\n",
       "      <td>@@ -0,0 +1,121 @@\\n+# coding=utf-8\\n+# Copyrig...</td>\n",
       "      <td>@@ -0,0 +1,121 @@\\n+# coding=utf-8\\n+# Copyrig...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Commit SHA Parent SHA       Author  \\\n",
       "0  27d9cbb35b71082a6f457d96b5967fe5e5594e72         []  Thomas Wolf   \n",
       "1  27d9cbb35b71082a6f457d96b5967fe5e5594e72         []  Thomas Wolf   \n",
       "2  27d9cbb35b71082a6f457d96b5967fe5e5594e72         []  Thomas Wolf   \n",
       "3  27d9cbb35b71082a6f457d96b5967fe5e5594e72         []  Thomas Wolf   \n",
       "4  27d9cbb35b71082a6f457d96b5967fe5e5594e72         []  Thomas Wolf   \n",
       "5  27d9cbb35b71082a6f457d96b5967fe5e5594e72         []  Thomas Wolf   \n",
       "6  27d9cbb35b71082a6f457d96b5967fe5e5594e72         []  Thomas Wolf   \n",
       "7  27d9cbb35b71082a6f457d96b5967fe5e5594e72         []  Thomas Wolf   \n",
       "8  27d9cbb35b71082a6f457d96b5967fe5e5594e72         []  Thomas Wolf   \n",
       "9  27d9cbb35b71082a6f457d96b5967fe5e5594e72         []  Thomas Wolf   \n",
       "\n",
       "   Commit Message              Filename Old File Path  \\\n",
       "0  Initial commit            .gitignore          None   \n",
       "1  Initial commit               AUTHORS          None   \n",
       "2  Initial commit       CONTRIBUTING.md          None   \n",
       "3  Initial commit               LICENSE          None   \n",
       "4  Initial commit             README.md          None   \n",
       "5  Initial commit               glue.py          None   \n",
       "6  Initial commit              aeslc.py          None   \n",
       "7  Initial commit  amazon_us_reviews.py          None   \n",
       "8  Initial commit         big_patent.py          None   \n",
       "9  Initial commit            billsum.py          None   \n",
       "\n",
       "                                       New File Path  \\\n",
       "0                                         .gitignore   \n",
       "1                                            AUTHORS   \n",
       "2                                    CONTRIBUTING.md   \n",
       "3                                            LICENSE   \n",
       "4                                          README.md   \n",
       "5                                   datasets/glue.py   \n",
       "6                        datasets/nlp/aeslc/aeslc.py   \n",
       "7  datasets/nlp/amazon_us_reviews/amazon_us_revie...   \n",
       "8              datasets/nlp/big_patent/big_patent.py   \n",
       "9                    datasets/nlp/billsum/billsum.py   \n",
       "\n",
       "                                          Diff_Myers  \\\n",
       "0  @@ -0,0 +1,28 @@\\n+# Compiled python modules.\\...   \n",
       "1  @@ -0,0 +1,8 @@\\n+# This is the list of Huggin...   \n",
       "2  @@ -0,0 +1,97 @@\\n+# How to Contribute\\n+\\n+Th...   \n",
       "3  @@ -0,0 +1,202 @@\\n+\\n+                       ...   \n",
       "4  @@ -0,0 +1,268 @@\\n+# HuggingFace Datasets\\n+\\...   \n",
       "5  @@ -0,0 +1,592 @@\\n+# coding=utf-8\\n+# Copyrig...   \n",
       "6  @@ -0,0 +1,119 @@\\n+# coding=utf-8\\n+# Copyrig...   \n",
       "7  @@ -0,0 +1,174 @@\\n+# coding=utf-8\\n+# Copyrig...   \n",
       "8  @@ -0,0 +1,286 @@\\n+# coding=utf-8\\n+# Copyrig...   \n",
       "9  @@ -0,0 +1,121 @@\\n+# coding=utf-8\\n+# Copyrig...   \n",
       "\n",
       "                                      Diff_Histogram  Discrepancy  \n",
       "0  @@ -0,0 +1,28 @@\\n+# Compiled python modules.\\...        False  \n",
       "1  @@ -0,0 +1,8 @@\\n+# This is the list of Huggin...        False  \n",
       "2  @@ -0,0 +1,97 @@\\n+# How to Contribute\\n+\\n+Th...        False  \n",
       "3  @@ -0,0 +1,202 @@\\n+\\n+                       ...        False  \n",
       "4  @@ -0,0 +1,268 @@\\n+# HuggingFace Datasets\\n+\\...        False  \n",
       "5  @@ -0,0 +1,592 @@\\n+# coding=utf-8\\n+# Copyrig...        False  \n",
       "6  @@ -0,0 +1,119 @@\\n+# coding=utf-8\\n+# Copyrig...        False  \n",
       "7  @@ -0,0 +1,174 @@\\n+# coding=utf-8\\n+# Copyrig...        False  \n",
       "8  @@ -0,0 +1,286 @@\\n+# coding=utf-8\\n+# Copyrig...        False  \n",
       "9  @@ -0,0 +1,121 @@\\n+# coding=utf-8\\n+# Copyrig...        False  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consolidated_df.drop(columns=['Repository','Change Type']).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T18:28:53.268572Z",
     "iopub.status.busy": "2025-09-03T18:28:53.268222Z",
     "iopub.status.idle": "2025-09-03T18:28:53.332135Z",
     "shell.execute_reply": "2025-09-03T18:28:53.331231Z",
     "shell.execute_reply.started": "2025-09-03T18:28:53.268547Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Categorizing files\n",
    "def categorize_file(filename):\n",
    "    if pd.isna(filename):\n",
    "        return \"Other\"\n",
    "    fname = filename.lower()\n",
    "   \n",
    "    # README\n",
    "    if \"readme\" in fname:\n",
    "        return \"README\"\n",
    "   \n",
    "    # LICENSE\n",
    "    if \"license\" in fname:\n",
    "        return \"LICENSE\"\n",
    "   \n",
    "    # Test files\n",
    "    if \"test\" in fname:\n",
    "        return \"Test Code\"\n",
    "   \n",
    "    # Source code (The repository has only python language)\n",
    "    if fname.split(\".\")[-1]=='py':\n",
    "        return \"Source Code\"\n",
    "   \n",
    "    return \"Other\"\n",
    "consolidated_df[\"File_category\"] = consolidated_df[\"Filename\"].apply(categorize_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T18:28:55.711022Z",
     "iopub.status.busy": "2025-09-03T18:28:55.710700Z",
     "iopub.status.idle": "2025-09-03T18:28:55.727463Z",
     "shell.execute_reply": "2025-09-03T18:28:55.726433Z",
     "shell.execute_reply.started": "2025-09-03T18:28:55.710998Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@ -34,33 +34,23 @@ The main library entrypoints are:\n",
      " __version__ = \"0.0.1\"\n",
      " \n",
      " # Types are pyarrow types\n",
      "-from pyarrow import (null, bool_,\n",
      "-                     int8, int16, int32, int64,\n",
      "-                     uint8, uint16, uint32, uint64,\n",
      "-                     time32, time64, timestamp, date32, date64, duration,\n",
      "-                     float16, float32, float64,\n",
      "-                     binary, string, utf8,\n",
      "-                     large_binary, large_string, large_utf8,\n",
      "-                     decimal128,\n",
      "-                     list_, large_list, map_, struct, union, dictionary)\n",
      "-from pyarrow import total_allocated_bytes\n",
      "-\n",
      "-from . import download, features, load, datasets\n",
      "-from .load import builder, load\n",
      "-from .download import GenerateMode\n",
      "+from pyarrow import (binary, bool_, date32, date64, decimal128, dictionary,\n",
      "+                     duration, float16, float32, float64, int8, int16, int32,\n",
      "+                     int64, large_binary, large_list, large_string, large_utf8,\n",
      "+                     list_, map_, null, string, struct, time32, time64,\n",
      "+                     timestamp, total_allocated_bytes, uint8, uint16, uint32,\n",
      "+                     uint64, union, utf8)\n",
      "+\n",
      "+from . import datasets, download, features, load\n",
      " from .arrow_dataset import Dataset\n",
      "-from .splits import percent\n",
      "-from .splits import Split\n",
      "-from .utils.tqdm_utils import disable_progress_bar\n",
      "-\n",
      "-from .builder import BeamBasedBuilder, BuilderConfig, DatasetBuilder, GeneratorBasedBuilder\n",
      "-\n",
      "+from .arrow_reader import ReadInstruction\n",
      "+from .builder import (BeamBasedBuilder, BuilderConfig, DatasetBuilder,\n",
      "+                      GeneratorBasedBuilder)\n",
      "+from .download import GenerateMode\n",
      " from .info import DatasetInfo\n",
      "-\n",
      " from .lazy_imports_lib import lazy_imports\n",
      "-\n",
      "-from .splits import NamedSplit, SplitBase, SplitDict, SplitGenerator, SplitInfo, SubSplitInfo\n",
      "-\n",
      "-from .arrow_reader import ReadInstruction\n",
      "-\n",
      "+from .load import builder, load\n",
      "+from .splits import (NamedSplit, Split, SplitBase, SplitDict, SplitGenerator,\n",
      "+                     SplitInfo, SubSplitInfo, percent)\n",
      " from .utils import *\n",
      "+from .utils.tqdm_utils import disable_progress_bar\n",
      "\n",
      "@@ -34,33 +34,23 @@ The main library entrypoints are:\n",
      " __version__ = \"0.0.1\"\n",
      " \n",
      " # Types are pyarrow types\n",
      "-from pyarrow import (null, bool_,\n",
      "-                     int8, int16, int32, int64,\n",
      "-                     uint8, uint16, uint32, uint64,\n",
      "-                     time32, time64, timestamp, date32, date64, duration,\n",
      "-                     float16, float32, float64,\n",
      "-                     binary, string, utf8,\n",
      "-                     large_binary, large_string, large_utf8,\n",
      "-                     decimal128,\n",
      "-                     list_, large_list, map_, struct, union, dictionary)\n",
      "-from pyarrow import total_allocated_bytes\n",
      "+from pyarrow import (binary, bool_, date32, date64, decimal128, dictionary,\n",
      "+                     duration, float16, float32, float64, int8, int16, int32,\n",
      "+                     int64, large_binary, large_list, large_string, large_utf8,\n",
      "+                     list_, map_, null, string, struct, time32, time64,\n",
      "+                     timestamp, total_allocated_bytes, uint8, uint16, uint32,\n",
      "+                     uint64, union, utf8)\n",
      " \n",
      "-from . import download, features, load, datasets\n",
      "-from .load import builder, load\n",
      "-from .download import GenerateMode\n",
      "+from . import datasets, download, features, load\n",
      " from .arrow_dataset import Dataset\n",
      "-from .splits import percent\n",
      "-from .splits import Split\n",
      "-from .utils.tqdm_utils import disable_progress_bar\n",
      "-\n",
      "-from .builder import BeamBasedBuilder, BuilderConfig, DatasetBuilder, GeneratorBasedBuilder\n",
      "-\n",
      "-from .info import DatasetInfo\n",
      "-\n",
      "-from .lazy_imports_lib import lazy_imports\n",
      "-\n",
      "-from .splits import NamedSplit, SplitBase, SplitDict, SplitGenerator, SplitInfo, SubSplitInfo\n",
      "-\n",
      " from .arrow_reader import ReadInstruction\n",
      "-\n",
      "+from .builder import (BeamBasedBuilder, BuilderConfig, DatasetBuilder,\n",
      "+                      GeneratorBasedBuilder)\n",
      "+from .download import GenerateMode\n",
      "+from .info import DatasetInfo\n",
      "+from .lazy_imports_lib import lazy_imports\n",
      "+from .load import builder, load\n",
      "+from .splits import (NamedSplit, Split, SplitBase, SplitDict, SplitGenerator,\n",
      "+                     SplitInfo, SubSplitInfo, percent)\n",
      " from .utils import *\n",
      "+from .utils.tqdm_utils import disable_progress_bar\n",
      "\n"
     ]
    }
   ],
   "source": [
    "req_df = consolidated_df[(consolidated_df[\"File_category\"]=='Source Code')&(consolidated_df['Discrepancy'])]\n",
    "print(req_df['Diff_Myers'].iloc[0])\n",
    "print(req_df['Diff_Histogram'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T18:28:59.492549Z",
     "iopub.status.busy": "2025-09-03T18:28:59.492184Z",
     "iopub.status.idle": "2025-09-03T18:28:59.500161Z",
     "shell.execute_reply": "2025-09-03T18:28:59.499261Z",
     "shell.execute_reply.started": "2025-09-03T18:28:59.492514Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114, 151)\n",
      "(114, 151)\n"
     ]
    }
   ],
   "source": [
    "def count_diff_changes(diff_text):\n",
    "    added, deleted = 0, 0\n",
    "    for line in diff_text.splitlines():\n",
    "        if line.startswith('+') and not line.startswith('+++'):\n",
    "            added += 1\n",
    "        elif line.startswith('-') and not line.startswith('---'):\n",
    "            deleted += 1\n",
    "    return added, deleted\n",
    "print(count_diff_changes(req_df['Diff_Histogram'].iloc[1]))\n",
    "print(count_diff_changes(req_df['Diff_Myers'].iloc[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T18:30:07.461061Z",
     "iopub.status.busy": "2025-09-03T18:30:07.460731Z",
     "iopub.status.idle": "2025-09-03T18:30:08.139274Z",
     "shell.execute_reply": "2025-09-03T18:30:08.138531Z",
     "shell.execute_reply.started": "2025-09-03T18:30:07.461039Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mismatch Statistics:\n",
      "      Category  Mismatches\n",
      "0      LICENSE           0\n",
      "1        Other         334\n",
      "2       README          92\n",
      "3  Source Code         726\n",
      "4    Test Code          68\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stats = consolidated_df.groupby(\"File_category\")[\"Discrepancy\"].sum().reset_index()\n",
    "stats.columns = [\"Category\", \"Mismatches\"]\n",
    "\n",
    "# Saving stats to CSV\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "stats.to_csv(\"output/mismatch_stats.csv\", index=False)\n",
    "\n",
    "print(\"Mismatch Statistics:\")\n",
    "print(stats.head())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "\n",
    "colors = [\"#77DD77\",\"#64E8F9\", \"#FFB347\", \"#FF6961\",\n",
    "          \"#AEC6CF\", \"#FDFD96\", \"#CBAACB\"]\n",
    "stats_sorted = stats.sort_values(by=\"Mismatches\",ascending = False)\n",
    "\n",
    "# # Use light colors (from a colormap)\n",
    "# colors = cm.GnBu(np.linspace(0, 1, len(stats_sorted)))\n",
    "\n",
    "# --- Bar plot ---\n",
    "plt.figure(figsize=(8,6))\n",
    "bars = plt.bar(stats_sorted[\"Category\"], stats_sorted[\"Mismatches\"], color=colors)\n",
    "\n",
    "# Add count labels above each bar\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width()/2,   # X position (center of bar)\n",
    "        height,                            # Y position (top of bar)\n",
    "        f\"{int(height)}\",                  # Label (integer value)\n",
    "        ha=\"center\", va=\"bottom\", fontsize=10\n",
    "    )\n",
    "\n",
    "plt.title(\"Number of Mismatches by File Category\")\n",
    "plt.xlabel(\"File Category\")\n",
    "plt.ylabel(\"Number of Mismatches\")\n",
    "plt.xticks(rotation=30)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"output/mismatch_barplot.png\",transparent=True)\n",
    "plt.show()\n",
    "\n",
    "# --- Pie chart (remove 0%) ---\n",
    "nonzero_stats = stats_sorted[stats_sorted[\"Mismatches\"] > 0]\n",
    "# colors_pie = cm.GnBu(np.linspace(0, 1, len(nonzero_stats)))\n",
    "\n",
    "plt.figure(figsize=(5,5), facecolor='none')\n",
    "plt.pie(\n",
    "    nonzero_stats[\"Mismatches\"], \n",
    "    labels=nonzero_stats[\"Category\"], \n",
    "    autopct=\"%1.1f%%\", \n",
    "    startangle=90,\n",
    "    colors=colors\n",
    ")\n",
    "plt.title(\"Mismatch Distribution by File Category\")\n",
    "plt.savefig(\"output/mismatch_piechart.png\", transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T18:35:13.481844Z",
     "iopub.status.busy": "2025-09-03T18:35:13.481561Z",
     "iopub.status.idle": "2025-09-03T18:35:13.487917Z",
     "shell.execute_reply": "2025-09-03T18:35:13.486880Z",
     "shell.execute_reply.started": "2025-09-03T18:35:13.481825Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Modified files: 66099\n",
      "Total Mismatches: 1220\n",
      "Total Mismatch percent: 1.85%\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Modified files:\",len(consolidated_df))\n",
    "print(\"Total Mismatches:\",consolidated_df[\"Discrepancy\"].sum())\n",
    "print(f\"Total Mismatch percent: {round(consolidated_df['Discrepancy'].sum()/len(consolidated_df)*100,2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "stats = df.groupby(\"Category\")[\"Discrepancy\"].sum().reset_index()\n",
    "stats.columns = [\"Category\", \"Mismatches\"]\n",
    "\n",
    "# Saving stats to CSV\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "stats.to_csv(\"output/mismatch_stats.csv\", index=False)\n",
    "\n",
    "print(\"Mismatch Statistics:\")\n",
    "print(stats.head())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "\n",
    "colors = [\"#77DD77\",\"#64E8F9\", \"#FFB347\", \"#FF6961\",\n",
    "          \"#AEC6CF\", \"#FDFD96\", \"#CBAACB\"]\n",
    "stats_sorted = stats.sort_values(by=\"Mismatches\",ascending = False)\n",
    "\n",
    "# # Use light colors (from a colormap)\n",
    "# colors = cm.GnBu(np.linspace(0, 1, len(stats_sorted)))\n",
    "\n",
    "# --- Bar plot ---\n",
    "plt.figure(figsize=(8,6))\n",
    "bars = plt.bar(stats_sorted[\"Category\"], stats_sorted[\"Mismatches\"], color=colors)\n",
    "\n",
    "# Add count labels above each bar\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width()/2,   # X position (center of bar)\n",
    "        height,                            # Y position (top of bar)\n",
    "        f\"{int(height)}\",                  # Label (integer value)\n",
    "        ha=\"center\", va=\"bottom\", fontsize=10\n",
    "    )\n",
    "\n",
    "plt.title(\"Number of Mismatches by File Category\")\n",
    "plt.xlabel(\"File Category\")\n",
    "plt.ylabel(\"Number of Mismatches\")\n",
    "plt.xticks(rotation=30)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"output/mismatch_barplot.png\",transparent=True)\n",
    "plt.show()\n",
    "\n",
    "# --- Pie chart (remove 0%) ---\n",
    "nonzero_stats = stats_sorted[stats_sorted[\"Mismatches\"] > 0]\n",
    "# colors_pie = cm.GnBu(np.linspace(0, 1, len(nonzero_stats)))\n",
    "\n",
    "plt.figure(figsize=(5,5), facecolor='none')\n",
    "plt.pie(\n",
    "    nonzero_stats[\"Mismatches\"], \n",
    "    labels=nonzero_stats[\"Category\"], \n",
    "    autopct=\"%1.1f%%\", \n",
    "    startangle=90,\n",
    "    colors=colors\n",
    ")\n",
    "plt.title(\"Mismatch Distribution by File Category\")\n",
    "plt.savefig(\"output/mismatch_piechart.png\", transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T18:36:07.767739Z",
     "iopub.status.busy": "2025-09-05T18:36:07.767462Z",
     "iopub.status.idle": "2025-09-05T18:36:09.868075Z",
     "shell.execute_reply": "2025-09-05T18:36:09.866963Z",
     "shell.execute_reply.started": "2025-09-05T18:36:07.767710Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '/kaggle/working/unsloth'...\n",
      "remote: Enumerating objects: 14313, done.\u001b[K\n",
      "remote: Counting objects: 100% (773/773), done.\u001b[K\n",
      "remote: Compressing objects: 100% (230/230), done.\u001b[K\n",
      "remote: Total 14313 (delta 705), reused 543 (delta 543), pack-reused 13540 (from 5)\u001b[K\n",
      "Receiving objects: 100% (14313/14313), 7.71 MiB | 14.97 MiB/s, done.\n",
      "Resolving deltas: 100% (10718/10718), done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '/kaggle/working/unsloth'...\n",
      "remote: Enumerating objects: 14210, done.\u001b[K\n",
      "remote: Counting objects: 100% (695/695), done.\u001b[K\n",
      "remote: Compressing objects: 100% (193/193), done.\u001b[K\n",
      "remote: Total 14210 (delta 640), reused 502 (delta 502), pack-reused 13515 (from 3)\u001b[K\n",
      "Receiving objects: 100% (14210/14210), 7.64 MiB | 25.75 MiB/s, done.\n",
      "Resolving deltas: 100% (10649/10649), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com//unslothai/unsloth.git /kaggle/working/unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T18:36:11.083693Z",
     "iopub.status.busy": "2025-09-05T18:36:11.083282Z",
     "iopub.status.idle": "2025-09-05T18:36:16.397941Z",
     "shell.execute_reply": "2025-09-05T18:36:16.396868Z",
     "shell.execute_reply.started": "2025-09-05T18:36:11.083651Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydriller\n",
      "  Downloading pydriller-2.8-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: gitpython in /usr/local/lib/python3.11/dist-packages (from pydriller) (3.1.44)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.11/dist-packages (from pydriller) (2025.2)\n",
      "Requirement already satisfied: types-pytz in /usr/local/lib/python3.11/dist-packages (from pydriller) (2025.2.0.20250516)\n",
      "Collecting lizard==1.17.10 (from pydriller)\n",
      "  Downloading lizard-1.17.10-py2.py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython->pydriller) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython->pydriller) (5.0.2)\n",
      "Downloading pydriller-2.8-py3-none-any.whl (36 kB)\n",
      "Downloading lizard-1.17.10-py2.py3-none-any.whl (66 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.0/66.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: lizard, pydriller\n",
      "Successfully installed lizard-1.17.10 pydriller-2.8\n"
     ]
    }
   ],
   "source": [
    "!pip install pydriller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T18:37:51.610466Z",
     "iopub.status.busy": "2025-09-05T18:37:51.610149Z",
     "iopub.status.idle": "2025-09-05T18:37:51.615709Z",
     "shell.execute_reply": "2025-09-05T18:37:51.614805Z",
     "shell.execute_reply.started": "2025-09-05T18:37:51.610441Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Keywords used to identify bug-fix commits\n",
    "keywords = [\"fixed\", \"bug\", \"fixes\", \"fix\", \"crash\", \"solves\", \"resolves\", \"issue\", \"regression\", \"fall back\", \"assertion\", \"coverity\", \"reproducible\", \"stack-wanted\", \"steps-wanted\", \"testcase\", \"failur\", \"fail\", \"npe\", \"except\",\n",
    "\"broken\", \"differential testing\", \"error\", \"hang\", \"test fix\", \"steps to reproduce\", \"crash\", \"assertion\", \"failure\", \"leak\", \"stack trace\", \"heap overflow\", \"freez\", \"problem\", \"overflow\", \"avoid\", \"workaround\", \"break\", \"stop\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T18:38:26.652993Z",
     "iopub.status.busy": "2025-09-05T18:38:26.652715Z",
     "iopub.status.idle": "2025-09-05T18:38:37.891490Z",
     "shell.execute_reply": "2025-09-05T18:38:37.890452Z",
     "shell.execute_reply.started": "2025-09-05T18:38:26.652972Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from pydriller import Repository\n",
    "import pandas as pd\n",
    "bug_fix_df = []\n",
    "diff_analysis_df = []\n",
    "\n",
    "Repo_path = \"/kaggle/working/unsloth\"\n",
    "# Traversing commits using PyDriller\n",
    "for commit in Repository(Repo_path).traverse_commits():\n",
    "    for keyword in keywords:\n",
    "        if keyword in commit.msg:\n",
    "            bug_fix_df.append({\n",
    "                'Hash': commit.hash,\n",
    "                'Author': commit.author.name,\n",
    "                'Message': commit.msg,\n",
    "                'Hashes of parents': commit.parents,\n",
    "                'Is a merge commit?': len(commit.parents) > 1,\n",
    "                'List of modified files': [mod.filename for mod in commit.modified_files],\n",
    "            })\n",
    "\n",
    "            if commit.modified_files:  # normal case\n",
    "                for mod in commit.modified_files:\n",
    "                    diff_analysis_df.append({\n",
    "                        'Hash': commit.hash,\n",
    "                        'Author': commit.author.name,\n",
    "                        'Message': commit.msg,\n",
    "                        'Filename': mod.filename,\n",
    "                        'Change Type': mod.change_type.name,\n",
    "                        'Source Code (before)': mod.source_code_before,\n",
    "                        'Source Code (current)': mod.source_code,\n",
    "                        'Diff': mod.diff\n",
    "                    })\n",
    "            break\n",
    "# Create DataFrames\n",
    "bug_fix_df = pd.DataFrame(bug_fix_df)\n",
    "diff_analysis_df = pd.DataFrame(diff_analysis_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T18:38:40.317157Z",
     "iopub.status.busy": "2025-09-05T18:38:40.316716Z",
     "iopub.status.idle": "2025-09-05T18:38:40.357249Z",
     "shell.execute_reply": "2025-09-05T18:38:40.356322Z",
     "shell.execute_reply.started": "2025-09-05T18:38:40.317128Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hash</th>\n",
       "      <th>Author</th>\n",
       "      <th>Message</th>\n",
       "      <th>Hashes of parents</th>\n",
       "      <th>Is a merge commit?</th>\n",
       "      <th>List of modified files</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4b97a810b509c93f44be4c037c7aa18fb8922884</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Pre-release 2023 December version (Mistral, Pr...</td>\n",
       "      <td>[3aa16bb452ab82d7a2b2987ec3bfb47c6812582c]</td>\n",
       "      <td>False</td>\n",
       "      <td>[README.md, Discord.png, LAION 2GPU.png, LAION...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2d5d88487463e76f75002be3b2704267ec96e68a</td>\n",
       "      <td>Daniel Han-Chen</td>\n",
       "      <td>tokenizer pad fix</td>\n",
       "      <td>[28f3b971d21e469fb985f384db10a03982c4ce12]</td>\n",
       "      <td>False</td>\n",
       "      <td>[_utils.py, llama.py, mistral.py]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f380cc1170447800c112dc8568bdff3dd34c79a3</td>\n",
       "      <td>Daniel Han-Chen</td>\n",
       "      <td>Fix Mistral\\n\\nBlockDiagonalCausalMask fix cou...</td>\n",
       "      <td>[399f8ed56f40df0919208d1ffdee64a31a1b22c8]</td>\n",
       "      <td>False</td>\n",
       "      <td>[README.md, mistral.py]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>de855c2afa68ada67d8b3caad4eb9bb592bf4a4f</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Small fixes (#48)\\n\\n* Fix generation for GQA\\...</td>\n",
       "      <td>[725e581539a0755beb23aaff684608db4e42160a]</td>\n",
       "      <td>False</td>\n",
       "      <td>[README.md, unsloth made with love.png, unslot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51dd120e354cd2223df7ebe2240fb6d1a76108c5</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Fix RoPE Scaling issues (#52)\\n\\n* Fix RoPE Sc...</td>\n",
       "      <td>[627acc4bb37d5a0354a86c0783be20162f0940b2]</td>\n",
       "      <td>False</td>\n",
       "      <td>[llama.py, mistral.py]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>91b2a22548b99e034f89c2a76ca5b4eb59f41f76</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Update import_fixes.py</td>\n",
       "      <td>[a656a3df6e467556f19631e4b25da4b61b2a01fd]</td>\n",
       "      <td>False</td>\n",
       "      <td>[import_fixes.py]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>7ce3e3b2ce78bfa0074143b852eb9ab0decbafb7</td>\n",
       "      <td>Roland Tannous</td>\n",
       "      <td>fixed save_pretrained_torchao and associated t...</td>\n",
       "      <td>[91b2a22548b99e034f89c2a76ca5b4eb59f41f76]</td>\n",
       "      <td>False</td>\n",
       "      <td>[test_unsloth_save.py, mapper.py, save.py]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>978f73ed862ac1c10954cb27eb30e543f77d0421</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Bug fixes (#3266)\\n\\n* Fix mamba\\n\\n* Update l...</td>\n",
       "      <td>[cd71b1bb964098b0a2d8451eac48be53e08568b5]</td>\n",
       "      <td>False</td>\n",
       "      <td>[pyproject.toml, __init__.py, llama.py, mistra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>ff6cbb03d0c2d11fe15c844bfc635eb24f533243</td>\n",
       "      <td>DoubleMathew</td>\n",
       "      <td>llama vision inference fix (#3270)\\n\\n* llama ...</td>\n",
       "      <td>[c19a002a779ab08f207e0316013b16ea32885b3c]</td>\n",
       "      <td>False</td>\n",
       "      <td>[vision.py]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>551bc65235aaf4ce1d00b48fed79eb48d759507b</td>\n",
       "      <td>Roland Tannous</td>\n",
       "      <td>Add TorchAO quantization tests with FP16 model...</td>\n",
       "      <td>[ff6cbb03d0c2d11fe15c844bfc635eb24f533243]</td>\n",
       "      <td>False</td>\n",
       "      <td>[test_unsloth_save.py]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>369 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Hash           Author  \\\n",
       "0    4b97a810b509c93f44be4c037c7aa18fb8922884       Daniel Han   \n",
       "1    2d5d88487463e76f75002be3b2704267ec96e68a  Daniel Han-Chen   \n",
       "2    f380cc1170447800c112dc8568bdff3dd34c79a3  Daniel Han-Chen   \n",
       "3    de855c2afa68ada67d8b3caad4eb9bb592bf4a4f       Daniel Han   \n",
       "4    51dd120e354cd2223df7ebe2240fb6d1a76108c5       Daniel Han   \n",
       "..                                        ...              ...   \n",
       "364  91b2a22548b99e034f89c2a76ca5b4eb59f41f76       Daniel Han   \n",
       "365  7ce3e3b2ce78bfa0074143b852eb9ab0decbafb7   Roland Tannous   \n",
       "366  978f73ed862ac1c10954cb27eb30e543f77d0421       Daniel Han   \n",
       "367  ff6cbb03d0c2d11fe15c844bfc635eb24f533243     DoubleMathew   \n",
       "368  551bc65235aaf4ce1d00b48fed79eb48d759507b   Roland Tannous   \n",
       "\n",
       "                                               Message  \\\n",
       "0    Pre-release 2023 December version (Mistral, Pr...   \n",
       "1                                    tokenizer pad fix   \n",
       "2    Fix Mistral\\n\\nBlockDiagonalCausalMask fix cou...   \n",
       "3    Small fixes (#48)\\n\\n* Fix generation for GQA\\...   \n",
       "4    Fix RoPE Scaling issues (#52)\\n\\n* Fix RoPE Sc...   \n",
       "..                                                 ...   \n",
       "364                             Update import_fixes.py   \n",
       "365  fixed save_pretrained_torchao and associated t...   \n",
       "366  Bug fixes (#3266)\\n\\n* Fix mamba\\n\\n* Update l...   \n",
       "367  llama vision inference fix (#3270)\\n\\n* llama ...   \n",
       "368  Add TorchAO quantization tests with FP16 model...   \n",
       "\n",
       "                              Hashes of parents  Is a merge commit?  \\\n",
       "0    [3aa16bb452ab82d7a2b2987ec3bfb47c6812582c]               False   \n",
       "1    [28f3b971d21e469fb985f384db10a03982c4ce12]               False   \n",
       "2    [399f8ed56f40df0919208d1ffdee64a31a1b22c8]               False   \n",
       "3    [725e581539a0755beb23aaff684608db4e42160a]               False   \n",
       "4    [627acc4bb37d5a0354a86c0783be20162f0940b2]               False   \n",
       "..                                          ...                 ...   \n",
       "364  [a656a3df6e467556f19631e4b25da4b61b2a01fd]               False   \n",
       "365  [91b2a22548b99e034f89c2a76ca5b4eb59f41f76]               False   \n",
       "366  [cd71b1bb964098b0a2d8451eac48be53e08568b5]               False   \n",
       "367  [c19a002a779ab08f207e0316013b16ea32885b3c]               False   \n",
       "368  [ff6cbb03d0c2d11fe15c844bfc635eb24f533243]               False   \n",
       "\n",
       "                                List of modified files  \n",
       "0    [README.md, Discord.png, LAION 2GPU.png, LAION...  \n",
       "1                    [_utils.py, llama.py, mistral.py]  \n",
       "2                              [README.md, mistral.py]  \n",
       "3    [README.md, unsloth made with love.png, unslot...  \n",
       "4                               [llama.py, mistral.py]  \n",
       "..                                                 ...  \n",
       "364                                  [import_fixes.py]  \n",
       "365         [test_unsloth_save.py, mapper.py, save.py]  \n",
       "366  [pyproject.toml, __init__.py, llama.py, mistra...  \n",
       "367                                        [vision.py]  \n",
       "368                             [test_unsloth_save.py]  \n",
       "\n",
       "[369 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bug_fix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T19:02:28.108824Z",
     "iopub.status.busy": "2025-09-05T19:02:28.108465Z",
     "iopub.status.idle": "2025-09-05T19:02:28.132798Z",
     "shell.execute_reply": "2025-09-05T19:02:28.131375Z",
     "shell.execute_reply.started": "2025-09-05T19:02:28.108802Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hash</th>\n",
       "      <th>Author</th>\n",
       "      <th>Message</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Change Type</th>\n",
       "      <th>Source Code (before)</th>\n",
       "      <th>Source Code (current)</th>\n",
       "      <th>Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4b97a810b509c93f44be4c037c7aa18fb8922884</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Pre-release 2023 December version (Mistral, Pr...</td>\n",
       "      <td>README.md</td>\n",
       "      <td>MODIFY</td>\n",
       "      <td>&lt;div class=\"align-center\"&gt;\\n  &lt;img src=\"./imag...</td>\n",
       "      <td>&lt;div class=\"align-center\"&gt;\\n  &lt;img src=\"./imag...</td>\n",
       "      <td>@@ -1,23 +1,25 @@\\n &lt;div class=\"align-center\"&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4b97a810b509c93f44be4c037c7aa18fb8922884</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Pre-release 2023 December version (Mistral, Pr...</td>\n",
       "      <td>Discord.png</td>\n",
       "      <td>MODIFY</td>\n",
       "      <td>PNG\\r\\n\u001a\\n\u0000\u0000\u0000\\rIHDR\u0000\u0000\u0006\u0000\u0000\u0001\b\u0006\u0000\u0000\u0000\u000e\u0006\u0000\u0000\u0000\u0001sRGB\u0000\u001c\u0000\u0000\u0000\u0004...</td>\n",
       "      <td>PNG\\r\\n\u001a\\n\u0000\u0000\u0000\\rIHDR\u0000\u0000\u0003}\u0000\u0000\u0001\u0004\b\u0006\u0000\u0000\u00008]\u0000\u0000 \u0000IDATx\\t\u0014...</td>\n",
       "      <td>Binary files a/images/Discord.png and b/images...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4b97a810b509c93f44be4c037c7aa18fb8922884</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Pre-release 2023 December version (Mistral, Pr...</td>\n",
       "      <td>LAION 2GPU.png</td>\n",
       "      <td>ADD</td>\n",
       "      <td>None</td>\n",
       "      <td>PNG\\r\\n\u001a\\n\u0000\u0000\u0000\\rIHDR\u0000\u0000\u0003\u0000\u0000\u0002A\b\u0006\u0000\u0000\u0001\u0011\u0000\u0000ȫIDATx\u0001\u000b\\k]\\...</td>\n",
       "      <td>Binary files /dev/null and b/images/LAION 2GPU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4b97a810b509c93f44be4c037c7aa18fb8922884</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Pre-release 2023 December version (Mistral, Pr...</td>\n",
       "      <td>LAION 2GPU.svg</td>\n",
       "      <td>DELETE</td>\n",
       "      <td>&lt;?xml version=\"1.0\" encoding=\"utf-8\" standalon...</td>\n",
       "      <td>None</td>\n",
       "      <td>@@ -1,1518 +0,0 @@\\n-&lt;?xml version=\"1.0\" encod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4b97a810b509c93f44be4c037c7aa18fb8922884</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Pre-release 2023 December version (Mistral, Pr...</td>\n",
       "      <td>SlimOrca 1GPU.svg</td>\n",
       "      <td>DELETE</td>\n",
       "      <td>&lt;?xml version=\"1.0\" encoding=\"utf-8\" standalon...</td>\n",
       "      <td>None</td>\n",
       "      <td>@@ -1,1424 +0,0 @@\\n-&lt;?xml version=\"1.0\" encod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>978f73ed862ac1c10954cb27eb30e543f77d0421</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Bug fixes (#3266)\\n\\n* Fix mamba\\n\\n* Update l...</td>\n",
       "      <td>llama.py</td>\n",
       "      <td>MODIFY</td>\n",
       "      <td># Copyright 2023-present Daniel Han-Chen &amp; the...</td>\n",
       "      <td># Copyright 2023-present Daniel Han-Chen &amp; the...</td>\n",
       "      <td>@@ -1236,7 +1236,7 @@ def CausalLM_fast_forwar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243</th>\n",
       "      <td>978f73ed862ac1c10954cb27eb30e543f77d0421</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Bug fixes (#3266)\\n\\n* Fix mamba\\n\\n* Update l...</td>\n",
       "      <td>mistral.py</td>\n",
       "      <td>MODIFY</td>\n",
       "      <td># Copyright 2023-present Daniel Han-Chen &amp; the...</td>\n",
       "      <td># Copyright 2023-present Daniel Han-Chen &amp; the...</td>\n",
       "      <td>@@ -300,17 +300,30 @@ def MistralForCausalLM_f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244</th>\n",
       "      <td>978f73ed862ac1c10954cb27eb30e543f77d0421</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Bug fixes (#3266)\\n\\n* Fix mamba\\n\\n* Update l...</td>\n",
       "      <td>rl.py</td>\n",
       "      <td>MODIFY</td>\n",
       "      <td># Copyright 2023-present Daniel Han-Chen &amp; the...</td>\n",
       "      <td># Copyright 2023-present Daniel Han-Chen &amp; the...</td>\n",
       "      <td>@@ -513,7 +513,7 @@ def _patch_trl_rl_trainers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>ff6cbb03d0c2d11fe15c844bfc635eb24f533243</td>\n",
       "      <td>DoubleMathew</td>\n",
       "      <td>llama vision inference fix (#3270)\\n\\n* llama ...</td>\n",
       "      <td>vision.py</td>\n",
       "      <td>MODIFY</td>\n",
       "      <td># Copyright 2023-present Daniel Han-Chen &amp; the...</td>\n",
       "      <td># Copyright 2023-present Daniel Han-Chen &amp; the...</td>\n",
       "      <td>@@ -206,7 +206,7 @@ def unsloth_base_fast_gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>551bc65235aaf4ce1d00b48fed79eb48d759507b</td>\n",
       "      <td>Roland Tannous</td>\n",
       "      <td>Add TorchAO quantization tests with FP16 model...</td>\n",
       "      <td>test_unsloth_save.py</td>\n",
       "      <td>MODIFY</td>\n",
       "      <td>import json\\nimport os\\nimport shutil\\nimport ...</td>\n",
       "      <td>import json\\nimport os\\nimport shutil\\nimport ...</td>\n",
       "      <td>@@ -22,6 +22,15 @@ model_to_test = [\\n     \"un...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1247 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Hash          Author  \\\n",
       "0     4b97a810b509c93f44be4c037c7aa18fb8922884      Daniel Han   \n",
       "1     4b97a810b509c93f44be4c037c7aa18fb8922884      Daniel Han   \n",
       "2     4b97a810b509c93f44be4c037c7aa18fb8922884      Daniel Han   \n",
       "3     4b97a810b509c93f44be4c037c7aa18fb8922884      Daniel Han   \n",
       "4     4b97a810b509c93f44be4c037c7aa18fb8922884      Daniel Han   \n",
       "...                                        ...             ...   \n",
       "1242  978f73ed862ac1c10954cb27eb30e543f77d0421      Daniel Han   \n",
       "1243  978f73ed862ac1c10954cb27eb30e543f77d0421      Daniel Han   \n",
       "1244  978f73ed862ac1c10954cb27eb30e543f77d0421      Daniel Han   \n",
       "1245  ff6cbb03d0c2d11fe15c844bfc635eb24f533243    DoubleMathew   \n",
       "1246  551bc65235aaf4ce1d00b48fed79eb48d759507b  Roland Tannous   \n",
       "\n",
       "                                                Message              Filename  \\\n",
       "0     Pre-release 2023 December version (Mistral, Pr...             README.md   \n",
       "1     Pre-release 2023 December version (Mistral, Pr...           Discord.png   \n",
       "2     Pre-release 2023 December version (Mistral, Pr...        LAION 2GPU.png   \n",
       "3     Pre-release 2023 December version (Mistral, Pr...        LAION 2GPU.svg   \n",
       "4     Pre-release 2023 December version (Mistral, Pr...     SlimOrca 1GPU.svg   \n",
       "...                                                 ...                   ...   \n",
       "1242  Bug fixes (#3266)\\n\\n* Fix mamba\\n\\n* Update l...              llama.py   \n",
       "1243  Bug fixes (#3266)\\n\\n* Fix mamba\\n\\n* Update l...            mistral.py   \n",
       "1244  Bug fixes (#3266)\\n\\n* Fix mamba\\n\\n* Update l...                 rl.py   \n",
       "1245  llama vision inference fix (#3270)\\n\\n* llama ...             vision.py   \n",
       "1246  Add TorchAO quantization tests with FP16 model...  test_unsloth_save.py   \n",
       "\n",
       "     Change Type                               Source Code (before)  \\\n",
       "0         MODIFY  <div class=\"align-center\">\\n  <img src=\"./imag...   \n",
       "1         MODIFY  PNG\\r\\n\u001a\\n\u0000\u0000\u0000\\rIHDR\u0000\u0000\u0006\u0000\u0000\u0001\b\u0006\u0000\u0000\u0000\u000e\u0006\u0000\u0000\u0000\u0001sRGB\u0000\n",
       "\u0000\u0000\u0000\u0004...   \n",
       "2            ADD                                               None   \n",
       "3         DELETE  <?xml version=\"1.0\" encoding=\"utf-8\" standalon...   \n",
       "4         DELETE  <?xml version=\"1.0\" encoding=\"utf-8\" standalon...   \n",
       "...          ...                                                ...   \n",
       "1242      MODIFY  # Copyright 2023-present Daniel Han-Chen & the...   \n",
       "1243      MODIFY  # Copyright 2023-present Daniel Han-Chen & the...   \n",
       "1244      MODIFY  # Copyright 2023-present Daniel Han-Chen & the...   \n",
       "1245      MODIFY  # Copyright 2023-present Daniel Han-Chen & the...   \n",
       "1246      MODIFY  import json\\nimport os\\nimport shutil\\nimport ...   \n",
       "\n",
       "                                  Source Code (current)  \\\n",
       "0     <div class=\"align-center\">\\n  <img src=\"./imag...   \n",
       "1     PNG\\r\\n\u001a\\n\u0000\u0000\u0000\\rIHDR\u0000\u0000\u0003}\u0000\u0000\u0001\u0004\b\u0006\u0000\u0000\u00008]\u0000\u0000 \u0000IDATx\\t\u0014...   \n",
       "2     PNG\\r\\n\u001a\\n\u0000\u0000\u0000\\rIHDR\u0000\u0000\u0003\u0000\u0000\u0002A\b\u0006\u0000\u0000\u0001\u0011\u0000\u0000ȫIDATx\u0001\n",
       "\\k]\\...   \n",
       "3                                                  None   \n",
       "4                                                  None   \n",
       "...                                                 ...   \n",
       "1242  # Copyright 2023-present Daniel Han-Chen & the...   \n",
       "1243  # Copyright 2023-present Daniel Han-Chen & the...   \n",
       "1244  # Copyright 2023-present Daniel Han-Chen & the...   \n",
       "1245  # Copyright 2023-present Daniel Han-Chen & the...   \n",
       "1246  import json\\nimport os\\nimport shutil\\nimport ...   \n",
       "\n",
       "                                                   Diff  \n",
       "0     @@ -1,23 +1,25 @@\\n <div class=\"align-center\">...  \n",
       "1     Binary files a/images/Discord.png and b/images...  \n",
       "2     Binary files /dev/null and b/images/LAION 2GPU...  \n",
       "3     @@ -1,1518 +0,0 @@\\n-<?xml version=\"1.0\" encod...  \n",
       "4     @@ -1,1424 +0,0 @@\\n-<?xml version=\"1.0\" encod...  \n",
       "...                                                 ...  \n",
       "1242  @@ -1236,7 +1236,7 @@ def CausalLM_fast_forwar...  \n",
       "1243  @@ -300,17 +300,30 @@ def MistralForCausalLM_f...  \n",
       "1244  @@ -513,7 +513,7 @@ def _patch_trl_rl_trainers...  \n",
       "1245  @@ -206,7 +206,7 @@ def unsloth_base_fast_gene...  \n",
       "1246  @@ -22,6 +22,15 @@ model_to_test = [\\n     \"un...  \n",
       "\n",
       "[1247 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_analysis_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T18:39:33.264025Z",
     "iopub.status.busy": "2025-09-05T18:39:33.263713Z",
     "iopub.status.idle": "2025-09-05T18:39:52.537955Z",
     "shell.execute_reply": "2025-09-05T18:39:52.536394Z",
     "shell.execute_reply.started": "2025-09-05T18:39:33.264006Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "652a122b49f2429b8fc2dcbd8b194e24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a20b09ddbe9243808392c4d45a830d40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2215e4643db487db463c4ab3e1aa9f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14962bbcf3e844e3958d9ca19e46dd27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/57.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b75adba21024ca58992350c06d2ddbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc538e991f574b26996e2f0d65b766db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-05 18:39:51.613955: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1757097591.828956      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1757097591.888682      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_36/1200847653.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Using device:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForSeq2SeqLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mamiksik/CommitPredictorT5\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    566\u001b[0m             )\n\u001b[1;32m    567\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_configs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text_config\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m                 \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36m_get_model_class\u001b[0;34m(config, model_mapping)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m     \u001b[0msupported_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupported_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msupported_models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    772\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m             \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_attr_from_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0;31m# Maybe there was several model types associated with this config.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36m_load_attr_from_module\u001b[0;34m(self, model_type, attr)\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodule_name\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\".{module_name}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transformers.models\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattribute_from_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mgetattribute_from_module\u001b[0;34m(module, attr)\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattribute_from_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m     \u001b[0;31m# Some of the mappings have entries model_type -> object of another model type. In that case we try to grab the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2044\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2045\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2046\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2047\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2071\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2072\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2073\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2074\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2075\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mTokenClassifierOutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m )\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mmodeling_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPreTrainedModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mpytorch_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mALL_LAYERNORM_LAYERS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfind_pruneable_heads_and_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprune_linear_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m from ...utils import (\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mverify_tp_plan\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m )\n\u001b[0;32m---> 73\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLOSS_MAPPING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m from .pytorch_utils import (  # noqa: F401\n\u001b[1;32m     75\u001b[0m     \u001b[0mConv1D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/loss/loss_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMSELoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mloss_d_fine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDFineForObjectDetectionLoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mloss_deformable_detr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDeformableDetrForObjectDetectionLoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDeformableDetrForSegmentationLoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mloss_for_object_detection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mForObjectDetectionLoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mForSegmentationLoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/loss/loss_d_fine.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_vision_available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m from .loss_for_object_detection import (\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mbox_iou\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m )\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/loss/loss_for_object_detection.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_vision_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_transforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcenter_to_corners_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/image_transforms.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_tf_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_flax_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_pywrap_tensorflow\u001b[0m  \u001b[0;31m# pylint: disable=unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKerasLazyLoader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_KerasLazyLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Perform pre-load sanity checks in order to produce a more actionable error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mself_check\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreload_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# pylint: disable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/self_check.py\u001b[0m in \u001b[0;36mpreload_check\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;31m# incompatibilities before we trigger them (which would typically result in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# SIGILL).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pywrap_cpu_feature_guard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0m_pywrap_cpu_feature_guard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInfoAboutUnusedCPUFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Loading tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mamiksik/CommitPredictorT5\")\n",
    "\n",
    "# Loading model and moving it to GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"mamiksik/CommitPredictorT5\",device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T19:51:28.783520Z",
     "iopub.status.busy": "2025-09-05T19:51:28.783218Z",
     "iopub.status.idle": "2025-09-05T19:51:28.790755Z",
     "shell.execute_reply": "2025-09-05T19:51:28.789944Z",
     "shell.execute_reply.started": "2025-09-05T19:51:28.783496Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch, gc, time\n",
    "\n",
    "def predict_batch(model, tokenizer, commit_msgs, diffs, device=\"cuda\"):\n",
    "    system_prompt = (\n",
    "        \"You are given a code diff and the original developer commit message. \"\n",
    "        \"Your task is to rewrite the commit message so that it is concise, \"\n",
    "        \"grammatically correct, and clearly describes the changes made in the diff.\"\n",
    "    )\n",
    "\n",
    "    # Build prompts\n",
    "    texts = []\n",
    "    for commit_msg, diff in zip(commit_msgs, diffs):\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"Diff:\\n{diff}\\n\\nOriginal commit message: {commit_msg}\"}\n",
    "        ]\n",
    "        text = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True,\n",
    "        )\n",
    "        texts.append(text)\n",
    "\n",
    "    # Tokenize batch\n",
    "    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "\n",
    "    # Record input length (for trimming)\n",
    "    input_len = inputs.input_ids.shape[1]\n",
    "\n",
    "    # Generate\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            num_beams=5,\n",
    "            do_sample=True,\n",
    "            top_p=0.9,\n",
    "            max_new_tokens=100,  # safe cap\n",
    "            early_stopping=True\n",
    "        )\n",
    "    end_time = time.time()\n",
    "    print(\"Time taken for batch of\", len(commit_msgs), \":\", round(end_time - start_time, 2), \"seconds\")\n",
    "\n",
    "    # Decode\n",
    "    predictions = []\n",
    "    for output in outputs:\n",
    "        pred = tokenizer.decode(output[input_len:], skip_special_tokens=True).strip()\n",
    "        predictions.append(pred)\n",
    "\n",
    "    # Free memory\n",
    "    del inputs, outputs\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T20:17:11.023432Z",
     "iopub.status.busy": "2025-09-03T20:17:11.022947Z",
     "iopub.status.idle": "2025-09-03T20:23:10.353989Z",
     "shell.execute_reply": "2025-09-03T20:23:10.353155Z",
     "shell.execute_reply.started": "2025-09-03T20:17:11.023407Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 20 : 5.36007833480835 seconds.\n",
      "Time taken for batch of 20 : 5.279646873474121 seconds.\n",
      "Time taken for batch of 20 : 4.7002716064453125 seconds.\n",
      "Time taken for batch of 20 : 5.556906461715698 seconds.\n",
      "Time taken for batch of 20 : 5.836158752441406 seconds.\n",
      "Time taken for batch of 20 : 5.273885726928711 seconds.\n",
      "Time taken for batch of 20 : 5.291773557662964 seconds.\n",
      "Time taken for batch of 20 : 5.861851692199707 seconds.\n",
      "Time taken for batch of 20 : 5.017362356185913 seconds.\n",
      "Time taken for batch of 20 : 4.471691370010376 seconds.\n",
      "Time taken for batch of 20 : 5.034398794174194 seconds.\n",
      "Time taken for batch of 20 : 5.0324387550354 seconds.\n",
      "Time taken for batch of 20 : 5.047799587249756 seconds.\n",
      "Time taken for batch of 20 : 5.031895637512207 seconds.\n",
      "Time taken for batch of 20 : 5.311582088470459 seconds.\n",
      "Time taken for batch of 20 : 5.620614051818848 seconds.\n",
      "Time taken for batch of 20 : 5.081935167312622 seconds.\n",
      "Time taken for batch of 20 : 5.056572675704956 seconds.\n",
      "Time taken for batch of 20 : 4.79361629486084 seconds.\n",
      "Time taken for batch of 20 : 5.073583364486694 seconds.\n",
      "Time taken for batch of 20 : 5.079817295074463 seconds.\n",
      "Time taken for batch of 20 : 6.203255891799927 seconds.\n",
      "Time taken for batch of 20 : 5.094135522842407 seconds.\n",
      "Time taken for batch of 20 : 5.6601951122283936 seconds.\n",
      "Time taken for batch of 20 : 6.787935495376587 seconds.\n",
      "Time taken for batch of 20 : 4.552196502685547 seconds.\n",
      "Time taken for batch of 20 : 5.38364052772522 seconds.\n",
      "Time taken for batch of 20 : 6.265027761459351 seconds.\n",
      "Time taken for batch of 20 : 5.1344568729400635 seconds.\n",
      "Time taken for batch of 20 : 6.263135194778442 seconds.\n",
      "Time taken for batch of 20 : 4.862339019775391 seconds.\n",
      "Time taken for batch of 20 : 5.700581789016724 seconds.\n",
      "Time taken for batch of 20 : 4.844019412994385 seconds.\n",
      "Time taken for batch of 20 : 5.411619186401367 seconds.\n",
      "Time taken for batch of 20 : 4.841052055358887 seconds.\n",
      "Time taken for batch of 20 : 5.6445534229278564 seconds.\n",
      "Time taken for batch of 20 : 5.6668806076049805 seconds.\n",
      "Time taken for batch of 20 : 4.827131748199463 seconds.\n",
      "Time taken for batch of 20 : 5.3986780643463135 seconds.\n",
      "Time taken for batch of 20 : 4.842013835906982 seconds.\n",
      "Time taken for batch of 20 : 5.657012224197388 seconds.\n",
      "Time taken for batch of 20 : 5.113498687744141 seconds.\n",
      "Time taken for batch of 20 : 5.695874214172363 seconds.\n",
      "Time taken for batch of 20 : 5.7062530517578125 seconds.\n",
      "Time taken for batch of 20 : 4.851161479949951 seconds.\n",
      "Time taken for batch of 20 : 5.132807731628418 seconds.\n",
      "Time taken for batch of 20 : 5.418392181396484 seconds.\n",
      "Time taken for batch of 20 : 4.839756011962891 seconds.\n",
      "Time taken for batch of 20 : 4.847575902938843 seconds.\n",
      "Time taken for batch of 20 : 6.51946759223938 seconds.\n",
      "Time taken for batch of 20 : 5.670523405075073 seconds.\n",
      "Time taken for batch of 20 : 5.669216871261597 seconds.\n",
      "Time taken for batch of 20 : 5.928407669067383 seconds.\n",
      "Time taken for batch of 20 : 6.245543003082275 seconds.\n",
      "Time taken for batch of 20 : 4.8553078174591064 seconds.\n",
      "Time taken for batch of 20 : 5.1147894859313965 seconds.\n",
      "Time taken for batch of 20 : 5.416203022003174 seconds.\n",
      "Time taken for batch of 20 : 5.387255907058716 seconds.\n",
      "Time taken for batch of 20 : 5.114590167999268 seconds.\n",
      "Time taken for batch of 20 : 7.913918733596802 seconds.\n",
      "Time taken for batch of 20 : 5.399469614028931 seconds.\n",
      "Time taken for batch of 15 : 4.302406549453735 seconds.\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 20 # tune based on GPU memory\n",
    "\n",
    "all_predictions = []\n",
    "\n",
    "for i in range(0, len(diff_analysis_df), BATCH_SIZE):\n",
    "    batch_texts = diff_analysis_df[\"Diff\"].iloc[i:i+BATCH_SIZE].tolist()\n",
    "    preds = predict_batch(model, batch_texts, device=\"cuda\")\n",
    "    all_predictions.extend(preds)\n",
    "\n",
    "# Adding as a new column\n",
    "diff_analysis_df[\"LLM_inference\"] = all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T20:28:07.449707Z",
     "iopub.status.busy": "2025-09-03T20:28:07.448634Z",
     "iopub.status.idle": "2025-09-03T20:28:07.479642Z",
     "shell.execute_reply": "2025-09-03T20:28:07.478916Z",
     "shell.execute_reply.started": "2025-09-03T20:28:07.449678Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hash</th>\n",
       "      <th>Author</th>\n",
       "      <th>Message</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Change Type</th>\n",
       "      <th>Source Code (before)</th>\n",
       "      <th>Source Code (current)</th>\n",
       "      <th>Diff</th>\n",
       "      <th>LLM_inference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4b97a810b509c93f44be4c037c7aa18fb8922884</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Pre-release 2023 December version (Mistral, Pr...</td>\n",
       "      <td>README.md</td>\n",
       "      <td>MODIFY</td>\n",
       "      <td>&lt;div class=\"align-center\"&gt;\\n  &lt;img src=\"./imag...</td>\n",
       "      <td>&lt;div class=\"align-center\"&gt;\\n  &lt;img src=\"./imag...</td>\n",
       "      <td>@@ -1,23 +1,25 @@\\n &lt;div class=\"align-center\"&gt;...</td>\n",
       "      <td>add more info about nvidia gpus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4b97a810b509c93f44be4c037c7aa18fb8922884</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Pre-release 2023 December version (Mistral, Pr...</td>\n",
       "      <td>Discord.png</td>\n",
       "      <td>MODIFY</td>\n",
       "      <td>PNG\\r\\n\u001a\\n\u0000\u0000\u0000\\rIHDR\u0000\u0000\u0006\u0000\u0000\u0001\b\u0006\u0000\u0000\u0000\u000e\u0006\u0000\u0000\u0000\u0001sRGB\u0000\u001c\u0000\u0000\u0000\u0004...</td>\n",
       "      <td>PNG\\r\\n\u001a\\n\u0000\u0000\u0000\\rIHDR\u0000\u0000\u0003}\u0000\u0000\u0001\u0004\b\u0006\u0000\u0000\u00008]\u0000\u0000 \u0000IDATx\\t\u0014...</td>\n",
       "      <td>Binary files a/images/Discord.png and b/images...</td>\n",
       "      <td>distro binary files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4b97a810b509c93f44be4c037c7aa18fb8922884</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Pre-release 2023 December version (Mistral, Pr...</td>\n",
       "      <td>LAION 2GPU.png</td>\n",
       "      <td>ADD</td>\n",
       "      <td>None</td>\n",
       "      <td>PNG\\r\\n\u001a\\n\u0000\u0000\u0000\\rIHDR\u0000\u0000\u0003\u0000\u0000\u0002A\b\u0006\u0000\u0000\u0001\u0011\u0000\u0000ȫIDATx\u0001\u000b\\k]\\...</td>\n",
       "      <td>Binary files /dev/null and b/images/LAION 2GPU...</td>\n",
       "      <td>distinguish 2gpu image from null</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4b97a810b509c93f44be4c037c7aa18fb8922884</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Pre-release 2023 December version (Mistral, Pr...</td>\n",
       "      <td>LAION 2GPU.svg</td>\n",
       "      <td>DELETE</td>\n",
       "      <td>&lt;?xml version=\"1.0\" encoding=\"utf-8\" standalon...</td>\n",
       "      <td>None</td>\n",
       "      <td>@@ -1,1518 +0,0 @@\\n-&lt;?xml version=\"1.0\" encod...</td>\n",
       "      <td>add missing missing nodes in skeleton skeleton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4b97a810b509c93f44be4c037c7aa18fb8922884</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Pre-release 2023 December version (Mistral, Pr...</td>\n",
       "      <td>SlimOrca 1GPU.svg</td>\n",
       "      <td>DELETE</td>\n",
       "      <td>&lt;?xml version=\"1.0\" encoding=\"utf-8\" standalon...</td>\n",
       "      <td>None</td>\n",
       "      <td>@@ -1,1424 +0,0 @@\\n-&lt;?xml version=\"1.0\" encod...</td>\n",
       "      <td>add missing missing svg elements</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>9050d6f5278e2373e66d17fc9ac8c2ec4f986e7e</td>\n",
       "      <td>Roland Tannous</td>\n",
       "      <td>tests for mxfp4 and quantized models merge fix...</td>\n",
       "      <td>run_test.sh</td>\n",
       "      <td>ADD</td>\n",
       "      <td>None</td>\n",
       "      <td>#!/bin/bash\\nset -e\\n\\necho \"=================...</td>\n",
       "      <td>@@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...</td>\n",
       "      <td>add missing line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>9050d6f5278e2373e66d17fc9ac8c2ec4f986e7e</td>\n",
       "      <td>Roland Tannous</td>\n",
       "      <td>tests for mxfp4 and quantized models merge fix...</td>\n",
       "      <td>test_merged_model.py</td>\n",
       "      <td>ADD</td>\n",
       "      <td>None</td>\n",
       "      <td># inference_on_merged.py\\nfrom unsloth import ...</td>\n",
       "      <td>@@ -0,0 +1,55 @@\\n+# inference_on_merged.py\\n+...</td>\n",
       "      <td>add test for merge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>9050d6f5278e2373e66d17fc9ac8c2ec4f986e7e</td>\n",
       "      <td>Roland Tannous</td>\n",
       "      <td>tests for mxfp4 and quantized models merge fix...</td>\n",
       "      <td>train_and_merge.py</td>\n",
       "      <td>ADD</td>\n",
       "      <td>None</td>\n",
       "      <td># train_and_merge.py\\nfrom unsloth import Fast...</td>\n",
       "      <td>@@ -0,0 +1,71 @@\\n+# train_and_merge.py\\n+from...</td>\n",
       "      <td>add examples to train_and_merge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>9050d6f5278e2373e66d17fc9ac8c2ec4f986e7e</td>\n",
       "      <td>Roland Tannous</td>\n",
       "      <td>tests for mxfp4 and quantized models merge fix...</td>\n",
       "      <td>test_merge_4bit_validation.py</td>\n",
       "      <td>ADD</td>\n",
       "      <td>None</td>\n",
       "      <td>from unsloth import FastLanguageModel\\nfrom un...</td>\n",
       "      <td>@@ -0,0 +1,223 @@\\n+from unsloth import FastLa...</td>\n",
       "      <td>add test case for formatting prompts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>12737e503d32fc1464f8e38536be96d92db4f7d8</td>\n",
       "      <td>stevenxdavis</td>\n",
       "      <td>Fix incorrect function call in test_qwen3_grpo...</td>\n",
       "      <td>test_qwen3_grpo.py</td>\n",
       "      <td>MODIFY</td>\n",
       "      <td>from unsloth import FastLanguageModel\\nimport ...</td>\n",
       "      <td>from unsloth import FastLanguageModel\\nimport ...</td>\n",
       "      <td>@@ -415,7 +415,8 @@ sampling_params = Sampling...</td>\n",
       "      <td>update sample_params.rb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1235 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Hash          Author  \\\n",
       "0     4b97a810b509c93f44be4c037c7aa18fb8922884      Daniel Han   \n",
       "1     4b97a810b509c93f44be4c037c7aa18fb8922884      Daniel Han   \n",
       "2     4b97a810b509c93f44be4c037c7aa18fb8922884      Daniel Han   \n",
       "3     4b97a810b509c93f44be4c037c7aa18fb8922884      Daniel Han   \n",
       "4     4b97a810b509c93f44be4c037c7aa18fb8922884      Daniel Han   \n",
       "...                                        ...             ...   \n",
       "1230  9050d6f5278e2373e66d17fc9ac8c2ec4f986e7e  Roland Tannous   \n",
       "1231  9050d6f5278e2373e66d17fc9ac8c2ec4f986e7e  Roland Tannous   \n",
       "1232  9050d6f5278e2373e66d17fc9ac8c2ec4f986e7e  Roland Tannous   \n",
       "1233  9050d6f5278e2373e66d17fc9ac8c2ec4f986e7e  Roland Tannous   \n",
       "1234  12737e503d32fc1464f8e38536be96d92db4f7d8    stevenxdavis   \n",
       "\n",
       "                                                Message  \\\n",
       "0     Pre-release 2023 December version (Mistral, Pr...   \n",
       "1     Pre-release 2023 December version (Mistral, Pr...   \n",
       "2     Pre-release 2023 December version (Mistral, Pr...   \n",
       "3     Pre-release 2023 December version (Mistral, Pr...   \n",
       "4     Pre-release 2023 December version (Mistral, Pr...   \n",
       "...                                                 ...   \n",
       "1230  tests for mxfp4 and quantized models merge fix...   \n",
       "1231  tests for mxfp4 and quantized models merge fix...   \n",
       "1232  tests for mxfp4 and quantized models merge fix...   \n",
       "1233  tests for mxfp4 and quantized models merge fix...   \n",
       "1234  Fix incorrect function call in test_qwen3_grpo...   \n",
       "\n",
       "                           Filename Change Type  \\\n",
       "0                         README.md      MODIFY   \n",
       "1                       Discord.png      MODIFY   \n",
       "2                    LAION 2GPU.png         ADD   \n",
       "3                    LAION 2GPU.svg      DELETE   \n",
       "4                 SlimOrca 1GPU.svg      DELETE   \n",
       "...                             ...         ...   \n",
       "1230                    run_test.sh         ADD   \n",
       "1231           test_merged_model.py         ADD   \n",
       "1232             train_and_merge.py         ADD   \n",
       "1233  test_merge_4bit_validation.py         ADD   \n",
       "1234             test_qwen3_grpo.py      MODIFY   \n",
       "\n",
       "                                   Source Code (before)  \\\n",
       "0     <div class=\"align-center\">\\n  <img src=\"./imag...   \n",
       "1     PNG\\r\\n\u001a\\n\u0000\u0000\u0000\\rIHDR\u0000\u0000\u0006\u0000\u0000\u0001\b\u0006\u0000\u0000\u0000\u000e\u0006\u0000\u0000\u0000\u0001sRGB\u0000\n",
       "\u0000\u0000\u0000\u0004...   \n",
       "2                                                  None   \n",
       "3     <?xml version=\"1.0\" encoding=\"utf-8\" standalon...   \n",
       "4     <?xml version=\"1.0\" encoding=\"utf-8\" standalon...   \n",
       "...                                                 ...   \n",
       "1230                                               None   \n",
       "1231                                               None   \n",
       "1232                                               None   \n",
       "1233                                               None   \n",
       "1234  from unsloth import FastLanguageModel\\nimport ...   \n",
       "\n",
       "                                  Source Code (current)  \\\n",
       "0     <div class=\"align-center\">\\n  <img src=\"./imag...   \n",
       "1     PNG\\r\\n\u001a\\n\u0000\u0000\u0000\\rIHDR\u0000\u0000\u0003}\u0000\u0000\u0001\u0004\b\u0006\u0000\u0000\u00008]\u0000\u0000 \u0000IDATx\\t\u0014...   \n",
       "2     PNG\\r\\n\u001a\\n\u0000\u0000\u0000\\rIHDR\u0000\u0000\u0003\u0000\u0000\u0002A\b\u0006\u0000\u0000\u0001\u0011\u0000\u0000ȫIDATx\u0001\n",
       "\\k]\\...   \n",
       "3                                                  None   \n",
       "4                                                  None   \n",
       "...                                                 ...   \n",
       "1230  #!/bin/bash\\nset -e\\n\\necho \"=================...   \n",
       "1231  # inference_on_merged.py\\nfrom unsloth import ...   \n",
       "1232  # train_and_merge.py\\nfrom unsloth import Fast...   \n",
       "1233  from unsloth import FastLanguageModel\\nfrom un...   \n",
       "1234  from unsloth import FastLanguageModel\\nimport ...   \n",
       "\n",
       "                                                   Diff  \\\n",
       "0     @@ -1,23 +1,25 @@\\n <div class=\"align-center\">...   \n",
       "1     Binary files a/images/Discord.png and b/images...   \n",
       "2     Binary files /dev/null and b/images/LAION 2GPU...   \n",
       "3     @@ -1,1518 +0,0 @@\\n-<?xml version=\"1.0\" encod...   \n",
       "4     @@ -1,1424 +0,0 @@\\n-<?xml version=\"1.0\" encod...   \n",
       "...                                                 ...   \n",
       "1230  @@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...   \n",
       "1231  @@ -0,0 +1,55 @@\\n+# inference_on_merged.py\\n+...   \n",
       "1232  @@ -0,0 +1,71 @@\\n+# train_and_merge.py\\n+from...   \n",
       "1233  @@ -0,0 +1,223 @@\\n+from unsloth import FastLa...   \n",
       "1234  @@ -415,7 +415,8 @@ sampling_params = Sampling...   \n",
       "\n",
       "                                       LLM_inference  \n",
       "0                    add more info about nvidia gpus  \n",
       "1                                distro binary files  \n",
       "2                   distinguish 2gpu image from null  \n",
       "3     add missing missing nodes in skeleton skeleton  \n",
       "4                   add missing missing svg elements  \n",
       "...                                              ...  \n",
       "1230                                add missing line  \n",
       "1231                              add test for merge  \n",
       "1232                 add examples to train_and_merge  \n",
       "1233            add test case for formatting prompts  \n",
       "1234                         update sample_params.rb  \n",
       "\n",
       "[1235 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_analysis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T20:28:27.587352Z",
     "iopub.status.busy": "2025-09-03T20:28:27.586420Z",
     "iopub.status.idle": "2025-09-03T20:28:27.621219Z",
     "shell.execute_reply": "2025-09-03T20:28:27.620639Z",
     "shell.execute_reply.started": "2025-09-03T20:28:27.587323Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "new_df = diff_analysis_df.groupby('Hash',sort=False)['Diff'].apply(list).reset_index()\n",
    "diffs = []\n",
    "for i in range(len(new_df)):\n",
    "    diff = '\\n'.join(new_df.iloc[i]['Diff'])\n",
    "    diffs.append(diff)\n",
    "new_df['Overall_diff'] = diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_name = \"unsloth/Qwen3-4B-Instruct-2507-unsloth-bnb-4bit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T06:26:19.648063Z",
     "iopub.status.busy": "2025-09-06T06:26:19.647911Z",
     "iopub.status.idle": "2025-09-06T06:30:16.959959Z",
     "shell.execute_reply": "2025-09-06T06:30:16.959098Z",
     "shell.execute_reply.started": "2025-09-06T06:26:19.648045Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/utils/_process_posix.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0;31m# know whether we've finished (if we matched EOF) or not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m                 \u001b[0mres_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpect_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatterns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'replace'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pexpect/spawnbase.py\u001b[0m in \u001b[0;36mexpect_list\u001b[0;34m(self, pattern_list, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpect_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pexpect/expect.py\u001b[0m in \u001b[0;36mexpect_loop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0;31m# Still have time left, so read more data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m                 \u001b[0mincoming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_nonblocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelayafterread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36mread_nonblocking\u001b[0;34m(self, size, timeout)\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0;31m# (possibly timeout=None), we call select() with a timeout.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_nonblocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mselect_ignore_interrupts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild_fd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pexpect/utils.py\u001b[0m in \u001b[0;36mselect_ignore_interrupts\u001b[0;34m(iwtd, owtd, ewtd, timeout)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mselect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miwtd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mowtd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mewtd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_36/3384266862.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install pip3-autoremove'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install torch torchvision torchaudio xformers --index-url https://download.pytorch.org/whl/cu128'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install unsloth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install transformers==4.55.4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\u001b[0m in \u001b[0;36msystem_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_exit_code\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_exit_code\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m     \u001b[0;31m# Ensure new system_piped implementation is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/utils/_process_posix.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;31m# (the character is known as ETX for 'End of Text', see\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;31m# curses.ascii.ETX).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             \u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msendline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0;31m# Read and print any more output the program might produce on its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;31m# way out.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36msendline\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m    576\u001b[0m         '''\n\u001b[1;32m    577\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coerce_send_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinesep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_log_control\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelaybeforesend\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelaybeforesend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coerce_send_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "\n",
    "!pip install pip3-autoremove\n",
    "!pip install torch torchvision torchaudio xformers --index-url https://download.pytorch.org/whl/cu128\n",
    "!pip install unsloth\n",
    "!pip install transformers==4.55.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T13:04:41.995617Z",
     "iopub.status.busy": "2025-09-06T13:04:41.995052Z",
     "iopub.status.idle": "2025-09-06T13:04:48.326231Z",
     "shell.execute_reply": "2025-09-06T13:04:48.325468Z",
     "shell.execute_reply.started": "2025-09-06T13:04:41.995596Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "!pip install -q transformers accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T06:30:53.593472Z",
     "iopub.status.busy": "2025-09-06T06:30:53.593188Z",
     "iopub.status.idle": "2025-09-06T06:31:55.554166Z",
     "shell.execute_reply": "2025-09-06T06:31:55.553380Z",
     "shell.execute_reply.started": "2025-09-06T06:30:53.593444Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d336e742eed045a286c44672b2fe7803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b02c0740e7434e628b50f3082e3fb2ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0b42bc19cb047fbb2748f55253479b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a4ffdcfc9c8430681055e4019f3c267",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51ba22d796a941cabca65d0b177a582f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/707 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5926c219171d4a939fcf0463b9319635",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "531462a3fa6e4f519a0e076058b884b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.jinja: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baaade0f068747ddb8f3aa363e3c37a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-06 06:31:06.368850: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1757140266.616327      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1757140266.684917      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "775fe4bc37c64b02bc464b297be9c0f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.55G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9761ceaa36db49f2b34ac6865257004c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/237 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, how are you? I need help with a problem.\n",
      "\n",
      "Of course! I'm doing great, thanks for asking. Please go ahead and share the problem you need help with — I'm here to help! 😊\n",
      "\n",
      "(Also, if you're working on a math\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model_name = \"unsloth/Qwen3-4B-Instruct-2507-unsloth-bnb-4bit\"\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Load model in 4-bit (bnb) without unsloth\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",        # automatically places on GPU\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# Quick test\n",
    "inputs = tokenizer(\"Hello, how are you?\", return_tensors=\"pt\").to(\"cuda\")\n",
    "outputs = model.generate(**inputs, max_new_tokens=50)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T06:36:50.172506Z",
     "iopub.status.busy": "2025-09-06T06:36:50.172229Z",
     "iopub.status.idle": "2025-09-06T06:36:50.177706Z",
     "shell.execute_reply": "2025-09-06T06:36:50.177013Z",
     "shell.execute_reply.started": "2025-09-06T06:36:50.172483Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T07:08:23.245196Z",
     "iopub.status.busy": "2025-09-06T07:08:23.244704Z",
     "iopub.status.idle": "2025-09-06T07:08:23.253852Z",
     "shell.execute_reply": "2025-09-06T07:08:23.253215Z",
     "shell.execute_reply.started": "2025-09-06T07:08:23.245174Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch, gc, time\n",
    "\n",
    "def predict_batch(\n",
    "    model, tokenizer, commit_msgs, diffs, device=\"cuda\",\n",
    "    max_commit_tokens=64, max_diff_tokens=1024\n",
    "):\n",
    "    system_prompt = (\n",
    "    \"You are given a code diff and the original developer commit message. \"\n",
    "    \"Write a clear, concise, and grammatically correct commit message that best describes \"\n",
    "    \"the changes in the diff. \"\n",
    "    \"You may use the original developer message as a reference, but do not rely on it if it is unclear, incomplete, or misleading. \"\n",
    "    \"Output only the final commit message, without any extra text, labels, or explanation.\"\n",
    "    )\n",
    "\n",
    "    texts = []\n",
    "    for commit_msg, diff in zip(commit_msgs, diffs):\n",
    "        # Tokenize and truncate commit message\n",
    "        commit_tokens = tokenizer.encode(commit_msg, add_special_tokens=False)\n",
    "        if len(commit_tokens) > max_commit_tokens:\n",
    "            commit_tokens = commit_tokens[:max_commit_tokens]\n",
    "        commit_msg_trunc = tokenizer.decode(commit_tokens, skip_special_tokens=True)\n",
    "\n",
    "        # Tokenize and truncate diff\n",
    "        diff_tokens = tokenizer.encode(diff, add_special_tokens=False)\n",
    "        if len(diff_tokens) > max_diff_tokens:\n",
    "            diff_tokens = diff_tokens[:max_diff_tokens]\n",
    "        diff_trunc = tokenizer.decode(diff_tokens, skip_special_tokens=True)\n",
    "\n",
    "        # Build conversation\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"Diff:\\n{diff_trunc}\\n\\nOriginal commit message: {commit_msg_trunc}\"}\n",
    "        ]\n",
    "\n",
    "        text = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True,\n",
    "        )\n",
    "        texts.append(text)\n",
    "\n",
    "    # Tokenize batch (handles padding + truncation for full prompt)\n",
    "    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "\n",
    "    input_len = inputs.input_ids.shape[1]\n",
    "\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_p=0.80,\n",
    "            top_k=20,\n",
    "            max_new_tokens=64\n",
    "        )\n",
    "    end_time = time.time()\n",
    "    print(\"Time taken for batch of\", len(commit_msgs), \":\", round(end_time - start_time, 2), \"seconds\")\n",
    "\n",
    "    # Decode only the new tokens after the input length\n",
    "    predictions = []\n",
    "    for output in outputs:\n",
    "        pred = tokenizer.decode(output[input_len:], skip_special_tokens=True).strip()\n",
    "        predictions.append(pred)\n",
    "\n",
    "    # Free memory\n",
    "    del inputs, outputs\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T06:37:29.980921Z",
     "iopub.status.busy": "2025-09-06T06:37:29.980127Z",
     "iopub.status.idle": "2025-09-06T06:37:32.734334Z",
     "shell.execute_reply": "2025-09-06T06:37:32.733500Z",
     "shell.execute_reply.started": "2025-09-06T06:37:29.980896Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hash</th>\n",
       "      <th>Author</th>\n",
       "      <th>Message</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Change Type</th>\n",
       "      <th>Source Code (before)</th>\n",
       "      <th>Source Code (current)</th>\n",
       "      <th>Diff</th>\n",
       "      <th>LLM_inference</th>\n",
       "      <th>Overall_diff</th>\n",
       "      <th>Rectified Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4b97a810b509c93f44be4c037c7aa18fb8922884</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Pre-release 2023 December version (Mistral, Pr...</td>\n",
       "      <td>README.md</td>\n",
       "      <td>MODIFY</td>\n",
       "      <td>&lt;div class=\"align-center\"&gt;\\n  &lt;img src=\"./imag...</td>\n",
       "      <td>&lt;div class=\"align-center\"&gt;\\n  &lt;img src=\"./imag...</td>\n",
       "      <td>@@ -1,23 +1,25 @@\\n &lt;div class=\"align-center\"&gt;...</td>\n",
       "      <td>add more info about nvidia gpus</td>\n",
       "      <td>@@ -1,23 +1,25 @@\\n &lt;div class=\"align-center\"&gt;...</td>\n",
       "      <td>add more info about nvidia gpus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4b97a810b509c93f44be4c037c7aa18fb8922884</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Pre-release 2023 December version (Mistral, Pr...</td>\n",
       "      <td>Discord.png</td>\n",
       "      <td>MODIFY</td>\n",
       "      <td>PNG\\r\\n\u001a\\n</td>\n",
       "      <td>PNG\\r\\n\u001a\\n</td>\n",
       "      <td>Binary files a/images/Discord.png and b/images...</td>\n",
       "      <td>distro binary files</td>\n",
       "      <td>@@ -1,23 +1,25 @@\\n &lt;div class=\"align-center\"&gt;...</td>\n",
       "      <td>add more info about nvidia gpus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4b97a810b509c93f44be4c037c7aa18fb8922884</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Pre-release 2023 December version (Mistral, Pr...</td>\n",
       "      <td>LAION 2GPU.png</td>\n",
       "      <td>ADD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PNG\\r\\n\u001a\\n</td>\n",
       "      <td>Binary files /dev/null and b/images/LAION 2GPU...</td>\n",
       "      <td>distinguish 2gpu image from null</td>\n",
       "      <td>@@ -1,23 +1,25 @@\\n &lt;div class=\"align-center\"&gt;...</td>\n",
       "      <td>add more info about nvidia gpus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4b97a810b509c93f44be4c037c7aa18fb8922884</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Pre-release 2023 December version (Mistral, Pr...</td>\n",
       "      <td>LAION 2GPU.svg</td>\n",
       "      <td>DELETE</td>\n",
       "      <td>&lt;?xml version=\"1.0\" encoding=\"utf-8\" standalon...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@@ -1,1518 +0,0 @@\\n-&lt;?xml version=\"1.0\" encod...</td>\n",
       "      <td>add missing missing nodes in skeleton skeleton</td>\n",
       "      <td>@@ -1,23 +1,25 @@\\n &lt;div class=\"align-center\"&gt;...</td>\n",
       "      <td>add more info about nvidia gpus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4b97a810b509c93f44be4c037c7aa18fb8922884</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Pre-release 2023 December version (Mistral, Pr...</td>\n",
       "      <td>SlimOrca 1GPU.svg</td>\n",
       "      <td>DELETE</td>\n",
       "      <td>&lt;?xml version=\"1.0\" encoding=\"utf-8\" standalon...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@@ -1,1424 +0,0 @@\\n-&lt;?xml version=\"1.0\" encod...</td>\n",
       "      <td>add missing missing svg elements</td>\n",
       "      <td>@@ -1,23 +1,25 @@\\n &lt;div class=\"align-center\"&gt;...</td>\n",
       "      <td>add more info about nvidia gpus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>9050d6f5278e2373e66d17fc9ac8c2ec4f986e7e</td>\n",
       "      <td>Roland Tannous</td>\n",
       "      <td>tests for mxfp4 and quantized models merge fix...</td>\n",
       "      <td>run_test.sh</td>\n",
       "      <td>ADD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#!/bin/bash\\nset -e\\n\\necho \"=================...</td>\n",
       "      <td>@@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...</td>\n",
       "      <td>add missing line</td>\n",
       "      <td>@@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...</td>\n",
       "      <td>add test for merged model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>9050d6f5278e2373e66d17fc9ac8c2ec4f986e7e</td>\n",
       "      <td>Roland Tannous</td>\n",
       "      <td>tests for mxfp4 and quantized models merge fix...</td>\n",
       "      <td>test_merged_model.py</td>\n",
       "      <td>ADD</td>\n",
       "      <td>NaN</td>\n",
       "      <td># inference_on_merged.py\\nfrom unsloth import ...</td>\n",
       "      <td>@@ -0,0 +1,55 @@\\n+# inference_on_merged.py\\n+...</td>\n",
       "      <td>add test for merge</td>\n",
       "      <td>@@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...</td>\n",
       "      <td>add test for merged model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>9050d6f5278e2373e66d17fc9ac8c2ec4f986e7e</td>\n",
       "      <td>Roland Tannous</td>\n",
       "      <td>tests for mxfp4 and quantized models merge fix...</td>\n",
       "      <td>train_and_merge.py</td>\n",
       "      <td>ADD</td>\n",
       "      <td>NaN</td>\n",
       "      <td># train_and_merge.py\\nfrom unsloth import Fast...</td>\n",
       "      <td>@@ -0,0 +1,71 @@\\n+# train_and_merge.py\\n+from...</td>\n",
       "      <td>add examples to train_and_merge</td>\n",
       "      <td>@@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...</td>\n",
       "      <td>add test for merged model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>9050d6f5278e2373e66d17fc9ac8c2ec4f986e7e</td>\n",
       "      <td>Roland Tannous</td>\n",
       "      <td>tests for mxfp4 and quantized models merge fix...</td>\n",
       "      <td>test_merge_4bit_validation.py</td>\n",
       "      <td>ADD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>from unsloth import FastLanguageModel\\nfrom un...</td>\n",
       "      <td>@@ -0,0 +1,223 @@\\n+from unsloth import FastLa...</td>\n",
       "      <td>add test case for formatting prompts</td>\n",
       "      <td>@@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...</td>\n",
       "      <td>add test for merged model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>12737e503d32fc1464f8e38536be96d92db4f7d8</td>\n",
       "      <td>stevenxdavis</td>\n",
       "      <td>Fix incorrect function call in test_qwen3_grpo...</td>\n",
       "      <td>test_qwen3_grpo.py</td>\n",
       "      <td>MODIFY</td>\n",
       "      <td>from unsloth import FastLanguageModel\\nimport ...</td>\n",
       "      <td>from unsloth import FastLanguageModel\\nimport ...</td>\n",
       "      <td>@@ -415,7 +415,8 @@ sampling_params = Sampling...</td>\n",
       "      <td>update sample_params.rb</td>\n",
       "      <td>@@ -415,7 +415,8 @@ sampling_params = Sampling...</td>\n",
       "      <td>fast_generate example</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1235 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Hash          Author  \\\n",
       "0     4b97a810b509c93f44be4c037c7aa18fb8922884      Daniel Han   \n",
       "1     4b97a810b509c93f44be4c037c7aa18fb8922884      Daniel Han   \n",
       "2     4b97a810b509c93f44be4c037c7aa18fb8922884      Daniel Han   \n",
       "3     4b97a810b509c93f44be4c037c7aa18fb8922884      Daniel Han   \n",
       "4     4b97a810b509c93f44be4c037c7aa18fb8922884      Daniel Han   \n",
       "...                                        ...             ...   \n",
       "1230  9050d6f5278e2373e66d17fc9ac8c2ec4f986e7e  Roland Tannous   \n",
       "1231  9050d6f5278e2373e66d17fc9ac8c2ec4f986e7e  Roland Tannous   \n",
       "1232  9050d6f5278e2373e66d17fc9ac8c2ec4f986e7e  Roland Tannous   \n",
       "1233  9050d6f5278e2373e66d17fc9ac8c2ec4f986e7e  Roland Tannous   \n",
       "1234  12737e503d32fc1464f8e38536be96d92db4f7d8    stevenxdavis   \n",
       "\n",
       "                                                Message  \\\n",
       "0     Pre-release 2023 December version (Mistral, Pr...   \n",
       "1     Pre-release 2023 December version (Mistral, Pr...   \n",
       "2     Pre-release 2023 December version (Mistral, Pr...   \n",
       "3     Pre-release 2023 December version (Mistral, Pr...   \n",
       "4     Pre-release 2023 December version (Mistral, Pr...   \n",
       "...                                                 ...   \n",
       "1230  tests for mxfp4 and quantized models merge fix...   \n",
       "1231  tests for mxfp4 and quantized models merge fix...   \n",
       "1232  tests for mxfp4 and quantized models merge fix...   \n",
       "1233  tests for mxfp4 and quantized models merge fix...   \n",
       "1234  Fix incorrect function call in test_qwen3_grpo...   \n",
       "\n",
       "                           Filename Change Type  \\\n",
       "0                         README.md      MODIFY   \n",
       "1                       Discord.png      MODIFY   \n",
       "2                    LAION 2GPU.png         ADD   \n",
       "3                    LAION 2GPU.svg      DELETE   \n",
       "4                 SlimOrca 1GPU.svg      DELETE   \n",
       "...                             ...         ...   \n",
       "1230                    run_test.sh         ADD   \n",
       "1231           test_merged_model.py         ADD   \n",
       "1232             train_and_merge.py         ADD   \n",
       "1233  test_merge_4bit_validation.py         ADD   \n",
       "1234             test_qwen3_grpo.py      MODIFY   \n",
       "\n",
       "                                   Source Code (before)  \\\n",
       "0     <div class=\"align-center\">\\n  <img src=\"./imag...   \n",
       "1                                            PNG\\r\\n\u001a\\n   \n",
       "2                                                   NaN   \n",
       "3     <?xml version=\"1.0\" encoding=\"utf-8\" standalon...   \n",
       "4     <?xml version=\"1.0\" encoding=\"utf-8\" standalon...   \n",
       "...                                                 ...   \n",
       "1230                                                NaN   \n",
       "1231                                                NaN   \n",
       "1232                                                NaN   \n",
       "1233                                                NaN   \n",
       "1234  from unsloth import FastLanguageModel\\nimport ...   \n",
       "\n",
       "                                  Source Code (current)  \\\n",
       "0     <div class=\"align-center\">\\n  <img src=\"./imag...   \n",
       "1                                            PNG\\r\\n\u001a\\n   \n",
       "2                                            PNG\\r\\n\u001a\\n   \n",
       "3                                                   NaN   \n",
       "4                                                   NaN   \n",
       "...                                                 ...   \n",
       "1230  #!/bin/bash\\nset -e\\n\\necho \"=================...   \n",
       "1231  # inference_on_merged.py\\nfrom unsloth import ...   \n",
       "1232  # train_and_merge.py\\nfrom unsloth import Fast...   \n",
       "1233  from unsloth import FastLanguageModel\\nfrom un...   \n",
       "1234  from unsloth import FastLanguageModel\\nimport ...   \n",
       "\n",
       "                                                   Diff  \\\n",
       "0     @@ -1,23 +1,25 @@\\n <div class=\"align-center\">...   \n",
       "1     Binary files a/images/Discord.png and b/images...   \n",
       "2     Binary files /dev/null and b/images/LAION 2GPU...   \n",
       "3     @@ -1,1518 +0,0 @@\\n-<?xml version=\"1.0\" encod...   \n",
       "4     @@ -1,1424 +0,0 @@\\n-<?xml version=\"1.0\" encod...   \n",
       "...                                                 ...   \n",
       "1230  @@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...   \n",
       "1231  @@ -0,0 +1,55 @@\\n+# inference_on_merged.py\\n+...   \n",
       "1232  @@ -0,0 +1,71 @@\\n+# train_and_merge.py\\n+from...   \n",
       "1233  @@ -0,0 +1,223 @@\\n+from unsloth import FastLa...   \n",
       "1234  @@ -415,7 +415,8 @@ sampling_params = Sampling...   \n",
       "\n",
       "                                       LLM_inference  \\\n",
       "0                    add more info about nvidia gpus   \n",
       "1                                distro binary files   \n",
       "2                   distinguish 2gpu image from null   \n",
       "3     add missing missing nodes in skeleton skeleton   \n",
       "4                   add missing missing svg elements   \n",
       "...                                              ...   \n",
       "1230                                add missing line   \n",
       "1231                              add test for merge   \n",
       "1232                 add examples to train_and_merge   \n",
       "1233            add test case for formatting prompts   \n",
       "1234                         update sample_params.rb   \n",
       "\n",
       "                                           Overall_diff  \\\n",
       "0     @@ -1,23 +1,25 @@\\n <div class=\"align-center\">...   \n",
       "1     @@ -1,23 +1,25 @@\\n <div class=\"align-center\">...   \n",
       "2     @@ -1,23 +1,25 @@\\n <div class=\"align-center\">...   \n",
       "3     @@ -1,23 +1,25 @@\\n <div class=\"align-center\">...   \n",
       "4     @@ -1,23 +1,25 @@\\n <div class=\"align-center\">...   \n",
       "...                                                 ...   \n",
       "1230  @@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...   \n",
       "1231  @@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...   \n",
       "1232  @@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...   \n",
       "1233  @@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...   \n",
       "1234  @@ -415,7 +415,8 @@ sampling_params = Sampling...   \n",
       "\n",
       "                    Rectified Message  \n",
       "0     add more info about nvidia gpus  \n",
       "1     add more info about nvidia gpus  \n",
       "2     add more info about nvidia gpus  \n",
       "3     add more info about nvidia gpus  \n",
       "4     add more info about nvidia gpus  \n",
       "...                               ...  \n",
       "1230        add test for merged model  \n",
       "1231        add test for merged model  \n",
       "1232        add test for merged model  \n",
       "1233        add test for merged model  \n",
       "1234            fast_generate example  \n",
       "\n",
       "[1235 rows x 11 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "new_df = pd.read_csv('/kaggle/input/stt-labs/final_analysis (1).csv')\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T06:55:44.270520Z",
     "iopub.status.busy": "2025-09-06T06:55:44.269875Z",
     "iopub.status.idle": "2025-09-06T06:55:44.324471Z",
     "shell.execute_reply": "2025-09-06T06:55:44.323730Z",
     "shell.execute_reply.started": "2025-09-06T06:55:44.270495Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hash</th>\n",
       "      <th>Overall_diff</th>\n",
       "      <th>Message</th>\n",
       "      <th>Filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4b97a810b509c93f44be4c037c7aa18fb8922884</td>\n",
       "      <td>@@ -1,23 +1,25 @@\\n &lt;div class=\"align-center\"&gt;...</td>\n",
       "      <td>Pre-release 2023 December version (Mistral, Pr...</td>\n",
       "      <td>[README.md, Discord.png, LAION 2GPU.png, LAION...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2d5d88487463e76f75002be3b2704267ec96e68a</td>\n",
       "      <td>@@ -19,6 +19,14 @@ import warnings\\n import gc...</td>\n",
       "      <td>tokenizer pad fix</td>\n",
       "      <td>[_utils.py, llama.py, mistral.py]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f380cc1170447800c112dc8568bdff3dd34c79a3</td>\n",
       "      <td>@@ -7,7 +7,7 @@\\n ## 2-5x faster 60% less memo...</td>\n",
       "      <td>Fix Mistral\\n\\nBlockDiagonalCausalMask fix cou...</td>\n",
       "      <td>[README.md, mistral.py]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>de855c2afa68ada67d8b3caad4eb9bb592bf4a4f</td>\n",
       "      <td>@@ -33,7 +33,7 @@ If you trained a model with ...</td>\n",
       "      <td>Small fixes (#48)\\n\\n* Fix generation for GQA\\...</td>\n",
       "      <td>[README.md, unsloth made with love.png, unslot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51dd120e354cd2223df7ebe2240fb6d1a76108c5</td>\n",
       "      <td>@@ -369,6 +369,7 @@ def LlamaModel_fast_forwar...</td>\n",
       "      <td>Fix RoPE Scaling issues (#52)\\n\\n* Fix RoPE Sc...</td>\n",
       "      <td>[llama.py, mistral.py]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>26601f9d42b4c416efa59a062665c858b94c8673</td>\n",
       "      <td>@@ -37,7 +37,7 @@ triton = [\\n ]\\n \\n huggingf...</td>\n",
       "      <td>Bug fixes (#3195)\\n\\n* Fix mamba\\n\\n* Update l...</td>\n",
       "      <td>[pyproject.toml, __init__.py, import_fixes.py,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>e45ddb55a7193be9df23bd72f7396849a0089b2b</td>\n",
       "      <td>@@ -185,7 +185,15 @@ def Qwen3Attention_fast_f...</td>\n",
       "      <td>fix is casual for qwen3 (#3213)</td>\n",
       "      <td>[qwen3.py]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>b753ec05c1ae49ab2fedc0e252f73c829e36b442</td>\n",
       "      <td>@@ -149,9 +149,6 @@ class FastLanguageModel(Fa...</td>\n",
       "      <td>GPT OSS Bug fixes (#3231)\\n\\n* Update rl.py\\n\\...</td>\n",
       "      <td>[loader.py, rl.py]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>9050d6f5278e2373e66d17fc9ac8c2ec4f986e7e</td>\n",
       "      <td>@@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...</td>\n",
       "      <td>tests for mxfp4 and quantized models merge fix...</td>\n",
       "      <td>[run_test.sh, test_merged_model.py, train_and_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>12737e503d32fc1464f8e38536be96d92db4f7d8</td>\n",
       "      <td>@@ -415,7 +415,8 @@ sampling_params = Sampling...</td>\n",
       "      <td>Fix incorrect function call in test_qwen3_grpo...</td>\n",
       "      <td>[test_qwen3_grpo.py]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>346 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Hash  \\\n",
       "0    4b97a810b509c93f44be4c037c7aa18fb8922884   \n",
       "1    2d5d88487463e76f75002be3b2704267ec96e68a   \n",
       "2    f380cc1170447800c112dc8568bdff3dd34c79a3   \n",
       "3    de855c2afa68ada67d8b3caad4eb9bb592bf4a4f   \n",
       "4    51dd120e354cd2223df7ebe2240fb6d1a76108c5   \n",
       "..                                        ...   \n",
       "341  26601f9d42b4c416efa59a062665c858b94c8673   \n",
       "342  e45ddb55a7193be9df23bd72f7396849a0089b2b   \n",
       "343  b753ec05c1ae49ab2fedc0e252f73c829e36b442   \n",
       "344  9050d6f5278e2373e66d17fc9ac8c2ec4f986e7e   \n",
       "345  12737e503d32fc1464f8e38536be96d92db4f7d8   \n",
       "\n",
       "                                          Overall_diff  \\\n",
       "0    @@ -1,23 +1,25 @@\\n <div class=\"align-center\">...   \n",
       "1    @@ -19,6 +19,14 @@ import warnings\\n import gc...   \n",
       "2    @@ -7,7 +7,7 @@\\n ## 2-5x faster 60% less memo...   \n",
       "3    @@ -33,7 +33,7 @@ If you trained a model with ...   \n",
       "4    @@ -369,6 +369,7 @@ def LlamaModel_fast_forwar...   \n",
       "..                                                 ...   \n",
       "341  @@ -37,7 +37,7 @@ triton = [\\n ]\\n \\n huggingf...   \n",
       "342  @@ -185,7 +185,15 @@ def Qwen3Attention_fast_f...   \n",
       "343  @@ -149,9 +149,6 @@ class FastLanguageModel(Fa...   \n",
       "344  @@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...   \n",
       "345  @@ -415,7 +415,8 @@ sampling_params = Sampling...   \n",
       "\n",
       "                                               Message  \\\n",
       "0    Pre-release 2023 December version (Mistral, Pr...   \n",
       "1                                    tokenizer pad fix   \n",
       "2    Fix Mistral\\n\\nBlockDiagonalCausalMask fix cou...   \n",
       "3    Small fixes (#48)\\n\\n* Fix generation for GQA\\...   \n",
       "4    Fix RoPE Scaling issues (#52)\\n\\n* Fix RoPE Sc...   \n",
       "..                                                 ...   \n",
       "341  Bug fixes (#3195)\\n\\n* Fix mamba\\n\\n* Update l...   \n",
       "342                    fix is casual for qwen3 (#3213)   \n",
       "343  GPT OSS Bug fixes (#3231)\\n\\n* Update rl.py\\n\\...   \n",
       "344  tests for mxfp4 and quantized models merge fix...   \n",
       "345  Fix incorrect function call in test_qwen3_grpo...   \n",
       "\n",
       "                                              Filename  \n",
       "0    [README.md, Discord.png, LAION 2GPU.png, LAION...  \n",
       "1                    [_utils.py, llama.py, mistral.py]  \n",
       "2                              [README.md, mistral.py]  \n",
       "3    [README.md, unsloth made with love.png, unslot...  \n",
       "4                               [llama.py, mistral.py]  \n",
       "..                                                 ...  \n",
       "341  [pyproject.toml, __init__.py, import_fixes.py,...  \n",
       "342                                         [qwen3.py]  \n",
       "343                                 [loader.py, rl.py]  \n",
       "344  [run_test.sh, test_merged_model.py, train_and_...  \n",
       "345                               [test_qwen3_grpo.py]  \n",
       "\n",
       "[346 rows x 4 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "req_df = new_df.groupby(['Hash','Overall_diff','Message'],sort=False)['Filename'].agg(list).reset_index()\n",
    "req_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T06:57:56.800821Z",
     "iopub.status.busy": "2025-09-06T06:57:56.800126Z",
     "iopub.status.idle": "2025-09-06T06:57:56.815014Z",
     "shell.execute_reply": "2025-09-06T06:57:56.814368Z",
     "shell.execute_reply.started": "2025-09-06T06:57:56.800795Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15301.382225433526"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(req_df)):\n",
    "    length += len(req_df.iloc[i]['Overall_diff'])\n",
    "    # print(len(req_df.iloc[i]['Message']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T07:10:57.783618Z",
     "iopub.status.busy": "2025-09-06T07:10:57.782865Z",
     "iopub.status.idle": "2025-09-06T07:48:26.946611Z",
     "shell.execute_reply": "2025-09-06T07:48:26.945991Z",
     "shell.execute_reply.started": "2025-09-06T07:10:57.783592Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   0%|          | 0/35 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 10 : 68.51 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   3%|▎         | 1/35 [01:14<42:12, 74.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 10 : 67.7 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   6%|▌         | 2/35 [02:22<38:55, 70.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 10 : 66.67 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   9%|▊         | 3/35 [03:29<36:53, 69.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 10 : 66.51 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  11%|█▏        | 4/35 [04:36<35:18, 68.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 10 : 63.51 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  14%|█▍        | 5/35 [05:41<33:24, 66.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 10 : 65.93 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  17%|█▋        | 6/35 [06:47<32:13, 66.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 10 : 66.96 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  20%|██        | 7/35 [07:54<31:13, 66.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 10 : 66.81 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  23%|██▎       | 8/35 [09:02<30:10, 67.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 10 : 67.4 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  26%|██▌       | 9/35 [10:10<29:10, 67.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 10 : 67.02 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  29%|██▊       | 10/35 [11:17<28:04, 67.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 10 : 66.83 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  31%|███▏      | 11/35 [12:25<26:56, 67.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 10 : 67.2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  34%|███▍      | 12/35 [13:32<25:51, 67.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 10 : 66.28 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  37%|███▋      | 13/35 [14:39<24:39, 67.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 10 : 66.97 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  40%|████      | 14/35 [15:46<23:33, 67.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 10 : 67.3 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  43%|████▎     | 15/35 [16:54<22:29, 67.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 10 : 66.61 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  46%|████▌     | 16/35 [18:01<21:19, 67.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 10 : 66.71 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  49%|████▊     | 17/35 [19:09<20:11, 67.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 10 : 54.28 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  51%|█████▏    | 18/35 [20:03<18:00, 63.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 10 : 66.55 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  54%|█████▍    | 19/35 [21:10<17:13, 64.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 10 : 66.81 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  57%|█████▋    | 20/35 [22:18<16:20, 65.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 10 : 66.5 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  60%|██████    | 21/35 [23:25<15:22, 65.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 10 : 67.01 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  63%|██████▎   | 22/35 [24:32<14:22, 66.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 10 : 60.06 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  66%|██████▌   | 23/35 [25:33<12:55, 64.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 10 : 58.06 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  69%|██████▊   | 24/35 [26:31<11:30, 62.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 10 : 55.22 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  71%|███████▏  | 25/35 [27:27<10:06, 60.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 10 : 63.57 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  74%|███████▍  | 26/35 [28:31<09:14, 61.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 10 : 66.54 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  77%|███████▋  | 27/35 [29:38<08:26, 63.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 10 : 66.26 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  80%|████████  | 28/35 [30:45<07:30, 64.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 10 : 66.69 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  83%|████████▎ | 29/35 [31:52<06:30, 65.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 10 : 66.96 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  86%|████████▌ | 30/35 [32:59<05:29, 65.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 10 : 60.07 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  89%|████████▊ | 31/35 [34:00<04:17, 64.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 10 : 67.09 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  91%|█████████▏| 32/35 [35:07<03:15, 65.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 10 : 66.18 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  94%|█████████▍| 33/35 [36:14<02:11, 65.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 10 : 66.83 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  97%|█████████▋| 34/35 [37:21<01:06, 66.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 1 : 7.13 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 35/35 [37:29<00:00, 64.26s/it]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "for i in tqdm(range(5, len(req_df), BATCH_SIZE), desc=\"Processing batches\"):\n",
    "    batch_msgs = req_df[\"Message\"].iloc[i:i+BATCH_SIZE].tolist()\n",
    "    batch_diffs = req_df[\"Overall_diff\"].iloc[i:i+BATCH_SIZE].tolist()\n",
    "\n",
    "    preds = predict_batch(model, tokenizer, batch_msgs, batch_diffs, device=\"cuda\")\n",
    "\n",
    "    req_df.loc[i:i+len(preds)-1, \"New Rectified Message\"] = preds\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T08:01:55.299153Z",
     "iopub.status.busy": "2025-09-06T08:01:55.298631Z",
     "iopub.status.idle": "2025-09-06T08:01:55.425976Z",
     "shell.execute_reply": "2025-09-06T08:01:55.425386Z",
     "shell.execute_reply.started": "2025-09-06T08:01:55.299129Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "req_df.to_csv('Final_rectification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "req_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-09-06T06:50:57.140167Z",
     "iopub.status.busy": "2025-09-06T06:50:57.139921Z",
     "iopub.status.idle": "2025-09-06T06:50:57.227065Z",
     "shell.execute_reply": "2025-09-06T06:50:57.226356Z",
     "shell.execute_reply.started": "2025-09-06T06:50:57.140149Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "466\n",
      "1\n",
      "466\n",
      "2\n",
      "466\n",
      "3\n",
      "466\n",
      "4\n",
      "466\n",
      "5\n",
      "466\n",
      "6\n",
      "466\n",
      "7\n",
      "466\n",
      "8\n",
      "466\n",
      "9\n",
      "466\n",
      "10\n",
      "466\n",
      "11\n",
      "466\n",
      "12\n",
      "17\n",
      "13\n",
      "17\n",
      "14\n",
      "17\n",
      "15\n",
      "76\n",
      "16\n",
      "76\n",
      "17\n",
      "266\n",
      "18\n",
      "266\n",
      "19\n",
      "266\n",
      "20\n",
      "266\n",
      "21\n",
      "266\n",
      "22\n",
      "266\n",
      "23\n",
      "266\n",
      "24\n",
      "91\n",
      "25\n",
      "91\n",
      "26\n",
      "344\n",
      "27\n",
      "344\n",
      "28\n",
      "344\n",
      "29\n",
      "344\n",
      "30\n",
      "344\n",
      "31\n",
      "344\n",
      "32\n",
      "472\n",
      "33\n",
      "472\n",
      "34\n",
      "472\n",
      "35\n",
      "526\n",
      "36\n",
      "526\n",
      "37\n",
      "526\n",
      "38\n",
      "526\n",
      "39\n",
      "17\n",
      "40\n",
      "17\n",
      "41\n",
      "320\n",
      "42\n",
      "320\n",
      "43\n",
      "320\n",
      "44\n",
      "320\n",
      "45\n",
      "13\n",
      "46\n",
      "13\n",
      "47\n",
      "13\n",
      "48\n",
      "325\n",
      "49\n",
      "325\n",
      "50\n",
      "325\n",
      "51\n",
      "325\n",
      "52\n",
      "325\n",
      "53\n",
      "1627\n",
      "54\n",
      "1627\n",
      "55\n",
      "1627\n",
      "56\n",
      "1627\n",
      "57\n",
      "1627\n",
      "58\n",
      "1627\n",
      "59\n",
      "1627\n",
      "60\n",
      "1627\n",
      "61\n",
      "1627\n",
      "62\n",
      "1765\n",
      "63\n",
      "1765\n",
      "64\n",
      "1765\n",
      "65\n",
      "1765\n",
      "66\n",
      "1765\n",
      "67\n",
      "1781\n",
      "68\n",
      "1781\n",
      "69\n",
      "1898\n",
      "70\n",
      "1898\n",
      "71\n",
      "1898\n",
      "72\n",
      "1898\n",
      "73\n",
      "2230\n",
      "74\n",
      "2230\n",
      "75\n",
      "2230\n",
      "76\n",
      "2230\n",
      "77\n",
      "2363\n",
      "78\n",
      "295\n",
      "79\n",
      "295\n",
      "80\n",
      "295\n",
      "81\n",
      "1355\n",
      "82\n",
      "1355\n",
      "83\n",
      "1355\n",
      "84\n",
      "1355\n",
      "85\n",
      "1355\n",
      "86\n",
      "1355\n",
      "87\n",
      "1355\n",
      "88\n",
      "1355\n",
      "89\n",
      "2584\n",
      "90\n",
      "2584\n",
      "91\n",
      "2584\n",
      "92\n",
      "2724\n",
      "93\n",
      "3396\n",
      "94\n",
      "3396\n",
      "95\n",
      "3396\n",
      "96\n",
      "3396\n",
      "97\n",
      "3415\n",
      "98\n",
      "3869\n",
      "99\n",
      "3869\n",
      "100\n",
      "3869\n",
      "101\n",
      "3869\n",
      "102\n",
      "3933\n",
      "103\n",
      "3933\n",
      "104\n",
      "3996\n",
      "105\n",
      "4441\n",
      "106\n",
      "4441\n",
      "107\n",
      "4441\n",
      "108\n",
      "4441\n",
      "109\n",
      "4441\n",
      "110\n",
      "63464\n",
      "111\n",
      "63464\n",
      "112\n",
      "63464\n",
      "113\n",
      "63464\n",
      "114\n",
      "63464\n",
      "115\n",
      "5086\n",
      "116\n",
      "5086\n",
      "117\n",
      "5086\n",
      "118\n",
      "5086\n",
      "119\n",
      "5086\n",
      "120\n",
      "5086\n",
      "121\n",
      "5086\n",
      "122\n",
      "5086\n",
      "123\n",
      "4964\n",
      "124\n",
      "4964\n",
      "125\n",
      "4964\n",
      "126\n",
      "4964\n",
      "127\n",
      "4964\n",
      "128\n",
      "4964\n",
      "129\n",
      "4964\n",
      "130\n",
      "4964\n",
      "131\n",
      "4964\n",
      "132\n",
      "5520\n",
      "133\n",
      "5520\n",
      "134\n",
      "5520\n",
      "135\n",
      "5520\n",
      "136\n",
      "5520\n",
      "137\n",
      "5520\n",
      "138\n",
      "5520\n",
      "139\n",
      "5520\n",
      "140\n",
      "5520\n",
      "141\n",
      "5520\n",
      "142\n",
      "5520\n",
      "143\n",
      "5520\n",
      "144\n",
      "5520\n",
      "145\n",
      "5520\n",
      "146\n",
      "5533\n",
      "147\n",
      "5533\n",
      "148\n",
      "10997\n",
      "149\n",
      "11013\n",
      "150\n",
      "11013\n",
      "151\n",
      "11013\n",
      "152\n",
      "11013\n",
      "153\n",
      "11013\n",
      "154\n",
      "11013\n",
      "155\n",
      "11013\n",
      "156\n",
      "11013\n",
      "157\n",
      "10989\n",
      "158\n",
      "11026\n",
      "159\n",
      "11022\n",
      "160\n",
      "11022\n",
      "161\n",
      "11022\n",
      "162\n",
      "11022\n",
      "163\n",
      "11022\n",
      "164\n",
      "11022\n",
      "165\n",
      "11022\n",
      "166\n",
      "11022\n",
      "167\n",
      "11009\n",
      "168\n",
      "11009\n",
      "169\n",
      "11009\n",
      "170\n",
      "11009\n",
      "171\n",
      "11009\n",
      "172\n",
      "10929\n",
      "173\n",
      "10929\n",
      "174\n",
      "10911\n",
      "175\n",
      "10911\n",
      "176\n",
      "10911\n",
      "177\n",
      "10911\n",
      "178\n",
      "10939\n",
      "179\n",
      "10939\n",
      "180\n",
      "10939\n",
      "181\n",
      "10939\n",
      "182\n",
      "10939\n",
      "183\n",
      "10939\n",
      "184\n",
      "10980\n",
      "185\n",
      "10934\n",
      "186\n",
      "10934\n",
      "187\n",
      "10934\n",
      "188\n",
      "10934\n",
      "189\n",
      "10934\n",
      "190\n",
      "10916\n",
      "191\n",
      "10916\n",
      "192\n",
      "132412\n",
      "193\n",
      "10881\n",
      "194\n",
      "10881\n",
      "195\n",
      "10881\n",
      "196\n",
      "10841\n",
      "197\n",
      "10841\n",
      "198\n",
      "10841\n",
      "199\n",
      "10841\n",
      "200\n",
      "10795\n",
      "201\n",
      "10795\n",
      "202\n",
      "10795\n",
      "203\n",
      "10777\n",
      "204\n",
      "10870\n",
      "205\n",
      "10870\n",
      "206\n",
      "10870\n",
      "207\n",
      "10870\n",
      "208\n",
      "10870\n",
      "209\n",
      "10870\n",
      "210\n",
      "10870\n",
      "211\n",
      "10870\n",
      "212\n",
      "10870\n",
      "213\n",
      "10824\n",
      "214\n",
      "10824\n",
      "215\n",
      "10824\n",
      "216\n",
      "103\n",
      "217\n",
      "103\n",
      "218\n",
      "103\n",
      "219\n",
      "10532\n",
      "220\n",
      "10532\n",
      "221\n",
      "10532\n",
      "222\n",
      "10532\n",
      "223\n",
      "10505\n",
      "224\n",
      "10505\n",
      "225\n",
      "10505\n",
      "226\n",
      "19\n",
      "227\n",
      "19\n",
      "228\n",
      "5056\n",
      "229\n",
      "5056\n",
      "230\n",
      "5056\n",
      "231\n",
      "5056\n",
      "232\n",
      "5056\n",
      "233\n",
      "5093\n",
      "234\n",
      "5093\n",
      "235\n",
      "5093\n",
      "236\n",
      "5093\n",
      "237\n",
      "5073\n",
      "238\n",
      "5073\n",
      "239\n",
      "5073\n",
      "240\n",
      "5073\n",
      "241\n",
      "5018\n",
      "242\n",
      "5018\n",
      "243\n",
      "5052\n",
      "244\n",
      "5014\n",
      "245\n",
      "5014\n",
      "246\n",
      "5014\n",
      "247\n",
      "5014\n",
      "248\n",
      "158\n",
      "249\n",
      "4975\n",
      "250\n",
      "4975\n",
      "251\n",
      "4975\n",
      "252\n",
      "4975\n",
      "253\n",
      "4975\n",
      "254\n",
      "4975\n",
      "255\n",
      "432\n",
      "256\n",
      "432\n",
      "257\n",
      "432\n",
      "258\n",
      "432\n",
      "259\n",
      "432\n",
      "260\n",
      "985\n",
      "261\n",
      "985\n",
      "262\n",
      "985\n",
      "263\n",
      "985\n",
      "264\n",
      "985\n",
      "265\n",
      "985\n",
      "266\n",
      "985\n",
      "267\n",
      "1390\n",
      "268\n",
      "1390\n",
      "269\n",
      "1596\n",
      "270\n",
      "1596\n",
      "271\n",
      "1596\n",
      "272\n",
      "1704\n",
      "273\n",
      "1704\n",
      "274\n",
      "1704\n",
      "275\n",
      "2643\n",
      "276\n",
      "2643\n",
      "277\n",
      "2643\n",
      "278\n",
      "2643\n",
      "279\n",
      "2643\n",
      "280\n",
      "2643\n",
      "281\n",
      "2643\n",
      "282\n",
      "2643\n",
      "283\n",
      "2643\n",
      "284\n",
      "2643\n",
      "285\n",
      "2643\n",
      "286\n",
      "2846\n",
      "287\n",
      "2846\n",
      "288\n",
      "2846\n",
      "289\n",
      "2846\n",
      "290\n",
      "2846\n",
      "291\n",
      "3103\n",
      "292\n",
      "3103\n",
      "293\n",
      "3103\n",
      "294\n",
      "3103\n",
      "295\n",
      "17\n",
      "296\n",
      "17\n",
      "297\n",
      "345\n",
      "298\n",
      "99\n",
      "299\n",
      "99\n",
      "300\n",
      "587\n",
      "301\n",
      "61\n",
      "302\n",
      "5998\n",
      "303\n",
      "5998\n",
      "304\n",
      "5998\n",
      "305\n",
      "5998\n",
      "306\n",
      "5998\n",
      "307\n",
      "5998\n",
      "308\n",
      "5998\n",
      "309\n",
      "5998\n",
      "310\n",
      "5998\n",
      "311\n",
      "6522\n",
      "312\n",
      "6522\n",
      "313\n",
      "6522\n",
      "314\n",
      "6522\n",
      "315\n",
      "6686\n",
      "316\n",
      "6686\n",
      "317\n",
      "6686\n",
      "318\n",
      "6749\n",
      "319\n",
      "6749\n",
      "320\n",
      "6749\n",
      "321\n",
      "6749\n",
      "322\n",
      "6845\n",
      "323\n",
      "6845\n",
      "324\n",
      "6845\n",
      "325\n",
      "6845\n",
      "326\n",
      "6845\n",
      "327\n",
      "7005\n",
      "328\n",
      "7005\n",
      "329\n",
      "7005\n",
      "330\n",
      "15560\n",
      "331\n",
      "15869\n",
      "332\n",
      "15869\n",
      "333\n",
      "16317\n",
      "334\n",
      "16317\n",
      "335\n",
      "16317\n",
      "336\n",
      "16317\n",
      "337\n",
      "16573\n",
      "338\n",
      "16573\n",
      "339\n",
      "16573\n",
      "340\n",
      "16683\n",
      "341\n",
      "16716\n",
      "342\n",
      "16716\n",
      "343\n",
      "16716\n",
      "344\n",
      "16716\n",
      "345\n",
      "16941\n",
      "346\n",
      "16941\n",
      "347\n",
      "16941\n",
      "348\n",
      "16980\n",
      "349\n",
      "16980\n",
      "350\n",
      "16980\n",
      "351\n",
      "16980\n",
      "352\n",
      "16980\n",
      "353\n",
      "16980\n",
      "354\n",
      "16980\n",
      "355\n",
      "16980\n",
      "356\n",
      "16980\n",
      "357\n",
      "16980\n",
      "358\n",
      "16980\n",
      "359\n",
      "16980\n",
      "360\n",
      "16980\n",
      "361\n",
      "16980\n",
      "362\n",
      "16980\n",
      "363\n",
      "16980\n",
      "364\n",
      "16980\n",
      "365\n",
      "439\n",
      "366\n",
      "439\n",
      "367\n",
      "439\n",
      "368\n",
      "439\n",
      "369\n",
      "1053\n",
      "370\n",
      "1053\n",
      "371\n",
      "1053\n",
      "372\n",
      "1053\n",
      "373\n",
      "1053\n",
      "374\n",
      "1053\n",
      "375\n",
      "1053\n",
      "376\n",
      "1053\n",
      "377\n",
      "1219\n",
      "378\n",
      "1219\n",
      "379\n",
      "1219\n",
      "380\n",
      "1219\n",
      "381\n",
      "1551\n",
      "382\n",
      "1551\n",
      "383\n",
      "1551\n",
      "384\n",
      "1551\n",
      "385\n",
      "1551\n",
      "386\n",
      "1588\n",
      "387\n",
      "1708\n",
      "388\n",
      "1708\n",
      "389\n",
      "1708\n",
      "390\n",
      "1708\n",
      "391\n",
      "1708\n",
      "392\n",
      "1708\n",
      "393\n",
      "1708\n",
      "394\n",
      "1708\n",
      "395\n",
      "1708\n",
      "396\n",
      "1708\n",
      "397\n",
      "2445\n",
      "398\n",
      "2445\n",
      "399\n",
      "2445\n",
      "400\n",
      "2445\n",
      "401\n",
      "2445\n",
      "402\n",
      "2445\n",
      "403\n",
      "3583\n",
      "404\n",
      "3583\n",
      "405\n",
      "3583\n",
      "406\n",
      "3583\n",
      "407\n",
      "3583\n",
      "408\n",
      "3583\n",
      "409\n",
      "3583\n",
      "410\n",
      "3583\n",
      "411\n",
      "3583\n",
      "412\n",
      "3583\n",
      "413\n",
      "3583\n",
      "414\n",
      "3583\n",
      "415\n",
      "228\n",
      "416\n",
      "228\n",
      "417\n",
      "228\n",
      "418\n",
      "228\n",
      "419\n",
      "228\n",
      "420\n",
      "10\n",
      "421\n",
      "10\n",
      "422\n",
      "478\n",
      "423\n",
      "478\n",
      "424\n",
      "478\n",
      "425\n",
      "478\n",
      "426\n",
      "478\n",
      "427\n",
      "478\n",
      "428\n",
      "478\n",
      "429\n",
      "420\n",
      "430\n",
      "420\n",
      "431\n",
      "420\n",
      "432\n",
      "420\n",
      "433\n",
      "420\n",
      "434\n",
      "345\n",
      "435\n",
      "4\n",
      "436\n",
      "4\n",
      "437\n",
      "4\n",
      "438\n",
      "224\n",
      "439\n",
      "224\n",
      "440\n",
      "224\n",
      "441\n",
      "224\n",
      "442\n",
      "224\n",
      "443\n",
      "224\n",
      "444\n",
      "224\n",
      "445\n",
      "470\n",
      "446\n",
      "844\n",
      "447\n",
      "844\n",
      "448\n",
      "140\n",
      "449\n",
      "326\n",
      "450\n",
      "326\n",
      "451\n",
      "326\n",
      "452\n",
      "326\n",
      "453\n",
      "1466\n",
      "454\n",
      "1466\n",
      "455\n",
      "1466\n",
      "456\n",
      "1466\n",
      "457\n",
      "1466\n",
      "458\n",
      "1466\n",
      "459\n",
      "1968\n",
      "460\n",
      "1968\n",
      "461\n",
      "1968\n",
      "462\n",
      "2358\n",
      "463\n",
      "2358\n",
      "464\n",
      "2358\n",
      "465\n",
      "2384\n",
      "466\n",
      "2406\n",
      "467\n",
      "2406\n",
      "468\n",
      "2599\n",
      "469\n",
      "2599\n",
      "470\n",
      "2599\n",
      "471\n",
      "9\n",
      "472\n",
      "9\n",
      "473\n",
      "9\n",
      "474\n",
      "9\n",
      "475\n",
      "307\n",
      "476\n",
      "307\n",
      "477\n",
      "307\n",
      "478\n",
      "735\n",
      "479\n",
      "735\n",
      "480\n",
      "735\n",
      "481\n",
      "735\n",
      "482\n",
      "2274\n",
      "483\n",
      "2274\n",
      "484\n",
      "2274\n",
      "485\n",
      "2274\n",
      "486\n",
      "2274\n",
      "487\n",
      "2274\n",
      "488\n",
      "2274\n",
      "489\n",
      "2274\n",
      "490\n",
      "2274\n",
      "491\n",
      "2347\n",
      "492\n",
      "2347\n",
      "493\n",
      "2347\n",
      "494\n",
      "2347\n",
      "495\n",
      "2347\n",
      "496\n",
      "7\n",
      "497\n",
      "7\n",
      "498\n",
      "9\n",
      "499\n",
      "9\n",
      "500\n",
      "3935\n",
      "501\n",
      "3935\n",
      "502\n",
      "3935\n",
      "503\n",
      "3935\n",
      "504\n",
      "3935\n",
      "505\n",
      "3935\n",
      "506\n",
      "3935\n",
      "507\n",
      "114\n",
      "508\n",
      "430\n",
      "509\n",
      "430\n",
      "510\n",
      "430\n",
      "511\n",
      "430\n",
      "512\n",
      "430\n",
      "513\n",
      "430\n",
      "514\n",
      "430\n",
      "515\n",
      "430\n",
      "516\n",
      "430\n",
      "517\n",
      "1119\n",
      "518\n",
      "1119\n",
      "519\n",
      "1119\n",
      "520\n",
      "1119\n",
      "521\n",
      "1119\n",
      "522\n",
      "268\n",
      "523\n",
      "612\n",
      "524\n",
      "612\n",
      "525\n",
      "612\n",
      "526\n",
      "612\n",
      "527\n",
      "612\n",
      "528\n",
      "612\n",
      "529\n",
      "612\n",
      "530\n",
      "319\n",
      "531\n",
      "1040\n",
      "532\n",
      "1915\n",
      "533\n",
      "1915\n",
      "534\n",
      "323\n",
      "535\n",
      "2422\n",
      "536\n",
      "2422\n",
      "537\n",
      "2422\n",
      "538\n",
      "16\n",
      "539\n",
      "16\n",
      "540\n",
      "9\n",
      "541\n",
      "9\n",
      "542\n",
      "9\n",
      "543\n",
      "9\n",
      "544\n",
      "6565\n",
      "545\n",
      "6565\n",
      "546\n",
      "6565\n",
      "547\n",
      "6565\n",
      "548\n",
      "6565\n",
      "549\n",
      "6565\n",
      "550\n",
      "6565\n",
      "551\n",
      "6565\n",
      "552\n",
      "6565\n",
      "553\n",
      "6565\n",
      "554\n",
      "6565\n",
      "555\n",
      "6565\n",
      "556\n",
      "6565\n",
      "557\n",
      "6565\n",
      "558\n",
      "6798\n",
      "559\n",
      "6910\n",
      "560\n",
      "255\n",
      "561\n",
      "253\n",
      "562\n",
      "7981\n",
      "563\n",
      "7981\n",
      "564\n",
      "7981\n",
      "565\n",
      "7981\n",
      "566\n",
      "7981\n",
      "567\n",
      "8249\n",
      "568\n",
      "8249\n",
      "569\n",
      "8249\n",
      "570\n",
      "8249\n",
      "571\n",
      "8249\n",
      "572\n",
      "8249\n",
      "573\n",
      "706\n",
      "574\n",
      "650\n",
      "575\n",
      "276\n",
      "576\n",
      "416\n",
      "577\n",
      "416\n",
      "578\n",
      "10519\n",
      "579\n",
      "10519\n",
      "580\n",
      "10519\n",
      "581\n",
      "10519\n",
      "582\n",
      "10519\n",
      "583\n",
      "257\n",
      "584\n",
      "9812\n",
      "585\n",
      "9812\n",
      "586\n",
      "9812\n",
      "587\n",
      "9812\n",
      "588\n",
      "9812\n",
      "589\n",
      "9812\n",
      "590\n",
      "9812\n",
      "591\n",
      "9812\n",
      "592\n",
      "9812\n",
      "593\n",
      "9812\n",
      "594\n",
      "9812\n",
      "595\n",
      "9812\n",
      "596\n",
      "9812\n",
      "597\n",
      "9812\n",
      "598\n",
      "5\n",
      "599\n",
      "5\n",
      "600\n",
      "8946\n",
      "601\n",
      "8946\n",
      "602\n",
      "8946\n",
      "603\n",
      "8946\n",
      "604\n",
      "8946\n",
      "605\n",
      "9195\n",
      "606\n",
      "9195\n",
      "607\n",
      "9195\n",
      "608\n",
      "9195\n",
      "609\n",
      "9195\n",
      "610\n",
      "9195\n",
      "611\n",
      "9124\n",
      "612\n",
      "9124\n",
      "613\n",
      "9124\n",
      "614\n",
      "9838\n",
      "615\n",
      "19321\n",
      "616\n",
      "19321\n",
      "617\n",
      "19321\n",
      "618\n",
      "19321\n",
      "619\n",
      "19321\n",
      "620\n",
      "19321\n",
      "621\n",
      "19321\n",
      "622\n",
      "19321\n",
      "623\n",
      "19321\n",
      "624\n",
      "78\n",
      "625\n",
      "8\n",
      "626\n",
      "8\n",
      "627\n",
      "20141\n",
      "628\n",
      "20141\n",
      "629\n",
      "20141\n",
      "630\n",
      "20141\n",
      "631\n",
      "20141\n",
      "632\n",
      "20141\n",
      "633\n",
      "20141\n",
      "634\n",
      "20141\n",
      "635\n",
      "7\n",
      "636\n",
      "7\n",
      "637\n",
      "20128\n",
      "638\n",
      "20128\n",
      "639\n",
      "20128\n",
      "640\n",
      "20128\n",
      "641\n",
      "20128\n",
      "642\n",
      "20128\n",
      "643\n",
      "20128\n",
      "644\n",
      "20128\n",
      "645\n",
      "20128\n",
      "646\n",
      "20128\n",
      "647\n",
      "7\n",
      "648\n",
      "20080\n",
      "649\n",
      "20080\n",
      "650\n",
      "649\n",
      "651\n",
      "649\n",
      "652\n",
      "649\n",
      "653\n",
      "649\n",
      "654\n",
      "649\n",
      "655\n",
      "72\n",
      "656\n",
      "72\n",
      "657\n",
      "72\n",
      "658\n",
      "58\n",
      "659\n",
      "482\n",
      "660\n",
      "33\n",
      "661\n",
      "33\n",
      "662\n",
      "220\n",
      "663\n",
      "220\n",
      "664\n",
      "220\n",
      "665\n",
      "220\n",
      "666\n",
      "220\n",
      "667\n",
      "220\n",
      "668\n",
      "319\n",
      "669\n",
      "385\n",
      "670\n",
      "385\n",
      "671\n",
      "385\n",
      "672\n",
      "4140\n",
      "673\n",
      "4140\n",
      "674\n",
      "4140\n",
      "675\n",
      "4140\n",
      "676\n",
      "4140\n",
      "677\n",
      "4140\n",
      "678\n",
      "4140\n",
      "679\n",
      "4140\n",
      "680\n",
      "4140\n",
      "681\n",
      "4140\n",
      "682\n",
      "4140\n",
      "683\n",
      "4140\n",
      "684\n",
      "4140\n",
      "685\n",
      "4140\n",
      "686\n",
      "4140\n",
      "687\n",
      "4140\n",
      "688\n",
      "240\n",
      "689\n",
      "4185\n",
      "690\n",
      "4185\n",
      "691\n",
      "4185\n",
      "692\n",
      "13\n",
      "693\n",
      "13\n",
      "694\n",
      "22\n",
      "695\n",
      "28\n",
      "696\n",
      "22\n",
      "697\n",
      "9\n",
      "698\n",
      "9\n",
      "699\n",
      "22\n",
      "700\n",
      "9\n",
      "701\n",
      "9\n",
      "702\n",
      "9\n",
      "703\n",
      "5235\n",
      "704\n",
      "5235\n",
      "705\n",
      "5235\n",
      "706\n",
      "5235\n",
      "707\n",
      "5235\n",
      "708\n",
      "5235\n",
      "709\n",
      "5235\n",
      "710\n",
      "16\n",
      "711\n",
      "16\n",
      "712\n",
      "5272\n",
      "713\n",
      "7\n",
      "714\n",
      "7\n",
      "715\n",
      "7257\n",
      "716\n",
      "7257\n",
      "717\n",
      "7257\n",
      "718\n",
      "7257\n",
      "719\n",
      "7257\n",
      "720\n",
      "7257\n",
      "721\n",
      "7257\n",
      "722\n",
      "7257\n",
      "723\n",
      "7257\n",
      "724\n",
      "7257\n",
      "725\n",
      "7257\n",
      "726\n",
      "7257\n",
      "727\n",
      "7257\n",
      "728\n",
      "7284\n",
      "729\n",
      "7284\n",
      "730\n",
      "5944\n",
      "731\n",
      "5944\n",
      "732\n",
      "5944\n",
      "733\n",
      "5944\n",
      "734\n",
      "5944\n",
      "735\n",
      "5944\n",
      "736\n",
      "5944\n",
      "737\n",
      "5430\n",
      "738\n",
      "5430\n",
      "739\n",
      "5430\n",
      "740\n",
      "5430\n",
      "741\n",
      "25\n",
      "742\n",
      "25\n",
      "743\n",
      "198\n",
      "744\n",
      "174\n",
      "745\n",
      "174\n",
      "746\n",
      "6204\n",
      "747\n",
      "6204\n",
      "748\n",
      "6204\n",
      "749\n",
      "6204\n",
      "750\n",
      "6204\n",
      "751\n",
      "6204\n",
      "752\n",
      "6204\n",
      "753\n",
      "6204\n",
      "754\n",
      "6204\n",
      "755\n",
      "6204\n",
      "756\n",
      "6204\n",
      "757\n",
      "7\n",
      "758\n",
      "7\n",
      "759\n",
      "6240\n",
      "760\n",
      "6240\n",
      "761\n",
      "6240\n",
      "762\n",
      "6240\n",
      "763\n",
      "597\n",
      "764\n",
      "230\n",
      "765\n",
      "230\n",
      "766\n",
      "98\n",
      "767\n",
      "171\n",
      "768\n",
      "171\n",
      "769\n",
      "171\n",
      "770\n",
      "171\n",
      "771\n",
      "171\n",
      "772\n",
      "158\n",
      "773\n",
      "158\n",
      "774\n",
      "147\n",
      "775\n",
      "9\n",
      "776\n",
      "9\n",
      "777\n",
      "9\n",
      "778\n",
      "6826\n",
      "779\n",
      "6826\n",
      "780\n",
      "6826\n",
      "781\n",
      "6826\n",
      "782\n",
      "6826\n",
      "783\n",
      "6826\n",
      "784\n",
      "6826\n",
      "785\n",
      "6826\n",
      "786\n",
      "6826\n",
      "787\n",
      "6826\n",
      "788\n",
      "6826\n",
      "789\n",
      "6826\n",
      "790\n",
      "6826\n",
      "791\n",
      "6826\n",
      "792\n",
      "6826\n",
      "793\n",
      "6826\n",
      "794\n",
      "7\n",
      "795\n",
      "7\n",
      "796\n",
      "7\n",
      "797\n",
      "7\n",
      "798\n",
      "7\n",
      "799\n",
      "7\n",
      "800\n",
      "9\n",
      "801\n",
      "9\n",
      "802\n",
      "7\n",
      "803\n",
      "7\n",
      "804\n",
      "6807\n",
      "805\n",
      "6807\n",
      "806\n",
      "6807\n",
      "807\n",
      "6807\n",
      "808\n",
      "6807\n",
      "809\n",
      "6807\n",
      "810\n",
      "6807\n",
      "811\n",
      "15\n",
      "812\n",
      "15\n",
      "813\n",
      "6739\n",
      "814\n",
      "6739\n",
      "815\n",
      "6739\n",
      "816\n",
      "6739\n",
      "817\n",
      "6739\n",
      "818\n",
      "6703\n",
      "819\n",
      "6703\n",
      "820\n",
      "6703\n",
      "821\n",
      "6703\n",
      "822\n",
      "9\n",
      "823\n",
      "9\n",
      "824\n",
      "9\n",
      "825\n",
      "303\n",
      "826\n",
      "303\n",
      "827\n",
      "303\n",
      "828\n",
      "9\n",
      "829\n",
      "9\n",
      "830\n",
      "9\n",
      "831\n",
      "6644\n",
      "832\n",
      "6644\n",
      "833\n",
      "6644\n",
      "834\n",
      "6644\n",
      "835\n",
      "6644\n",
      "836\n",
      "6644\n",
      "837\n",
      "6644\n",
      "838\n",
      "6644\n",
      "839\n",
      "173\n",
      "840\n",
      "173\n",
      "841\n",
      "31\n",
      "842\n",
      "31\n",
      "843\n",
      "31\n",
      "844\n",
      "31\n",
      "845\n",
      "31\n",
      "846\n",
      "31\n",
      "847\n",
      "31\n",
      "848\n",
      "7176\n",
      "849\n",
      "7176\n",
      "850\n",
      "7176\n",
      "851\n",
      "7176\n",
      "852\n",
      "7176\n",
      "853\n",
      "7176\n",
      "854\n",
      "7176\n",
      "855\n",
      "7176\n",
      "856\n",
      "7176\n",
      "857\n",
      "9\n",
      "858\n",
      "9\n",
      "859\n",
      "9\n",
      "860\n",
      "9\n",
      "861\n",
      "7174\n",
      "862\n",
      "7174\n",
      "863\n",
      "7174\n",
      "864\n",
      "7174\n",
      "865\n",
      "7174\n",
      "866\n",
      "7174\n",
      "867\n",
      "7174\n",
      "868\n",
      "10\n",
      "869\n",
      "10\n",
      "870\n",
      "10\n",
      "871\n",
      "223\n",
      "872\n",
      "223\n",
      "873\n",
      "8\n",
      "874\n",
      "8\n",
      "875\n",
      "6743\n",
      "876\n",
      "6743\n",
      "877\n",
      "6743\n",
      "878\n",
      "6743\n",
      "879\n",
      "6743\n",
      "880\n",
      "6743\n",
      "881\n",
      "6743\n",
      "882\n",
      "6743\n",
      "883\n",
      "6743\n",
      "884\n",
      "6743\n",
      "885\n",
      "6743\n",
      "886\n",
      "6743\n",
      "887\n",
      "6743\n",
      "888\n",
      "6743\n",
      "889\n",
      "6743\n",
      "890\n",
      "6730\n",
      "891\n",
      "6730\n",
      "892\n",
      "16\n",
      "893\n",
      "16\n",
      "894\n",
      "21\n",
      "895\n",
      "11\n",
      "896\n",
      "14\n",
      "897\n",
      "14\n",
      "898\n",
      "570\n",
      "899\n",
      "25\n",
      "900\n",
      "6549\n",
      "901\n",
      "6549\n",
      "902\n",
      "6549\n",
      "903\n",
      "6549\n",
      "904\n",
      "6549\n",
      "905\n",
      "6549\n",
      "906\n",
      "6549\n",
      "907\n",
      "6549\n",
      "908\n",
      "6549\n",
      "909\n",
      "242\n",
      "910\n",
      "6796\n",
      "911\n",
      "6796\n",
      "912\n",
      "6796\n",
      "913\n",
      "6796\n",
      "914\n",
      "6796\n",
      "915\n",
      "6796\n",
      "916\n",
      "6797\n",
      "917\n",
      "6797\n",
      "918\n",
      "314\n",
      "919\n",
      "7068\n",
      "920\n",
      "7068\n",
      "921\n",
      "7068\n",
      "922\n",
      "7068\n",
      "923\n",
      "7068\n",
      "924\n",
      "7068\n",
      "925\n",
      "7068\n",
      "926\n",
      "7068\n",
      "927\n",
      "7068\n",
      "928\n",
      "7068\n",
      "929\n",
      "7068\n",
      "930\n",
      "7\n",
      "931\n",
      "7\n",
      "932\n",
      "7\n",
      "933\n",
      "7\n",
      "934\n",
      "7034\n",
      "935\n",
      "7034\n",
      "936\n",
      "7034\n",
      "937\n",
      "7034\n",
      "938\n",
      "7034\n",
      "939\n",
      "7034\n",
      "940\n",
      "7034\n",
      "941\n",
      "7034\n",
      "942\n",
      "18\n",
      "943\n",
      "18\n",
      "944\n",
      "22\n",
      "945\n",
      "22\n",
      "946\n",
      "22\n",
      "947\n",
      "22\n",
      "948\n",
      "22\n",
      "949\n",
      "22\n",
      "950\n",
      "22\n",
      "951\n",
      "22\n",
      "952\n",
      "19\n",
      "953\n",
      "21\n",
      "954\n",
      "21\n",
      "955\n",
      "25\n",
      "956\n",
      "21\n",
      "957\n",
      "20\n",
      "958\n",
      "20\n",
      "959\n",
      "276\n",
      "960\n",
      "276\n",
      "961\n",
      "55\n",
      "962\n",
      "64\n",
      "963\n",
      "84\n",
      "964\n",
      "84\n",
      "965\n",
      "77\n",
      "966\n",
      "77\n",
      "967\n",
      "77\n",
      "968\n",
      "85\n",
      "969\n",
      "21\n",
      "970\n",
      "21\n",
      "971\n",
      "7399\n",
      "972\n",
      "7399\n",
      "973\n",
      "7399\n",
      "974\n",
      "7399\n",
      "975\n",
      "7399\n",
      "976\n",
      "7399\n",
      "977\n",
      "7399\n",
      "978\n",
      "7399\n",
      "979\n",
      "7399\n",
      "980\n",
      "7399\n",
      "981\n",
      "7399\n",
      "982\n",
      "7399\n",
      "983\n",
      "7399\n",
      "984\n",
      "7399\n",
      "985\n",
      "7399\n",
      "986\n",
      "7399\n",
      "987\n",
      "7399\n",
      "988\n",
      "7399\n",
      "989\n",
      "7399\n",
      "990\n",
      "7374\n",
      "991\n",
      "7374\n",
      "992\n",
      "7374\n",
      "993\n",
      "15\n",
      "994\n",
      "15\n",
      "995\n",
      "15\n",
      "996\n",
      "7\n",
      "997\n",
      "7\n",
      "998\n",
      "105\n",
      "999\n",
      "112\n",
      "1000\n",
      "112\n",
      "1001\n",
      "498\n",
      "1002\n",
      "498\n",
      "1003\n",
      "498\n",
      "1004\n",
      "498\n",
      "1005\n",
      "6480\n",
      "1006\n",
      "6480\n",
      "1007\n",
      "6480\n",
      "1008\n",
      "6480\n",
      "1009\n",
      "6480\n",
      "1010\n",
      "6480\n",
      "1011\n",
      "50\n",
      "1012\n",
      "125\n",
      "1013\n",
      "6450\n",
      "1014\n",
      "6450\n",
      "1015\n",
      "6450\n",
      "1016\n",
      "6450\n",
      "1017\n",
      "22\n",
      "1018\n",
      "22\n",
      "1019\n",
      "22\n",
      "1020\n",
      "22\n",
      "1021\n",
      "22\n",
      "1022\n",
      "22\n",
      "1023\n",
      "22\n",
      "1024\n",
      "22\n",
      "1025\n",
      "22\n",
      "1026\n",
      "22\n",
      "1027\n",
      "22\n",
      "1028\n",
      "22\n",
      "1029\n",
      "22\n",
      "1030\n",
      "54\n",
      "1031\n",
      "2847\n",
      "1032\n",
      "2847\n",
      "1033\n",
      "2847\n",
      "1034\n",
      "6091\n",
      "1035\n",
      "6091\n",
      "1036\n",
      "6091\n",
      "1037\n",
      "6091\n",
      "1038\n",
      "179\n",
      "1039\n",
      "6019\n",
      "1040\n",
      "6019\n",
      "1041\n",
      "6019\n",
      "1042\n",
      "22\n",
      "1043\n",
      "252\n",
      "1044\n",
      "65\n",
      "1045\n",
      "255\n",
      "1046\n",
      "171\n",
      "1047\n",
      "171\n",
      "1048\n",
      "171\n",
      "1049\n",
      "171\n",
      "1050\n",
      "171\n",
      "1051\n",
      "171\n",
      "1052\n",
      "171\n",
      "1053\n",
      "171\n",
      "1054\n",
      "171\n",
      "1055\n",
      "171\n",
      "1056\n",
      "171\n",
      "1057\n",
      "171\n",
      "1058\n",
      "171\n",
      "1059\n",
      "171\n",
      "1060\n",
      "171\n",
      "1061\n",
      "171\n",
      "1062\n",
      "171\n",
      "1063\n",
      "171\n",
      "1064\n",
      "42\n",
      "1065\n",
      "8\n",
      "1066\n",
      "8\n",
      "1067\n",
      "6034\n",
      "1068\n",
      "6034\n",
      "1069\n",
      "6034\n",
      "1070\n",
      "22\n",
      "1071\n",
      "22\n",
      "1072\n",
      "66\n",
      "1073\n",
      "377\n",
      "1074\n",
      "377\n",
      "1075\n",
      "377\n",
      "1076\n",
      "377\n",
      "1077\n",
      "377\n",
      "1078\n",
      "377\n",
      "1079\n",
      "377\n",
      "1080\n",
      "14\n",
      "1081\n",
      "346\n",
      "1082\n",
      "346\n",
      "1083\n",
      "346\n",
      "1084\n",
      "16\n",
      "1085\n",
      "64\n",
      "1086\n",
      "6062\n",
      "1087\n",
      "6062\n",
      "1088\n",
      "6062\n",
      "1089\n",
      "6062\n",
      "1090\n",
      "6045\n",
      "1091\n",
      "6045\n",
      "1092\n",
      "5688\n",
      "1093\n",
      "5688\n",
      "1094\n",
      "5688\n",
      "1095\n",
      "544\n",
      "1096\n",
      "544\n",
      "1097\n",
      "544\n",
      "1098\n",
      "544\n",
      "1099\n",
      "322\n",
      "1100\n",
      "322\n",
      "1101\n",
      "14\n",
      "1102\n",
      "14\n",
      "1103\n",
      "181\n",
      "1104\n",
      "14\n",
      "1105\n",
      "14\n",
      "1106\n",
      "5332\n",
      "1107\n",
      "5332\n",
      "1108\n",
      "5332\n",
      "1109\n",
      "5332\n",
      "1110\n",
      "5332\n",
      "1111\n",
      "166\n",
      "1112\n",
      "166\n",
      "1113\n",
      "166\n",
      "1114\n",
      "166\n",
      "1115\n",
      "166\n",
      "1116\n",
      "166\n",
      "1117\n",
      "166\n",
      "1118\n",
      "166\n",
      "1119\n",
      "166\n",
      "1120\n",
      "166\n",
      "1121\n",
      "5102\n",
      "1122\n",
      "5102\n",
      "1123\n",
      "143\n",
      "1124\n",
      "4869\n",
      "1125\n",
      "4869\n",
      "1126\n",
      "118\n",
      "1127\n",
      "673\n",
      "1128\n",
      "673\n",
      "1129\n",
      "673\n",
      "1130\n",
      "673\n",
      "1131\n",
      "673\n",
      "1132\n",
      "673\n",
      "1133\n",
      "673\n",
      "1134\n",
      "673\n",
      "1135\n",
      "673\n",
      "1136\n",
      "673\n",
      "1137\n",
      "673\n",
      "1138\n",
      "673\n",
      "1139\n",
      "11\n",
      "1140\n",
      "11\n",
      "1141\n",
      "11\n",
      "1142\n",
      "11\n",
      "1143\n",
      "4707\n",
      "1144\n",
      "4707\n",
      "1145\n",
      "4707\n",
      "1146\n",
      "4707\n",
      "1147\n",
      "4707\n",
      "1148\n",
      "223\n",
      "1149\n",
      "294\n",
      "1150\n",
      "294\n",
      "1151\n",
      "294\n",
      "1152\n",
      "61\n",
      "1153\n",
      "4481\n",
      "1154\n",
      "4481\n",
      "1155\n",
      "4481\n",
      "1156\n",
      "4481\n",
      "1157\n",
      "4481\n",
      "1158\n",
      "4481\n",
      "1159\n",
      "78\n",
      "1160\n",
      "78\n",
      "1161\n",
      "150\n",
      "1162\n",
      "150\n",
      "1163\n",
      "150\n",
      "1164\n",
      "150\n",
      "1165\n",
      "26\n",
      "1166\n",
      "26\n",
      "1167\n",
      "26\n",
      "1168\n",
      "4596\n",
      "1169\n",
      "4596\n",
      "1170\n",
      "4596\n",
      "1171\n",
      "4596\n",
      "1172\n",
      "4596\n",
      "1173\n",
      "4575\n",
      "1174\n",
      "4575\n",
      "1175\n",
      "4575\n",
      "1176\n",
      "4575\n",
      "1177\n",
      "27\n",
      "1178\n",
      "189\n",
      "1179\n",
      "4522\n",
      "1180\n",
      "4492\n",
      "1181\n",
      "4492\n",
      "1182\n",
      "4492\n",
      "1183\n",
      "4492\n",
      "1184\n",
      "4492\n",
      "1185\n",
      "4492\n",
      "1186\n",
      "4492\n",
      "1187\n",
      "4492\n",
      "1188\n",
      "167\n",
      "1189\n",
      "167\n",
      "1190\n",
      "44\n",
      "1191\n",
      "38\n",
      "1192\n",
      "38\n",
      "1193\n",
      "4308\n",
      "1194\n",
      "4308\n",
      "1195\n",
      "13\n",
      "1196\n",
      "13\n",
      "1197\n",
      "13\n",
      "1198\n",
      "638\n",
      "1199\n",
      "638\n",
      "1200\n",
      "17\n",
      "1201\n",
      "17\n",
      "1202\n",
      "765\n",
      "1203\n",
      "765\n",
      "1204\n",
      "765\n",
      "1205\n",
      "765\n",
      "1206\n",
      "411\n",
      "1207\n",
      "140\n",
      "1208\n",
      "63\n",
      "1209\n",
      "98\n",
      "1210\n",
      "1093\n",
      "1211\n",
      "1093\n",
      "1212\n",
      "1093\n",
      "1213\n",
      "1093\n",
      "1214\n",
      "1093\n",
      "1215\n",
      "1254\n",
      "1216\n",
      "1254\n",
      "1217\n",
      "1254\n",
      "1218\n",
      "1254\n",
      "1219\n",
      "1254\n",
      "1220\n",
      "14\n",
      "1221\n",
      "14\n",
      "1222\n",
      "1709\n",
      "1223\n",
      "1709\n",
      "1224\n",
      "1709\n",
      "1225\n",
      "1709\n",
      "1226\n",
      "1709\n",
      "1227\n",
      "31\n",
      "1228\n",
      "152\n",
      "1229\n",
      "152\n",
      "1230\n",
      "73\n",
      "1231\n",
      "73\n",
      "1232\n",
      "73\n",
      "1233\n",
      "73\n",
      "1234\n",
      "631\n"
     ]
    }
   ],
   "source": [
    "length = 0\n",
    "for i in range(len(new_df)):\n",
    "    print(i)\n",
    "    length += len(new_df.iloc[i]['Message'])\n",
    "    print(len(new_df.iloc[i]['Message']))\n",
    "# length/len(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T20:30:45.592250Z",
     "iopub.status.busy": "2025-09-03T20:30:45.591516Z",
     "iopub.status.idle": "2025-09-03T20:30:48.696442Z",
     "shell.execute_reply": "2025-09-03T20:30:48.695880Z",
     "shell.execute_reply.started": "2025-09-03T20:30:45.592227Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "final_df = diff_analysis_df.merge(new_df.drop('Diff',axis=1),on='Hash',how='inner')\n",
    "final_df.to_csv('final_analysis.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T06:53:41.407836Z",
     "iopub.status.busy": "2025-09-05T06:53:41.407524Z",
     "iopub.status.idle": "2025-09-05T06:53:44.890588Z",
     "shell.execute_reply": "2025-09-05T06:53:44.889635Z",
     "shell.execute_reply.started": "2025-09-05T06:53:41.407814Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting radon\n",
      "  Downloading radon-6.0.1-py2.py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting mando<0.8,>=0.6 (from radon)\n",
      "  Downloading mando-0.7.1-py2.py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: colorama>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from radon) (0.4.6)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from mando<0.8,>=0.6->radon) (1.17.0)\n",
      "Downloading radon-6.0.1-py2.py3-none-any.whl (52 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mando-0.7.1-py2.py3-none-any.whl (28 kB)\n",
      "Installing collected packages: mando, radon\n",
      "Successfully installed mando-0.7.1 radon-6.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install radon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T07:06:31.689648Z",
     "iopub.status.busy": "2025-09-05T07:06:31.688874Z",
     "iopub.status.idle": "2025-09-05T07:11:39.173545Z",
     "shell.execute_reply": "2025-09-05T07:11:39.172739Z",
     "shell.execute_reply.started": "2025-09-05T07:06:31.689624Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from radon.complexity import cc_visit\n",
    "from radon.metrics import mi_visit\n",
    "from radon.raw import analyze\n",
    "\n",
    "\n",
    "def analyze_code(source_code: str):\n",
    "    \"\"\"Extract MI, CC, and LOC from given source code string.\"\"\"\n",
    "    try:\n",
    "        # Maintainability Index\n",
    "        mi_score = mi_visit(source_code, True)\n",
    "\n",
    "        # Average Cyclomatic Complexity\n",
    "        cc_blocks = cc_visit(source_code)\n",
    "        cc_score =  sum(block.complexity for block in cc_blocks)/len(cc_blocks)\n",
    "\n",
    "        # Lines of Code\n",
    "        raw_metrics = analyze(source_code)\n",
    "        loc = raw_metrics.loc\n",
    "\n",
    "        return mi_score, cc_score, loc\n",
    "    except Exception:\n",
    "        return None, None, None\n",
    "\n",
    "\n",
    "def process_dataframe(df: pd.DataFrame):\n",
    "    \"\"\"Run radon analysis on Source Code (before/current) for each row.\"\"\"\n",
    "    results = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        mi_before, cc_before, loc_before = analyze_code(str(row[\"Source Code (before)\"]))\n",
    "        mi_after, cc_after, loc_after = analyze_code(str(row[\"Source Code (current)\"]))\n",
    "\n",
    "        results.append({\n",
    "            \"MI_Change\": (mi_after - mi_before) if mi_before is not None and mi_after is not None else None,\n",
    "            \"CC_Change\": (cc_after - cc_before) if cc_before is not None and cc_after is not None else None,\n",
    "            \"LOC_Change\": (loc_after - loc_before) if loc_before is not None and loc_after is not None else None\n",
    "        })\n",
    "\n",
    "    # Merging with original dataframe\n",
    "    return pd.concat([df, pd.DataFrame(results)], axis=1)\n",
    "\n",
    "\n",
    "df_processed = process_dataframe(final_df)\n",
    "df_processed.to_csv(\"radon_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# # Loading tokenizer\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"mamiksik/CommitPredictorT5\")\n",
    "\n",
    "# # Loading model and moving it to GPU\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(\"Using device:\", device)\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(\"mamiksik/CommitPredictorT5\",device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T06:22:15.274746Z",
     "iopub.status.busy": "2025-09-05T06:22:15.274113Z",
     "iopub.status.idle": "2025-09-05T06:23:01.256424Z",
     "shell.execute_reply": "2025-09-05T06:23:01.255457Z",
     "shell.execute_reply.started": "2025-09-05T06:22:15.274722Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11fd6dfd32794571b22d380480e93419",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "186fc069ad0d41ca87c66b359b8484e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/498 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8bddf2f2f284d8693c056904610ee24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08ae8851a2de429ca6d0dbd69c62fc9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de7da355e963406e9d9cb0203237fc63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-05 06:22:41.207153: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1757053361.557522      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1757053361.654838      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb89e6d9c13c4be188be37dca65504e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b93f24fec70e4f169f9fa43251b3e528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "model = AutoModel.from_pretrained(\"microsoft/codebert-base\",device_map=\"auto\")\n",
    "\n",
    "def semantic_similarity(code1, code2):\n",
    "    inputs = tokenizer([code1, code2], return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Mean pooling over tokens\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "\n",
    "    # Cosine similarity\n",
    "    sim = cosine_similarity([embeddings[0].numpy()], [embeddings[1].numpy()])[0][0]\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T06:30:19.508146Z",
     "iopub.status.busy": "2025-09-05T06:30:19.507844Z",
     "iopub.status.idle": "2025-09-05T06:30:19.651426Z",
     "shell.execute_reply": "2025-09-05T06:30:19.650688Z",
     "shell.execute_reply.started": "2025-09-05T06:30:19.508121Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sacrebleu.metrics import BLEU\n",
    "\n",
    "# Initialize BLEU scorer\n",
    "bleu = BLEU()\n",
    "\n",
    "def token_similarity_bleu(before_code, after_code):\n",
    "    sys = [after_code]\n",
    "    refs = [[before_code]]\n",
    "    \n",
    "    score = bleu.corpus_score(sys, refs)\n",
    "    return score.score / 100.0      # sacrebleu returns score out of 100, normalize to [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T07:46:01.509000Z",
     "iopub.status.busy": "2025-09-05T07:46:01.508718Z",
     "iopub.status.idle": "2025-09-05T07:48:17.168007Z",
     "shell.execute_reply": "2025-09-05T07:48:17.167135Z",
     "shell.execute_reply.started": "2025-09-05T07:46:01.508979Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1136/1136 [01:40<00:00, 11.27it/s]\n",
      "/tmp/ipykernel_36/4121688861.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results_df[\"Semantic_Similarity\"] = results_df.progress_apply(\n",
      "100%|██████████| 1136/1136 [00:31<00:00, 35.57it/s]\n",
      "/tmp/ipykernel_36/4121688861.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results_df[\"Token_Similarity\"] = results_df.progress_apply(\n",
      "/tmp/ipykernel_36/4121688861.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results_df[\"Semantic_Class\"] = results_df[\"Semantic_Similarity\"].apply(classify_semantic)\n",
      "/tmp/ipykernel_36/4121688861.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results_df[\"Token_Class\"] = results_df[\"Token_Similarity\"].apply(classify_token)\n",
      "/tmp/ipykernel_36/4121688861.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results_df[\"Classes_Agree\"] = results_df.apply(\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Wrap apply with tqdm\n",
    "tqdm.pandas()\n",
    "results_df = df_processed.dropna(subset=[\"Source Code (before)\", \"Source Code (current)\"])\n",
    "results_df[\"Semantic_Similarity\"] = results_df.progress_apply(\n",
    "    lambda row: semantic_similarity(str(row[\"Source Code (before)\"]), str(row[\"Source Code (current)\"])), axis=1\n",
    ")\n",
    "\n",
    "results_df[\"Token_Similarity\"] = results_df.progress_apply(\n",
    "    lambda row: token_similarity_bleu(str(row[\"Source Code (before)\"]), str(row[\"Source Code (current)\"])), axis=1\n",
    ")\n",
    "\n",
    "def classify_semantic(sim):\n",
    "    return \"Minor\" if sim >= 0.80 else \"Major\"\n",
    "\n",
    "def classify_token(sim):\n",
    "    return \"Minor\" if sim >= 0.75 else \"Major\"\n",
    "\n",
    "results_df[\"Semantic_Class\"] = results_df[\"Semantic_Similarity\"].apply(classify_semantic)\n",
    "results_df[\"Token_Class\"] = results_df[\"Token_Similarity\"].apply(classify_token)\n",
    "results_df[\"Classes_Agree\"] = results_df.apply(\n",
    "    lambda row: \"YES\" if row[\"Semantic_Class\"] == row[\"Token_Class\"] else \"NO\", axis=1\n",
    ")\n",
    "results_df.to_csv(\"Lab3_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T07:52:54.691306Z",
     "iopub.status.busy": "2025-09-05T07:52:54.690800Z",
     "iopub.status.idle": "2025-09-05T07:52:54.710376Z",
     "shell.execute_reply": "2025-09-05T07:52:54.709614Z",
     "shell.execute_reply.started": "2025-09-05T07:52:54.691284Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater\n",
      "  return op(a, b)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hash</th>\n",
       "      <th>Author</th>\n",
       "      <th>Message</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Change Type</th>\n",
       "      <th>Source Code (before)</th>\n",
       "      <th>Source Code (current)</th>\n",
       "      <th>Diff</th>\n",
       "      <th>LLM_inference</th>\n",
       "      <th>Overall_diff</th>\n",
       "      <th>Rectified Message</th>\n",
       "      <th>MI_Change</th>\n",
       "      <th>CC_Change</th>\n",
       "      <th>LOC_Change</th>\n",
       "      <th>Semantic_Similarity</th>\n",
       "      <th>Token_Similarity</th>\n",
       "      <th>Semantic_Class</th>\n",
       "      <th>Token_Class</th>\n",
       "      <th>Classes_Agree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>8b57e17c8db14eeec4edcf7cd24b33abeaaabb86</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Vision support (#1315)\\n\\n* Fix pad token\\r\\n\\...</td>\n",
       "      <td>loader.py</td>\n",
       "      <td>MODIFY</td>\n",
       "      <td># Copyright 2023-present Daniel Han-Chen &amp; the...</td>\n",
       "      <td># Copyright 2023-present Daniel Han-Chen &amp; the...</td>\n",
       "      <td>@@ -20,8 +20,8 @@ from .cohere  import FastCoh...</td>\n",
       "      <td>add support for native model loading</td>\n",
       "      <td>@@ -55,7 +55,7 @@ else:\\n pass\\n \\n # Reduce V...</td>\n",
       "      <td>add hf_hub_enable_hf_transfer</td>\n",
       "      <td>-5.128501</td>\n",
       "      <td>13.3</td>\n",
       "      <td>134.0</td>\n",
       "      <td>0.999736</td>\n",
       "      <td>0.661871</td>\n",
       "      <td>Minor</td>\n",
       "      <td>Major</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>c14046ea4a68f73dc3de29223b0d805382320e9f</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Bug fixes (#1516)\\n\\n* use exact model name\\r\\...</td>\n",
       "      <td>loader.py</td>\n",
       "      <td>MODIFY</td>\n",
       "      <td># Copyright 2023-present Daniel Han-Chen &amp; the...</td>\n",
       "      <td># Copyright 2023-present Daniel Han-Chen &amp; the...</td>\n",
       "      <td>@@ -31,8 +31,17 @@ except:\\n pass\\n from huggi...</td>\n",
       "      <td>add unsloth support</td>\n",
       "      <td>@@ -212,6 +212,9 @@ For **advanced installatio...</td>\n",
       "      <td>add unsloth download script</td>\n",
       "      <td>-1.982538</td>\n",
       "      <td>12.3</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.998443</td>\n",
       "      <td>0.937678</td>\n",
       "      <td>Minor</td>\n",
       "      <td>Minor</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>016315eb0495135c78235fff9684cb8759ff0b64</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Fix bugs (#1701)\\n\\n* Phi 4\\r\\n\\r\\n* Update ll...</td>\n",
       "      <td>rl.py</td>\n",
       "      <td>MODIFY</td>\n",
       "      <td># Copyright 2023-present Daniel Han-Chen &amp; the...</td>\n",
       "      <td># Copyright 2023-present Daniel Han-Chen &amp; the...</td>\n",
       "      <td>@@ -16,30 +16,17 @@ __all__ = [\\n     \"PatchFa...</td>\n",
       "      <td>add patch notes</td>\n",
       "      <td>@@ -187,9 +187,9 @@ cu124onlytorch260 = [\\n   ...</td>\n",
       "      <td>add tests for python 3.10 and 3.11</td>\n",
       "      <td>-7.132900</td>\n",
       "      <td>10.3</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.998740</td>\n",
       "      <td>0.386074</td>\n",
       "      <td>Minor</td>\n",
       "      <td>Major</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Hash      Author  \\\n",
       "592  8b57e17c8db14eeec4edcf7cd24b33abeaaabb86  Daniel Han   \n",
       "685  c14046ea4a68f73dc3de29223b0d805382320e9f  Daniel Han   \n",
       "734  016315eb0495135c78235fff9684cb8759ff0b64  Daniel Han   \n",
       "\n",
       "                                               Message   Filename Change Type  \\\n",
       "592  Vision support (#1315)\\n\\n* Fix pad token\\r\\n\\...  loader.py      MODIFY   \n",
       "685  Bug fixes (#1516)\\n\\n* use exact model name\\r\\...  loader.py      MODIFY   \n",
       "734  Fix bugs (#1701)\\n\\n* Phi 4\\r\\n\\r\\n* Update ll...      rl.py      MODIFY   \n",
       "\n",
       "                                  Source Code (before)  \\\n",
       "592  # Copyright 2023-present Daniel Han-Chen & the...   \n",
       "685  # Copyright 2023-present Daniel Han-Chen & the...   \n",
       "734  # Copyright 2023-present Daniel Han-Chen & the...   \n",
       "\n",
       "                                 Source Code (current)  \\\n",
       "592  # Copyright 2023-present Daniel Han-Chen & the...   \n",
       "685  # Copyright 2023-present Daniel Han-Chen & the...   \n",
       "734  # Copyright 2023-present Daniel Han-Chen & the...   \n",
       "\n",
       "                                                  Diff  \\\n",
       "592  @@ -20,8 +20,8 @@ from .cohere  import FastCoh...   \n",
       "685  @@ -31,8 +31,17 @@ except:\\n pass\\n from huggi...   \n",
       "734  @@ -16,30 +16,17 @@ __all__ = [\\n     \"PatchFa...   \n",
       "\n",
       "                            LLM_inference  \\\n",
       "592  add support for native model loading   \n",
       "685                   add unsloth support   \n",
       "734                       add patch notes   \n",
       "\n",
       "                                          Overall_diff  \\\n",
       "592  @@ -55,7 +55,7 @@ else:\\n pass\\n \\n # Reduce V...   \n",
       "685  @@ -212,6 +212,9 @@ For **advanced installatio...   \n",
       "734  @@ -187,9 +187,9 @@ cu124onlytorch260 = [\\n   ...   \n",
       "\n",
       "                      Rectified Message  MI_Change  CC_Change  LOC_Change  \\\n",
       "592       add hf_hub_enable_hf_transfer  -5.128501       13.3       134.0   \n",
       "685         add unsloth download script  -1.982538       12.3        15.0   \n",
       "734  add tests for python 3.10 and 3.11  -7.132900       10.3       148.0   \n",
       "\n",
       "     Semantic_Similarity  Token_Similarity Semantic_Class Token_Class  \\\n",
       "592             0.999736          0.661871          Minor       Major   \n",
       "685             0.998443          0.937678          Minor       Minor   \n",
       "734             0.998740          0.386074          Minor       Major   \n",
       "\n",
       "    Classes_Agree  \n",
       "592            NO  \n",
       "685           YES  \n",
       "734            NO  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[results_df['CC_Change']>10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T07:41:24.882057Z",
     "iopub.status.busy": "2025-09-05T07:41:24.881504Z",
     "iopub.status.idle": "2025-09-05T07:41:24.945966Z",
     "shell.execute_reply": "2025-09-05T07:41:24.945251Z",
     "shell.execute_reply.started": "2025-09-05T07:41:24.882035Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n",
      "  has_large_values = (abs_vals > 1e6).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hash</th>\n",
       "      <th>Author</th>\n",
       "      <th>Message</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Change Type</th>\n",
       "      <th>Source Code (before)</th>\n",
       "      <th>Source Code (current)</th>\n",
       "      <th>Diff</th>\n",
       "      <th>LLM_inference</th>\n",
       "      <th>Overall_diff</th>\n",
       "      <th>Rectified Message</th>\n",
       "      <th>MI_Change</th>\n",
       "      <th>CC_Change</th>\n",
       "      <th>LOC_Change</th>\n",
       "      <th>Semantic_Similarity</th>\n",
       "      <th>Token_Similarity</th>\n",
       "      <th>Semantic_Class</th>\n",
       "      <th>Token_Class</th>\n",
       "      <th>Classes_Agree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4b97a810b509c93f44be4c037c7aa18fb8922884</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Pre-release 2023 December version (Mistral, Pr...</td>\n",
       "      <td>README.md</td>\n",
       "      <td>MODIFY</td>\n",
       "      <td>&lt;div class=\"align-center\"&gt;\\n  &lt;img src=\"./imag...</td>\n",
       "      <td>&lt;div class=\"align-center\"&gt;\\n  &lt;img src=\"./imag...</td>\n",
       "      <td>@@ -1,23 +1,25 @@\\n &lt;div class=\"align-center\"&gt;...</td>\n",
       "      <td>add more info about nvidia gpus</td>\n",
       "      <td>@@ -1,23 +1,25 @@\\n &lt;div class=\"align-center\"&gt;...</td>\n",
       "      <td>add more info about nvidia gpus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.997825</td>\n",
       "      <td>0.681603</td>\n",
       "      <td>Minor</td>\n",
       "      <td>Major</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4b97a810b509c93f44be4c037c7aa18fb8922884</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Pre-release 2023 December version (Mistral, Pr...</td>\n",
       "      <td>Discord.png</td>\n",
       "      <td>MODIFY</td>\n",
       "      <td>PNG\\r\\n\u001a\\n</td>\n",
       "      <td>PNG\\r\\n\u001a\\n</td>\n",
       "      <td>Binary files a/images/Discord.png and b/images...</td>\n",
       "      <td>distro binary files</td>\n",
       "      <td>@@ -1,23 +1,25 @@\\n &lt;div class=\"align-center\"&gt;...</td>\n",
       "      <td>add more info about nvidia gpus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Minor</td>\n",
       "      <td>Major</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4b97a810b509c93f44be4c037c7aa18fb8922884</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Pre-release 2023 December version (Mistral, Pr...</td>\n",
       "      <td>LAION 2GPU.png</td>\n",
       "      <td>ADD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PNG\\r\\n\u001a\\n</td>\n",
       "      <td>Binary files /dev/null and b/images/LAION 2GPU...</td>\n",
       "      <td>distinguish 2gpu image from null</td>\n",
       "      <td>@@ -1,23 +1,25 @@\\n &lt;div class=\"align-center\"&gt;...</td>\n",
       "      <td>add more info about nvidia gpus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.821685</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Minor</td>\n",
       "      <td>Major</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4b97a810b509c93f44be4c037c7aa18fb8922884</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Pre-release 2023 December version (Mistral, Pr...</td>\n",
       "      <td>LAION 2GPU.svg</td>\n",
       "      <td>DELETE</td>\n",
       "      <td>&lt;?xml version=\"1.0\" encoding=\"utf-8\" standalon...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@@ -1,1518 +0,0 @@\\n-&lt;?xml version=\"1.0\" encod...</td>\n",
       "      <td>add missing missing nodes in skeleton skeleton</td>\n",
       "      <td>@@ -1,23 +1,25 @@\\n &lt;div class=\"align-center\"&gt;...</td>\n",
       "      <td>add more info about nvidia gpus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.572012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Major</td>\n",
       "      <td>Major</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4b97a810b509c93f44be4c037c7aa18fb8922884</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Pre-release 2023 December version (Mistral, Pr...</td>\n",
       "      <td>SlimOrca 1GPU.svg</td>\n",
       "      <td>DELETE</td>\n",
       "      <td>&lt;?xml version=\"1.0\" encoding=\"utf-8\" standalon...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@@ -1,1424 +0,0 @@\\n-&lt;?xml version=\"1.0\" encod...</td>\n",
       "      <td>add missing missing svg elements</td>\n",
       "      <td>@@ -1,23 +1,25 @@\\n &lt;div class=\"align-center\"&gt;...</td>\n",
       "      <td>add more info about nvidia gpus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.572148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Major</td>\n",
       "      <td>Major</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>9050d6f5278e2373e66d17fc9ac8c2ec4f986e7e</td>\n",
       "      <td>Roland Tannous</td>\n",
       "      <td>tests for mxfp4 and quantized models merge fix...</td>\n",
       "      <td>run_test.sh</td>\n",
       "      <td>ADD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#!/bin/bash\\nset -e\\n\\necho \"=================...</td>\n",
       "      <td>@@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...</td>\n",
       "      <td>add missing line</td>\n",
       "      <td>@@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...</td>\n",
       "      <td>add test for merged model</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.593026</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Major</td>\n",
       "      <td>Major</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>9050d6f5278e2373e66d17fc9ac8c2ec4f986e7e</td>\n",
       "      <td>Roland Tannous</td>\n",
       "      <td>tests for mxfp4 and quantized models merge fix...</td>\n",
       "      <td>test_merged_model.py</td>\n",
       "      <td>ADD</td>\n",
       "      <td>NaN</td>\n",
       "      <td># inference_on_merged.py\\nfrom unsloth import ...</td>\n",
       "      <td>@@ -0,0 +1,55 @@\\n+# inference_on_merged.py\\n+...</td>\n",
       "      <td>add test for merge</td>\n",
       "      <td>@@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...</td>\n",
       "      <td>add test for merged model</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.605916</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Major</td>\n",
       "      <td>Major</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>9050d6f5278e2373e66d17fc9ac8c2ec4f986e7e</td>\n",
       "      <td>Roland Tannous</td>\n",
       "      <td>tests for mxfp4 and quantized models merge fix...</td>\n",
       "      <td>train_and_merge.py</td>\n",
       "      <td>ADD</td>\n",
       "      <td>NaN</td>\n",
       "      <td># train_and_merge.py\\nfrom unsloth import Fast...</td>\n",
       "      <td>@@ -0,0 +1,71 @@\\n+# train_and_merge.py\\n+from...</td>\n",
       "      <td>add examples to train_and_merge</td>\n",
       "      <td>@@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...</td>\n",
       "      <td>add test for merged model</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.584959</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Major</td>\n",
       "      <td>Major</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>9050d6f5278e2373e66d17fc9ac8c2ec4f986e7e</td>\n",
       "      <td>Roland Tannous</td>\n",
       "      <td>tests for mxfp4 and quantized models merge fix...</td>\n",
       "      <td>test_merge_4bit_validation.py</td>\n",
       "      <td>ADD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>from unsloth import FastLanguageModel\\nfrom un...</td>\n",
       "      <td>@@ -0,0 +1,223 @@\\n+from unsloth import FastLa...</td>\n",
       "      <td>add test case for formatting prompts</td>\n",
       "      <td>@@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...</td>\n",
       "      <td>add test for merged model</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.585805</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Major</td>\n",
       "      <td>Major</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>12737e503d32fc1464f8e38536be96d92db4f7d8</td>\n",
       "      <td>stevenxdavis</td>\n",
       "      <td>Fix incorrect function call in test_qwen3_grpo...</td>\n",
       "      <td>test_qwen3_grpo.py</td>\n",
       "      <td>MODIFY</td>\n",
       "      <td>from unsloth import FastLanguageModel\\nimport ...</td>\n",
       "      <td>from unsloth import FastLanguageModel\\nimport ...</td>\n",
       "      <td>@@ -415,7 +415,8 @@ sampling_params = Sampling...</td>\n",
       "      <td>update sample_params.rb</td>\n",
       "      <td>@@ -415,7 +415,8 @@ sampling_params = Sampling...</td>\n",
       "      <td>fast_generate example</td>\n",
       "      <td>0.05492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996770</td>\n",
       "      <td>Minor</td>\n",
       "      <td>Minor</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1235 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Hash          Author  \\\n",
       "0     4b97a810b509c93f44be4c037c7aa18fb8922884      Daniel Han   \n",
       "1     4b97a810b509c93f44be4c037c7aa18fb8922884      Daniel Han   \n",
       "2     4b97a810b509c93f44be4c037c7aa18fb8922884      Daniel Han   \n",
       "3     4b97a810b509c93f44be4c037c7aa18fb8922884      Daniel Han   \n",
       "4     4b97a810b509c93f44be4c037c7aa18fb8922884      Daniel Han   \n",
       "...                                        ...             ...   \n",
       "1230  9050d6f5278e2373e66d17fc9ac8c2ec4f986e7e  Roland Tannous   \n",
       "1231  9050d6f5278e2373e66d17fc9ac8c2ec4f986e7e  Roland Tannous   \n",
       "1232  9050d6f5278e2373e66d17fc9ac8c2ec4f986e7e  Roland Tannous   \n",
       "1233  9050d6f5278e2373e66d17fc9ac8c2ec4f986e7e  Roland Tannous   \n",
       "1234  12737e503d32fc1464f8e38536be96d92db4f7d8    stevenxdavis   \n",
       "\n",
       "                                                Message  \\\n",
       "0     Pre-release 2023 December version (Mistral, Pr...   \n",
       "1     Pre-release 2023 December version (Mistral, Pr...   \n",
       "2     Pre-release 2023 December version (Mistral, Pr...   \n",
       "3     Pre-release 2023 December version (Mistral, Pr...   \n",
       "4     Pre-release 2023 December version (Mistral, Pr...   \n",
       "...                                                 ...   \n",
       "1230  tests for mxfp4 and quantized models merge fix...   \n",
       "1231  tests for mxfp4 and quantized models merge fix...   \n",
       "1232  tests for mxfp4 and quantized models merge fix...   \n",
       "1233  tests for mxfp4 and quantized models merge fix...   \n",
       "1234  Fix incorrect function call in test_qwen3_grpo...   \n",
       "\n",
       "                           Filename Change Type  \\\n",
       "0                         README.md      MODIFY   \n",
       "1                       Discord.png      MODIFY   \n",
       "2                    LAION 2GPU.png         ADD   \n",
       "3                    LAION 2GPU.svg      DELETE   \n",
       "4                 SlimOrca 1GPU.svg      DELETE   \n",
       "...                             ...         ...   \n",
       "1230                    run_test.sh         ADD   \n",
       "1231           test_merged_model.py         ADD   \n",
       "1232             train_and_merge.py         ADD   \n",
       "1233  test_merge_4bit_validation.py         ADD   \n",
       "1234             test_qwen3_grpo.py      MODIFY   \n",
       "\n",
       "                                   Source Code (before)  \\\n",
       "0     <div class=\"align-center\">\\n  <img src=\"./imag...   \n",
       "1                                            PNG\\r\\n\u001a\\n   \n",
       "2                                                   NaN   \n",
       "3     <?xml version=\"1.0\" encoding=\"utf-8\" standalon...   \n",
       "4     <?xml version=\"1.0\" encoding=\"utf-8\" standalon...   \n",
       "...                                                 ...   \n",
       "1230                                                NaN   \n",
       "1231                                                NaN   \n",
       "1232                                                NaN   \n",
       "1233                                                NaN   \n",
       "1234  from unsloth import FastLanguageModel\\nimport ...   \n",
       "\n",
       "                                  Source Code (current)  \\\n",
       "0     <div class=\"align-center\">\\n  <img src=\"./imag...   \n",
       "1                                            PNG\\r\\n\u001a\\n   \n",
       "2                                            PNG\\r\\n\u001a\\n   \n",
       "3                                                   NaN   \n",
       "4                                                   NaN   \n",
       "...                                                 ...   \n",
       "1230  #!/bin/bash\\nset -e\\n\\necho \"=================...   \n",
       "1231  # inference_on_merged.py\\nfrom unsloth import ...   \n",
       "1232  # train_and_merge.py\\nfrom unsloth import Fast...   \n",
       "1233  from unsloth import FastLanguageModel\\nfrom un...   \n",
       "1234  from unsloth import FastLanguageModel\\nimport ...   \n",
       "\n",
       "                                                   Diff  \\\n",
       "0     @@ -1,23 +1,25 @@\\n <div class=\"align-center\">...   \n",
       "1     Binary files a/images/Discord.png and b/images...   \n",
       "2     Binary files /dev/null and b/images/LAION 2GPU...   \n",
       "3     @@ -1,1518 +0,0 @@\\n-<?xml version=\"1.0\" encod...   \n",
       "4     @@ -1,1424 +0,0 @@\\n-<?xml version=\"1.0\" encod...   \n",
       "...                                                 ...   \n",
       "1230  @@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...   \n",
       "1231  @@ -0,0 +1,55 @@\\n+# inference_on_merged.py\\n+...   \n",
       "1232  @@ -0,0 +1,71 @@\\n+# train_and_merge.py\\n+from...   \n",
       "1233  @@ -0,0 +1,223 @@\\n+from unsloth import FastLa...   \n",
       "1234  @@ -415,7 +415,8 @@ sampling_params = Sampling...   \n",
       "\n",
       "                                       LLM_inference  \\\n",
       "0                    add more info about nvidia gpus   \n",
       "1                                distro binary files   \n",
       "2                   distinguish 2gpu image from null   \n",
       "3     add missing missing nodes in skeleton skeleton   \n",
       "4                   add missing missing svg elements   \n",
       "...                                              ...   \n",
       "1230                                add missing line   \n",
       "1231                              add test for merge   \n",
       "1232                 add examples to train_and_merge   \n",
       "1233            add test case for formatting prompts   \n",
       "1234                         update sample_params.rb   \n",
       "\n",
       "                                           Overall_diff  \\\n",
       "0     @@ -1,23 +1,25 @@\\n <div class=\"align-center\">...   \n",
       "1     @@ -1,23 +1,25 @@\\n <div class=\"align-center\">...   \n",
       "2     @@ -1,23 +1,25 @@\\n <div class=\"align-center\">...   \n",
       "3     @@ -1,23 +1,25 @@\\n <div class=\"align-center\">...   \n",
       "4     @@ -1,23 +1,25 @@\\n <div class=\"align-center\">...   \n",
       "...                                                 ...   \n",
       "1230  @@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...   \n",
       "1231  @@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...   \n",
       "1232  @@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...   \n",
       "1233  @@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...   \n",
       "1234  @@ -415,7 +415,8 @@ sampling_params = Sampling...   \n",
       "\n",
       "                    Rectified Message  MI_Change  CC_Change  LOC_Change  \\\n",
       "0     add more info about nvidia gpus        NaN        NaN         NaN   \n",
       "1     add more info about nvidia gpus        NaN        NaN         NaN   \n",
       "2     add more info about nvidia gpus        NaN        NaN         NaN   \n",
       "3     add more info about nvidia gpus        NaN        NaN         NaN   \n",
       "4     add more info about nvidia gpus        NaN        NaN         NaN   \n",
       "...                               ...        ...        ...         ...   \n",
       "1230        add test for merged model        NaN        NaN         NaN   \n",
       "1231        add test for merged model        NaN        NaN         NaN   \n",
       "1232        add test for merged model        NaN        NaN         NaN   \n",
       "1233        add test for merged model        NaN        NaN         NaN   \n",
       "1234            fast_generate example    0.05492        0.0         1.0   \n",
       "\n",
       "      Semantic_Similarity  Token_Similarity Semantic_Class Token_Class  \\\n",
       "0                0.997825          0.681603          Minor       Major   \n",
       "1                1.000000          0.000000          Minor       Major   \n",
       "2                0.821685          0.000000          Minor       Major   \n",
       "3                0.572012          0.000000          Major       Major   \n",
       "4                0.572148          0.000000          Major       Major   \n",
       "...                   ...               ...            ...         ...   \n",
       "1230             0.593026          0.000000          Major       Major   \n",
       "1231             0.605916          0.000000          Major       Major   \n",
       "1232             0.584959          0.000000          Major       Major   \n",
       "1233             0.585805          0.000000          Major       Major   \n",
       "1234             1.000000          0.996770          Minor       Minor   \n",
       "\n",
       "     Classes_Agree  \n",
       "0               NO  \n",
       "1               NO  \n",
       "2               NO  \n",
       "3              YES  \n",
       "4              YES  \n",
       "...            ...  \n",
       "1230           YES  \n",
       "1231           YES  \n",
       "1232           YES  \n",
       "1233           YES  \n",
       "1234           YES  \n",
       "\n",
       "[1235 rows x 19 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T07:02:21.155216Z",
     "iopub.status.busy": "2025-09-05T07:02:21.154744Z",
     "iopub.status.idle": "2025-09-05T07:02:21.177273Z",
     "shell.execute_reply": "2025-09-05T07:02:21.176516Z",
     "shell.execute_reply.started": "2025-09-05T07:02:21.155177Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic similarity: 0.8959043\n",
      "Token similarity: 0.7102992180127417\n"
     ]
    }
   ],
   "source": [
    "code_before = \"def add(a, b): return a + b\"\n",
    "code_after  = \"wo hi(a, b): return a + y\"\n",
    "\n",
    "print(\"Semantic similarity:\", semantic_similarity(code_before, code_after))\n",
    "print(\"Token similarity:\", token_similarity_bleu(code_before,code_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T06:29:10.360623Z",
     "iopub.status.busy": "2025-09-05T06:29:10.360344Z",
     "iopub.status.idle": "2025-09-05T06:29:15.981848Z",
     "shell.execute_reply": "2025-09-05T06:29:15.981133Z",
     "shell.execute_reply.started": "2025-09-05T06:29:10.360603Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sacrebleu\n",
      "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting portalocker (from sacrebleu)\n",
      "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2024.11.6)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (1.26.4)\n",
      "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.4.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (2.4.1)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->sacrebleu) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->sacrebleu) (2022.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->sacrebleu) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->sacrebleu) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->sacrebleu) (2024.2.0)\n",
      "Downloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: portalocker, sacrebleu\n",
      "Successfully installed portalocker-3.2.0 sacrebleu-2.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T06:26:30.785661Z",
     "iopub.status.busy": "2025-09-05T06:26:30.785404Z",
     "iopub.status.idle": "2025-09-05T06:26:30.794124Z",
     "shell.execute_reply": "2025-09-05T06:26:30.793337Z",
     "shell.execute_reply.started": "2025-09-05T06:26:30.785644Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token similarity: 4.515870009358044e-234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T18:39:38.932413Z",
     "iopub.status.busy": "2025-09-01T18:39:38.931785Z",
     "iopub.status.idle": "2025-09-01T18:39:41.412271Z",
     "shell.execute_reply": "2025-09-01T18:39:41.411676Z",
     "shell.execute_reply.started": "2025-09-01T18:39:38.932381Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "diff_analysis_df.to_csv('LLM_inference.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T20:08:28.203206Z",
     "iopub.status.busy": "2025-09-01T20:08:28.202451Z",
     "iopub.status.idle": "2025-09-01T20:08:28.221659Z",
     "shell.execute_reply": "2025-09-01T20:08:28.221001Z",
     "shell.execute_reply.started": "2025-09-01T20:08:28.203180Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hash</th>\n",
       "      <th>Author</th>\n",
       "      <th>Message</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Change Type</th>\n",
       "      <th>Source Code (before)</th>\n",
       "      <th>Source Code (current)</th>\n",
       "      <th>Diff</th>\n",
       "      <th>overall_diff</th>\n",
       "      <th>Rectified Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4b97a810b509c93f44be4c037c7aa18fb8922884</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Pre-release 2023 December version (Mistral, Pr...</td>\n",
       "      <td>README.md</td>\n",
       "      <td>MODIFY</td>\n",
       "      <td>&lt;div class=\"align-center\"&gt;\\n  &lt;img src=\"./imag...</td>\n",
       "      <td>&lt;div class=\"align-center\"&gt;\\n  &lt;img src=\"./imag...</td>\n",
       "      <td>@@ -1,23 +1,25 @@\\n &lt;div class=\"align-center\"&gt;...</td>\n",
       "      <td>@@ -1,23 +1,25 @@\\n &lt;div class=\"align-center\"&gt;...</td>\n",
       "      <td>add more info about nvidia gpus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4b97a810b509c93f44be4c037c7aa18fb8922884</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Pre-release 2023 December version (Mistral, Pr...</td>\n",
       "      <td>Discord.png</td>\n",
       "      <td>MODIFY</td>\n",
       "      <td>PNG\\r\\n\u001a\\n\u0000\u0000\u0000\\rIHDR\u0000\u0000\u0006\u0000\u0000\u0001\b\u0006\u0000\u0000\u0000\u000e\u0006\u0000\u0000\u0000\u0001sRGB\u0000\u001c\u0000\u0000\u0000\u0004...</td>\n",
       "      <td>PNG\\r\\n\u001a\\n\u0000\u0000\u0000\\rIHDR\u0000\u0000\u0003}\u0000\u0000\u0001\u0004\b\u0006\u0000\u0000\u00008]\u0000\u0000 \u0000IDATx\\t\u0014...</td>\n",
       "      <td>Binary files a/images/Discord.png and b/images...</td>\n",
       "      <td>@@ -1,23 +1,25 @@\\n &lt;div class=\"align-center\"&gt;...</td>\n",
       "      <td>add more info about nvidia gpus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4b97a810b509c93f44be4c037c7aa18fb8922884</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Pre-release 2023 December version (Mistral, Pr...</td>\n",
       "      <td>LAION 2GPU.png</td>\n",
       "      <td>ADD</td>\n",
       "      <td>None</td>\n",
       "      <td>PNG\\r\\n\u001a\\n\u0000\u0000\u0000\\rIHDR\u0000\u0000\u0003\u0000\u0000\u0002A\b\u0006\u0000\u0000\u0001\u0011\u0000\u0000ȫIDATx\u0001\u000b\\k]\\...</td>\n",
       "      <td>Binary files /dev/null and b/images/LAION 2GPU...</td>\n",
       "      <td>@@ -1,23 +1,25 @@\\n &lt;div class=\"align-center\"&gt;...</td>\n",
       "      <td>add more info about nvidia gpus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4b97a810b509c93f44be4c037c7aa18fb8922884</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Pre-release 2023 December version (Mistral, Pr...</td>\n",
       "      <td>LAION 2GPU.svg</td>\n",
       "      <td>DELETE</td>\n",
       "      <td>&lt;?xml version=\"1.0\" encoding=\"utf-8\" standalon...</td>\n",
       "      <td>None</td>\n",
       "      <td>@@ -1,1518 +0,0 @@\\n-&lt;?xml version=\"1.0\" encod...</td>\n",
       "      <td>@@ -1,23 +1,25 @@\\n &lt;div class=\"align-center\"&gt;...</td>\n",
       "      <td>add more info about nvidia gpus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4b97a810b509c93f44be4c037c7aa18fb8922884</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Pre-release 2023 December version (Mistral, Pr...</td>\n",
       "      <td>SlimOrca 1GPU.svg</td>\n",
       "      <td>DELETE</td>\n",
       "      <td>&lt;?xml version=\"1.0\" encoding=\"utf-8\" standalon...</td>\n",
       "      <td>None</td>\n",
       "      <td>@@ -1,1424 +0,0 @@\\n-&lt;?xml version=\"1.0\" encod...</td>\n",
       "      <td>@@ -1,23 +1,25 @@\\n &lt;div class=\"align-center\"&gt;...</td>\n",
       "      <td>add more info about nvidia gpus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>b753ec05c1ae49ab2fedc0e252f73c829e36b442</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>GPT OSS Bug fixes (#3231)\\n\\n* Update rl.py\\n\\...</td>\n",
       "      <td>rl.py</td>\n",
       "      <td>MODIFY</td>\n",
       "      <td># Copyright 2023-present Daniel Han-Chen &amp; the...</td>\n",
       "      <td># Copyright 2023-present Daniel Han-Chen &amp; the...</td>\n",
       "      <td>@@ -390,9 +390,17 @@ def _patch_trl_rl_trainer...</td>\n",
       "      <td>@@ -149,9 +149,6 @@ class FastLanguageModel(Fa...</td>\n",
       "      <td>add patch for unsloth vision trainer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>9050d6f5278e2373e66d17fc9ac8c2ec4f986e7e</td>\n",
       "      <td>Roland Tannous</td>\n",
       "      <td>tests for mxfp4 and quantized models merge fix...</td>\n",
       "      <td>run_test.sh</td>\n",
       "      <td>ADD</td>\n",
       "      <td>None</td>\n",
       "      <td>#!/bin/bash\\nset -e\\n\\necho \"=================...</td>\n",
       "      <td>@@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...</td>\n",
       "      <td>@@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...</td>\n",
       "      <td>add tests for merged language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>9050d6f5278e2373e66d17fc9ac8c2ec4f986e7e</td>\n",
       "      <td>Roland Tannous</td>\n",
       "      <td>tests for mxfp4 and quantized models merge fix...</td>\n",
       "      <td>test_merged_model.py</td>\n",
       "      <td>ADD</td>\n",
       "      <td>None</td>\n",
       "      <td># inference_on_merged.py\\nfrom unsloth import ...</td>\n",
       "      <td>@@ -0,0 +1,55 @@\\n+# inference_on_merged.py\\n+...</td>\n",
       "      <td>@@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...</td>\n",
       "      <td>add tests for merged language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>9050d6f5278e2373e66d17fc9ac8c2ec4f986e7e</td>\n",
       "      <td>Roland Tannous</td>\n",
       "      <td>tests for mxfp4 and quantized models merge fix...</td>\n",
       "      <td>train_and_merge.py</td>\n",
       "      <td>ADD</td>\n",
       "      <td>None</td>\n",
       "      <td># train_and_merge.py\\nfrom unsloth import Fast...</td>\n",
       "      <td>@@ -0,0 +1,71 @@\\n+# train_and_merge.py\\n+from...</td>\n",
       "      <td>@@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...</td>\n",
       "      <td>add tests for merged language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>9050d6f5278e2373e66d17fc9ac8c2ec4f986e7e</td>\n",
       "      <td>Roland Tannous</td>\n",
       "      <td>tests for mxfp4 and quantized models merge fix...</td>\n",
       "      <td>test_merge_4bit_validation.py</td>\n",
       "      <td>ADD</td>\n",
       "      <td>None</td>\n",
       "      <td>from unsloth import FastLanguageModel\\nfrom un...</td>\n",
       "      <td>@@ -0,0 +1,223 @@\\n+from unsloth import FastLa...</td>\n",
       "      <td>@@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...</td>\n",
       "      <td>add tests for merged language</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1234 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Hash          Author  \\\n",
       "0     4b97a810b509c93f44be4c037c7aa18fb8922884      Daniel Han   \n",
       "1     4b97a810b509c93f44be4c037c7aa18fb8922884      Daniel Han   \n",
       "2     4b97a810b509c93f44be4c037c7aa18fb8922884      Daniel Han   \n",
       "3     4b97a810b509c93f44be4c037c7aa18fb8922884      Daniel Han   \n",
       "4     4b97a810b509c93f44be4c037c7aa18fb8922884      Daniel Han   \n",
       "...                                        ...             ...   \n",
       "1229  b753ec05c1ae49ab2fedc0e252f73c829e36b442      Daniel Han   \n",
       "1230  9050d6f5278e2373e66d17fc9ac8c2ec4f986e7e  Roland Tannous   \n",
       "1231  9050d6f5278e2373e66d17fc9ac8c2ec4f986e7e  Roland Tannous   \n",
       "1232  9050d6f5278e2373e66d17fc9ac8c2ec4f986e7e  Roland Tannous   \n",
       "1233  9050d6f5278e2373e66d17fc9ac8c2ec4f986e7e  Roland Tannous   \n",
       "\n",
       "                                                Message  \\\n",
       "0     Pre-release 2023 December version (Mistral, Pr...   \n",
       "1     Pre-release 2023 December version (Mistral, Pr...   \n",
       "2     Pre-release 2023 December version (Mistral, Pr...   \n",
       "3     Pre-release 2023 December version (Mistral, Pr...   \n",
       "4     Pre-release 2023 December version (Mistral, Pr...   \n",
       "...                                                 ...   \n",
       "1229  GPT OSS Bug fixes (#3231)\\n\\n* Update rl.py\\n\\...   \n",
       "1230  tests for mxfp4 and quantized models merge fix...   \n",
       "1231  tests for mxfp4 and quantized models merge fix...   \n",
       "1232  tests for mxfp4 and quantized models merge fix...   \n",
       "1233  tests for mxfp4 and quantized models merge fix...   \n",
       "\n",
       "                           Filename Change Type  \\\n",
       "0                         README.md      MODIFY   \n",
       "1                       Discord.png      MODIFY   \n",
       "2                    LAION 2GPU.png         ADD   \n",
       "3                    LAION 2GPU.svg      DELETE   \n",
       "4                 SlimOrca 1GPU.svg      DELETE   \n",
       "...                             ...         ...   \n",
       "1229                          rl.py      MODIFY   \n",
       "1230                    run_test.sh         ADD   \n",
       "1231           test_merged_model.py         ADD   \n",
       "1232             train_and_merge.py         ADD   \n",
       "1233  test_merge_4bit_validation.py         ADD   \n",
       "\n",
       "                                   Source Code (before)  \\\n",
       "0     <div class=\"align-center\">\\n  <img src=\"./imag...   \n",
       "1     PNG\\r\\n\u001a\\n\u0000\u0000\u0000\\rIHDR\u0000\u0000\u0006\u0000\u0000\u0001\b\u0006\u0000\u0000\u0000\u000e\u0006\u0000\u0000\u0000\u0001sRGB\u0000\n",
       "\u0000\u0000\u0000\u0004...   \n",
       "2                                                  None   \n",
       "3     <?xml version=\"1.0\" encoding=\"utf-8\" standalon...   \n",
       "4     <?xml version=\"1.0\" encoding=\"utf-8\" standalon...   \n",
       "...                                                 ...   \n",
       "1229  # Copyright 2023-present Daniel Han-Chen & the...   \n",
       "1230                                               None   \n",
       "1231                                               None   \n",
       "1232                                               None   \n",
       "1233                                               None   \n",
       "\n",
       "                                  Source Code (current)  \\\n",
       "0     <div class=\"align-center\">\\n  <img src=\"./imag...   \n",
       "1     PNG\\r\\n\u001a\\n\u0000\u0000\u0000\\rIHDR\u0000\u0000\u0003}\u0000\u0000\u0001\u0004\b\u0006\u0000\u0000\u00008]\u0000\u0000 \u0000IDATx\\t\u0014...   \n",
       "2     PNG\\r\\n\u001a\\n\u0000\u0000\u0000\\rIHDR\u0000\u0000\u0003\u0000\u0000\u0002A\b\u0006\u0000\u0000\u0001\u0011\u0000\u0000ȫIDATx\u0001\n",
       "\\k]\\...   \n",
       "3                                                  None   \n",
       "4                                                  None   \n",
       "...                                                 ...   \n",
       "1229  # Copyright 2023-present Daniel Han-Chen & the...   \n",
       "1230  #!/bin/bash\\nset -e\\n\\necho \"=================...   \n",
       "1231  # inference_on_merged.py\\nfrom unsloth import ...   \n",
       "1232  # train_and_merge.py\\nfrom unsloth import Fast...   \n",
       "1233  from unsloth import FastLanguageModel\\nfrom un...   \n",
       "\n",
       "                                                   Diff  \\\n",
       "0     @@ -1,23 +1,25 @@\\n <div class=\"align-center\">...   \n",
       "1     Binary files a/images/Discord.png and b/images...   \n",
       "2     Binary files /dev/null and b/images/LAION 2GPU...   \n",
       "3     @@ -1,1518 +0,0 @@\\n-<?xml version=\"1.0\" encod...   \n",
       "4     @@ -1,1424 +0,0 @@\\n-<?xml version=\"1.0\" encod...   \n",
       "...                                                 ...   \n",
       "1229  @@ -390,9 +390,17 @@ def _patch_trl_rl_trainer...   \n",
       "1230  @@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...   \n",
       "1231  @@ -0,0 +1,55 @@\\n+# inference_on_merged.py\\n+...   \n",
       "1232  @@ -0,0 +1,71 @@\\n+# train_and_merge.py\\n+from...   \n",
       "1233  @@ -0,0 +1,223 @@\\n+from unsloth import FastLa...   \n",
       "\n",
       "                                           overall_diff  \\\n",
       "0     @@ -1,23 +1,25 @@\\n <div class=\"align-center\">...   \n",
       "1     @@ -1,23 +1,25 @@\\n <div class=\"align-center\">...   \n",
       "2     @@ -1,23 +1,25 @@\\n <div class=\"align-center\">...   \n",
       "3     @@ -1,23 +1,25 @@\\n <div class=\"align-center\">...   \n",
       "4     @@ -1,23 +1,25 @@\\n <div class=\"align-center\">...   \n",
       "...                                                 ...   \n",
       "1229  @@ -149,9 +149,6 @@ class FastLanguageModel(Fa...   \n",
       "1230  @@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...   \n",
       "1231  @@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...   \n",
       "1232  @@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...   \n",
       "1233  @@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...   \n",
       "\n",
       "                         Rectified Message  \n",
       "0          add more info about nvidia gpus  \n",
       "1          add more info about nvidia gpus  \n",
       "2          add more info about nvidia gpus  \n",
       "3          add more info about nvidia gpus  \n",
       "4          add more info about nvidia gpus  \n",
       "...                                    ...  \n",
       "1229  add patch for unsloth vision trainer  \n",
       "1230         add tests for merged language  \n",
       "1231         add tests for merged language  \n",
       "1232         add tests for merged language  \n",
       "1233         add tests for merged language  \n",
       "\n",
       "[1234 rows x 10 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "candidates = commit_messages  # e.g., [\"fix bug in array indexing\", ...]\n",
    "references = git_diffs        # e.g., [\"- arr[i+1] -> arr[i]\", ...]\n",
    "\n",
    "P, R, F1 = score(candidates, references, lang=\"en\", model_type=\"microsoft/codebert-base\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T18:42:56.724690Z",
     "iopub.status.busy": "2025-09-01T18:42:56.724059Z",
     "iopub.status.idle": "2025-09-01T18:42:56.836223Z",
     "shell.execute_reply": "2025-09-01T18:42:56.835546Z",
     "shell.execute_reply.started": "2025-09-01T18:42:56.724639Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diffs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diff --git a/pyproject.toml b/pyproject.toml\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>diff --git a/pyproject.toml b/pyproject.toml\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>diff --git a/unsloth/kernels/cross_entropy_los...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>diff --git a/unsloth/models/llama.py b/unsloth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>diff --git a/README.md b/README.md\\nindex 1f85...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>diff --git a/unsloth/kernels/cross_entropy_los...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>diff --git a/unsloth/models/dpo.py b/unsloth/m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>diff --git a/unsloth/chat_templates.py b/unslo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>diff --git a/unsloth/models/_utils.py b/unslot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>diff --git a/unsloth/models/llama.py b/unsloth...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>342 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 diffs\n",
       "0    diff --git a/pyproject.toml b/pyproject.toml\\n...\n",
       "1    diff --git a/pyproject.toml b/pyproject.toml\\n...\n",
       "2    diff --git a/unsloth/kernels/cross_entropy_los...\n",
       "3    diff --git a/unsloth/models/llama.py b/unsloth...\n",
       "4    diff --git a/README.md b/README.md\\nindex 1f85...\n",
       "..                                                 ...\n",
       "337  diff --git a/unsloth/kernels/cross_entropy_los...\n",
       "338  diff --git a/unsloth/models/dpo.py b/unsloth/m...\n",
       "339  diff --git a/unsloth/chat_templates.py b/unslo...\n",
       "340  diff --git a/unsloth/models/_utils.py b/unslot...\n",
       "341  diff --git a/unsloth/models/llama.py b/unsloth...\n",
       "\n",
       "[342 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "diffs_df = pd.read_csv('/kaggle/input/stt-labs/diffs.csv')\n",
    "diffs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T19:09:22.932708Z",
     "iopub.status.busy": "2025-09-01T19:09:22.932376Z",
     "iopub.status.idle": "2025-09-01T19:09:22.976437Z",
     "shell.execute_reply": "2025-09-01T19:09:22.975461Z",
     "shell.execute_reply.started": "2025-09-01T19:09:22.932652Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'concat_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_36/1891470293.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mcommit_hash\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconcat_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Hash'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mcommit_diff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_commit_diff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommit_hash\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommit_diff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'concat_df' is not defined"
     ]
    }
   ],
   "source": [
    "repo_path = \"/kaggle/working/unsloth\"\n",
    "\n",
    "def get_commit_diff(repo_path, commit_hash):\n",
    "    result = subprocess.run(\n",
    "        [\"git\", \"-C\", repo_path, \"diff\", f\"{commit_hash}^\", commit_hash],\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        encoding=\"utf-8\",\n",
    "        errors=\"replace\"\n",
    "    )\n",
    "    return result.stdout\n",
    "\n",
    "L = []\n",
    "for commit_hash in concat_df['Hash'].to_list():\n",
    "    commit_diff = get_commit_diff(repo_path, commit_hash)\n",
    "    L.append(commit_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T18:48:47.401799Z",
     "iopub.status.busy": "2025-09-01T18:48:47.401472Z",
     "iopub.status.idle": "2025-09-01T18:50:27.897813Z",
     "shell.execute_reply": "2025-09-01T18:50:27.897029Z",
     "shell.execute_reply.started": "2025-09-01T18:48:47.401776Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   0%|          | 0/18 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 20 : 5.816177129745483 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   6%|▌         | 1/18 [00:06<01:48,  6.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 20 : 4.873705148696899 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  11%|█         | 2/18 [00:11<01:32,  5.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 20 : 6.001535415649414 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  17%|█▋        | 3/18 [00:18<01:31,  6.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 20 : 5.470132112503052 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  22%|██▏       | 4/18 [00:24<01:25,  6.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 20 : 5.203893423080444 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  28%|██▊       | 5/18 [00:30<01:17,  5.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 20 : 5.48878812789917 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  33%|███▎      | 6/18 [00:36<01:12,  6.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 20 : 5.796406030654907 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  39%|███▉      | 7/18 [00:42<01:07,  6.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 20 : 5.244203090667725 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  44%|████▍     | 8/18 [00:48<00:59,  5.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 20 : 5.232848644256592 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  50%|█████     | 9/18 [00:53<00:53,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 20 : 5.223268032073975 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  56%|█████▌    | 10/18 [00:59<00:46,  5.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 20 : 4.908747434616089 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  61%|██████    | 11/18 [01:04<00:39,  5.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 20 : 5.484987497329712 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  67%|██████▋   | 12/18 [01:10<00:34,  5.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 20 : 5.713092088699341 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  72%|███████▏  | 13/18 [01:17<00:29,  5.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 20 : 4.879076957702637 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  78%|███████▊  | 14/18 [01:22<00:23,  5.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 20 : 5.170987606048584 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  83%|████████▎ | 15/18 [01:28<00:17,  5.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 20 : 4.887123107910156 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  89%|████████▉ | 16/18 [01:33<00:11,  5.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 20 : 5.447272777557373 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  94%|█████████▍| 17/18 [01:39<00:05,  5.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for batch of 2 : 0.6332879066467285 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 18/18 [01:40<00:00,  5.58s/it]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "BATCH_SIZE = 20\n",
    "for i in tqdm(range(0, len(diffs_df), BATCH_SIZE), desc=\"Processing batches\"):\n",
    "    batch_texts = diffs_df[\"diffs\"].iloc[i:i+BATCH_SIZE].tolist()\n",
    "    preds = predict_batch(model, batch_texts, device=\"cuda\")\n",
    "    diffs_df.loc[i:i+len(preds)-1, \"Rectified Message\"] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T19:32:02.259749Z",
     "iopub.status.busy": "2025-09-01T19:32:02.259430Z",
     "iopub.status.idle": "2025-09-01T19:32:02.298960Z",
     "shell.execute_reply": "2025-09-01T19:32:02.298017Z",
     "shell.execute_reply.started": "2025-09-01T19:32:02.259725Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hash</th>\n",
       "      <th>Diff_x</th>\n",
       "      <th>Author</th>\n",
       "      <th>Message</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Change Type</th>\n",
       "      <th>Source Code (before)</th>\n",
       "      <th>Source Code (current)</th>\n",
       "      <th>Diff_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0096445910418fe051d4b3eb0f866ee781344b76</td>\n",
       "      <td>[@@ -37,7 +37,7 @@ triton = [\\n ]\\n \\n hugging...</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Nightly (#2448)\\n\\n* move float32\\n\\n* Ensure ...</td>\n",
       "      <td>pyproject.toml</td>\n",
       "      <td>MODIFY</td>\n",
       "      <td>[build-system]\\nrequires = [\"setuptools\", \"set...</td>\n",
       "      <td>[build-system]\\nrequires = [\"setuptools\", \"set...</td>\n",
       "      <td>@@ -37,7 +37,7 @@ triton = [\\n ]\\n \\n huggingf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0096445910418fe051d4b3eb0f866ee781344b76</td>\n",
       "      <td>[@@ -37,7 +37,7 @@ triton = [\\n ]\\n \\n hugging...</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Nightly (#2448)\\n\\n* move float32\\n\\n* Ensure ...</td>\n",
       "      <td>synthetic.py</td>\n",
       "      <td>MODIFY</td>\n",
       "      <td># Copyright 2023-present Daniel Han-Chen &amp; the...</td>\n",
       "      <td># Copyright 2023-present Daniel Han-Chen &amp; the...</td>\n",
       "      <td>@@ -18,13 +18,16 @@ __all__ = [\\n import subpr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0096445910418fe051d4b3eb0f866ee781344b76</td>\n",
       "      <td>[@@ -37,7 +37,7 @@ triton = [\\n ]\\n \\n hugging...</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Nightly (#2448)\\n\\n* move float32\\n\\n* Ensure ...</td>\n",
       "      <td>_utils.py</td>\n",
       "      <td>MODIFY</td>\n",
       "      <td># Copyright 2023-present Daniel Han-Chen &amp; the...</td>\n",
       "      <td># Copyright 2023-present Daniel Han-Chen &amp; the...</td>\n",
       "      <td>@@ -12,7 +12,7 @@\\n # See the License for the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>016315eb0495135c78235fff9684cb8759ff0b64</td>\n",
       "      <td>[@@ -187,9 +187,9 @@ cu124onlytorch260 = [\\n  ...</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Fix bugs (#1701)\\n\\n* Phi 4\\r\\n\\r\\n* Update ll...</td>\n",
       "      <td>pyproject.toml</td>\n",
       "      <td>MODIFY</td>\n",
       "      <td>[build-system]\\nrequires = [\"setuptools\", \"set...</td>\n",
       "      <td>[build-system]\\nrequires = [\"setuptools\", \"set...</td>\n",
       "      <td>@@ -187,9 +187,9 @@ cu124onlytorch260 = [\\n   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>016315eb0495135c78235fff9684cb8759ff0b64</td>\n",
       "      <td>[@@ -187,9 +187,9 @@ cu124onlytorch260 = [\\n  ...</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Fix bugs (#1701)\\n\\n* Phi 4\\r\\n\\r\\n* Update ll...</td>\n",
       "      <td>_utils.py</td>\n",
       "      <td>MODIFY</td>\n",
       "      <td># Copyright 2023-present Daniel Han-Chen &amp; the...</td>\n",
       "      <td># Copyright 2023-present Daniel Han-Chen &amp; the...</td>\n",
       "      <td>@@ -12,7 +12,7 @@\\n # See the License for the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>ff18cb3a7436b3ad7f7c189834dff81f7526ee61</td>\n",
       "      <td>[@@ -12,7 +12,7 @@\\n # See the License for the...</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Bug fix</td>\n",
       "      <td>_utils.py</td>\n",
       "      <td>MODIFY</td>\n",
       "      <td># Copyright 2023-present Daniel Han-Chen &amp; the...</td>\n",
       "      <td># Copyright 2023-present Daniel Han-Chen &amp; the...</td>\n",
       "      <td>@@ -12,7 +12,7 @@\\n # See the License for the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>ff18cb3a7436b3ad7f7c189834dff81f7526ee61</td>\n",
       "      <td>[@@ -12,7 +12,7 @@\\n # See the License for the...</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Bug fix</td>\n",
       "      <td>tokenizer_utils.py</td>\n",
       "      <td>MODIFY</td>\n",
       "      <td># Copyright 2023-present Daniel Han-Chen &amp; the...</td>\n",
       "      <td># Copyright 2023-present Daniel Han-Chen &amp; the...</td>\n",
       "      <td>@@ -859,6 +859,7 @@ pass\\n \\n import inspect\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>ff75eb700f98800159a45ae2a4924955d10b3afd</td>\n",
       "      <td>[@@ -23,6 +23,7 @@ from ._utils import __versi...</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Qwen3 bug fixes</td>\n",
       "      <td>llama.py</td>\n",
       "      <td>MODIFY</td>\n",
       "      <td># Copyright 2023-present Daniel Han-Chen &amp; the...</td>\n",
       "      <td># Copyright 2023-present Daniel Han-Chen &amp; the...</td>\n",
       "      <td>@@ -23,6 +23,7 @@ from ._utils import __versio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>ff75eb700f98800159a45ae2a4924955d10b3afd</td>\n",
       "      <td>[@@ -23,6 +23,7 @@ from ._utils import __versi...</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Qwen3 bug fixes</td>\n",
       "      <td>loader_utils.py</td>\n",
       "      <td>MODIFY</td>\n",
       "      <td># Copyright 2023-present Daniel Han-Chen &amp; the...</td>\n",
       "      <td># Copyright 2023-present Daniel Han-Chen &amp; the...</td>\n",
       "      <td>@@ -19,6 +19,12 @@ from transformers import __...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>ff75eb700f98800159a45ae2a4924955d10b3afd</td>\n",
       "      <td>[@@ -23,6 +23,7 @@ from ._utils import __versi...</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Qwen3 bug fixes</td>\n",
       "      <td>mapper.py</td>\n",
       "      <td>MODIFY</td>\n",
       "      <td># Copyright 2023-present Daniel Han-Chen &amp; the...</td>\n",
       "      <td># Copyright 2023-present Daniel Han-Chen &amp; the...</td>\n",
       "      <td>@@ -763,9 +763,15 @@ __INT_TO_FLOAT_MAPPER = \\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1234 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Hash  \\\n",
       "0     0096445910418fe051d4b3eb0f866ee781344b76   \n",
       "1     0096445910418fe051d4b3eb0f866ee781344b76   \n",
       "2     0096445910418fe051d4b3eb0f866ee781344b76   \n",
       "3     016315eb0495135c78235fff9684cb8759ff0b64   \n",
       "4     016315eb0495135c78235fff9684cb8759ff0b64   \n",
       "...                                        ...   \n",
       "1229  ff18cb3a7436b3ad7f7c189834dff81f7526ee61   \n",
       "1230  ff18cb3a7436b3ad7f7c189834dff81f7526ee61   \n",
       "1231  ff75eb700f98800159a45ae2a4924955d10b3afd   \n",
       "1232  ff75eb700f98800159a45ae2a4924955d10b3afd   \n",
       "1233  ff75eb700f98800159a45ae2a4924955d10b3afd   \n",
       "\n",
       "                                                 Diff_x      Author  \\\n",
       "0     [@@ -37,7 +37,7 @@ triton = [\\n ]\\n \\n hugging...  Daniel Han   \n",
       "1     [@@ -37,7 +37,7 @@ triton = [\\n ]\\n \\n hugging...  Daniel Han   \n",
       "2     [@@ -37,7 +37,7 @@ triton = [\\n ]\\n \\n hugging...  Daniel Han   \n",
       "3     [@@ -187,9 +187,9 @@ cu124onlytorch260 = [\\n  ...  Daniel Han   \n",
       "4     [@@ -187,9 +187,9 @@ cu124onlytorch260 = [\\n  ...  Daniel Han   \n",
       "...                                                 ...         ...   \n",
       "1229  [@@ -12,7 +12,7 @@\\n # See the License for the...  Daniel Han   \n",
       "1230  [@@ -12,7 +12,7 @@\\n # See the License for the...  Daniel Han   \n",
       "1231  [@@ -23,6 +23,7 @@ from ._utils import __versi...  Daniel Han   \n",
       "1232  [@@ -23,6 +23,7 @@ from ._utils import __versi...  Daniel Han   \n",
       "1233  [@@ -23,6 +23,7 @@ from ._utils import __versi...  Daniel Han   \n",
       "\n",
       "                                                Message            Filename  \\\n",
       "0     Nightly (#2448)\\n\\n* move float32\\n\\n* Ensure ...      pyproject.toml   \n",
       "1     Nightly (#2448)\\n\\n* move float32\\n\\n* Ensure ...        synthetic.py   \n",
       "2     Nightly (#2448)\\n\\n* move float32\\n\\n* Ensure ...           _utils.py   \n",
       "3     Fix bugs (#1701)\\n\\n* Phi 4\\r\\n\\r\\n* Update ll...      pyproject.toml   \n",
       "4     Fix bugs (#1701)\\n\\n* Phi 4\\r\\n\\r\\n* Update ll...           _utils.py   \n",
       "...                                                 ...                 ...   \n",
       "1229                                            Bug fix           _utils.py   \n",
       "1230                                            Bug fix  tokenizer_utils.py   \n",
       "1231                                    Qwen3 bug fixes            llama.py   \n",
       "1232                                    Qwen3 bug fixes     loader_utils.py   \n",
       "1233                                    Qwen3 bug fixes           mapper.py   \n",
       "\n",
       "     Change Type                               Source Code (before)  \\\n",
       "0         MODIFY  [build-system]\\nrequires = [\"setuptools\", \"set...   \n",
       "1         MODIFY  # Copyright 2023-present Daniel Han-Chen & the...   \n",
       "2         MODIFY  # Copyright 2023-present Daniel Han-Chen & the...   \n",
       "3         MODIFY  [build-system]\\nrequires = [\"setuptools\", \"set...   \n",
       "4         MODIFY  # Copyright 2023-present Daniel Han-Chen & the...   \n",
       "...          ...                                                ...   \n",
       "1229      MODIFY  # Copyright 2023-present Daniel Han-Chen & the...   \n",
       "1230      MODIFY  # Copyright 2023-present Daniel Han-Chen & the...   \n",
       "1231      MODIFY  # Copyright 2023-present Daniel Han-Chen & the...   \n",
       "1232      MODIFY  # Copyright 2023-present Daniel Han-Chen & the...   \n",
       "1233      MODIFY  # Copyright 2023-present Daniel Han-Chen & the...   \n",
       "\n",
       "                                  Source Code (current)  \\\n",
       "0     [build-system]\\nrequires = [\"setuptools\", \"set...   \n",
       "1     # Copyright 2023-present Daniel Han-Chen & the...   \n",
       "2     # Copyright 2023-present Daniel Han-Chen & the...   \n",
       "3     [build-system]\\nrequires = [\"setuptools\", \"set...   \n",
       "4     # Copyright 2023-present Daniel Han-Chen & the...   \n",
       "...                                                 ...   \n",
       "1229  # Copyright 2023-present Daniel Han-Chen & the...   \n",
       "1230  # Copyright 2023-present Daniel Han-Chen & the...   \n",
       "1231  # Copyright 2023-present Daniel Han-Chen & the...   \n",
       "1232  # Copyright 2023-present Daniel Han-Chen & the...   \n",
       "1233  # Copyright 2023-present Daniel Han-Chen & the...   \n",
       "\n",
       "                                                 Diff_y  \n",
       "0     @@ -37,7 +37,7 @@ triton = [\\n ]\\n \\n huggingf...  \n",
       "1     @@ -18,13 +18,16 @@ __all__ = [\\n import subpr...  \n",
       "2     @@ -12,7 +12,7 @@\\n # See the License for the ...  \n",
       "3     @@ -187,9 +187,9 @@ cu124onlytorch260 = [\\n   ...  \n",
       "4     @@ -12,7 +12,7 @@\\n # See the License for the ...  \n",
       "...                                                 ...  \n",
       "1229  @@ -12,7 +12,7 @@\\n # See the License for the ...  \n",
       "1230  @@ -859,6 +859,7 @@ pass\\n \\n import inspect\\n...  \n",
       "1231  @@ -23,6 +23,7 @@ from ._utils import __versio...  \n",
       "1232  @@ -19,6 +19,12 @@ from transformers import __...  \n",
       "1233  @@ -763,9 +763,15 @@ __INT_TO_FLOAT_MAPPER = \\...  \n",
       "\n",
       "[1234 rows x 9 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T19:31:03.464093Z",
     "iopub.status.busy": "2025-09-01T19:31:03.463784Z",
     "iopub.status.idle": "2025-09-01T19:31:03.474478Z",
     "shell.execute_reply": "2025-09-01T19:31:03.473536Z",
     "shell.execute_reply.started": "2025-09-01T19:31:03.464070Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diffs</th>\n",
       "      <th>Rectified Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diff --git a/pyproject.toml b/pyproject.toml\\n...</td>\n",
       "      <td>add huggingface and colab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>diff --git a/pyproject.toml b/pyproject.toml\\n...</td>\n",
       "      <td>add tests for python 3.10 and 3.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>diff --git a/unsloth/kernels/cross_entropy_los...</td>\n",
       "      <td>add examples for large vocabs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>diff --git a/unsloth/models/llama.py b/unsloth...</td>\n",
       "      <td>update unsloth_llama.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>diff --git a/README.md b/README.md\\nindex 1f85...</td>\n",
       "      <td>add docs for unsloth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>diff --git a/unsloth/kernels/cross_entropy_los...</td>\n",
       "      <td>update unsloth.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>diff --git a/unsloth/models/dpo.py b/unsloth/m...</td>\n",
       "      <td>update inner_table in notebooks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>diff --git a/unsloth/chat_templates.py b/unslo...</td>\n",
       "      <td>add default_system_message</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>diff --git a/unsloth/models/_utils.py b/unslot...</td>\n",
       "      <td>add sft_trainer patch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>diff --git a/unsloth/models/llama.py b/unsloth...</td>\n",
       "      <td>add support for dynamic quant in unsloth</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>342 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 diffs  \\\n",
       "0    diff --git a/pyproject.toml b/pyproject.toml\\n...   \n",
       "1    diff --git a/pyproject.toml b/pyproject.toml\\n...   \n",
       "2    diff --git a/unsloth/kernels/cross_entropy_los...   \n",
       "3    diff --git a/unsloth/models/llama.py b/unsloth...   \n",
       "4    diff --git a/README.md b/README.md\\nindex 1f85...   \n",
       "..                                                 ...   \n",
       "337  diff --git a/unsloth/kernels/cross_entropy_los...   \n",
       "338  diff --git a/unsloth/models/dpo.py b/unsloth/m...   \n",
       "339  diff --git a/unsloth/chat_templates.py b/unslo...   \n",
       "340  diff --git a/unsloth/models/_utils.py b/unslot...   \n",
       "341  diff --git a/unsloth/models/llama.py b/unsloth...   \n",
       "\n",
       "                            Rectified Message  \n",
       "0                   add huggingface and colab  \n",
       "1          add tests for python 3.10 and 3.11  \n",
       "2               add examples for large vocabs  \n",
       "3                     update unsloth_llama.py  \n",
       "4                        add docs for unsloth  \n",
       "..                                        ...  \n",
       "337                         update unsloth.py  \n",
       "338           update inner_table in notebooks  \n",
       "339                add default_system_message  \n",
       "340                     add sft_trainer patch  \n",
       "341  add support for dynamic quant in unsloth  \n",
       "\n",
       "[342 rows x 2 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T18:27:06.136050Z",
     "iopub.status.busy": "2025-09-01T18:27:06.135546Z",
     "iopub.status.idle": "2025-09-01T18:27:06.140393Z",
     "shell.execute_reply": "2025-09-01T18:27:06.139640Z",
     "shell.execute_reply.started": "2025-09-01T18:27:06.136023Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def get_diff_with_algo(repo_path, commit_hash, parent_hash, file_path, algorithm):\n",
    "    \"\"\"\n",
    "    Returns the git diff of a file between commit_hash and its parent using the given algorithm.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\n",
    "                \"git\", \"-C\", repo_path,\n",
    "                \"diff\", f\"{parent_hash}\", f\"{commit_hash}\",\n",
    "                \"--\", file_path,\n",
    "                f\"--diff-algorithm={algorithm}\"\n",
    "            ],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            check=True\n",
    "        )\n",
    "        return result.stdout\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        return f\"Error running git diff with {algorithm}: {e.stderr}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T17:55:39.818210Z",
     "iopub.status.busy": "2025-08-22T17:55:39.817995Z",
     "iopub.status.idle": "2025-08-22T17:55:39.830632Z",
     "shell.execute_reply": "2025-08-22T17:55:39.829882Z",
     "shell.execute_reply.started": "2025-08-22T17:55:39.818185Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2655.352078239609\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(df2)):\n",
    "    count += len(df2['Diff'].iloc[i])\n",
    "print(count/len(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T09:56:19.136697Z",
     "iopub.status.busy": "2025-08-25T09:56:19.136421Z",
     "iopub.status.idle": "2025-08-25T09:56:46.615674Z",
     "shell.execute_reply": "2025-08-25T09:56:46.614913Z",
     "shell.execute_reply.started": "2025-08-25T09:56:19.136676Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.457013607025146\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pydriller import Repository\n",
    "import time\n",
    "\n",
    "rows = []\n",
    "rows2 = []\n",
    "# repo_link = 'https://github.com/google-deepmind/alphafold'\n",
    "# repo_link = 'https://github.com/unslothai/unsloth'\n",
    "repo_link =\"https://github.com/JakeWharton/butterknife\"\n",
    "start_time = time.time()\n",
    "for commit in Repository(repo_link).traverse_commits():\n",
    "            rows.append({\n",
    "                'Hash': commit.hash,\n",
    "                'Author' : commit.author.name,\n",
    "                'Message': commit.msg,\n",
    "                'Hashes of parents': commit.parents,\n",
    "                'Is a merge commit?': len(commit.parents) > 1,\n",
    "                'List of modified files': [mod.filename for mod in commit.modified_files],\n",
    "            })\n",
    "            if not commit.parents:\n",
    "                continue\n",
    "            for mod in commit.modified_files:\n",
    "                rows2.append({\n",
    "                    'old_file_path': mod.old_path,\n",
    "                    'new_file_path': mod.new_path,\n",
    "                    'commit SHA': commit.hash,\n",
    "                    'parent commit SHA': commit.parents,\n",
    "                    'author' : commit.author.name,\n",
    "                    'commit message': commit.msg,\n",
    "                    'filename' : mod.filename,\n",
    "                    'change Type': mod.change_type.name,\n",
    "                    'diff_myers' : get_diff_with_algo(commit.project_path, commit.hash, commit.parents[0], mod.new_path or mod.old_path, 'myers'),\n",
    "                    'diff_histogram' : get_diff_with_algo(commit.project_path, commit.hash, commit.parents[0], mod.new_path or mod.old_path, 'histogram')\n",
    "                })\n",
    "end_time = time.time()\n",
    "print(end_time-start_time)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(rows)\n",
    "df2 = pd.DataFrame(rows2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T10:00:20.141956Z",
     "iopub.status.busy": "2025-08-25T10:00:20.141473Z",
     "iopub.status.idle": "2025-08-25T10:00:20.187003Z",
     "shell.execute_reply": "2025-08-25T10:00:20.186500Z",
     "shell.execute_reply.started": "2025-08-25T10:00:20.141936Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(df2)):\n",
    "    if df2['diff_myers'].iloc[i] != df2['diff_histogram'].iloc[i]:\n",
    "        print(\"Diffs are different for commit:\", df2['commit SHA'].iloc[i], \"file:\", df2['filename'].iloc[i])\n",
    "        print(\"Myers Diff:\\n\", df2['diff_myers'].iloc[i])\n",
    "        print(\"Histogram Diff:\\n\", df2['diff_histogram'].iloc[i])\n",
    "        print(\"--------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T09:56:54.472921Z",
     "iopub.status.busy": "2025-08-25T09:56:54.472425Z",
     "iopub.status.idle": "2025-08-25T09:56:54.486565Z",
     "shell.execute_reply": "2025-08-25T09:56:54.485995Z",
     "shell.execute_reply.started": "2025-08-25T09:56:54.472893Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>old_file_path</th>\n",
       "      <th>new_file_path</th>\n",
       "      <th>commit SHA</th>\n",
       "      <th>parent commit SHA</th>\n",
       "      <th>author</th>\n",
       "      <th>commit message</th>\n",
       "      <th>filename</th>\n",
       "      <th>change Type</th>\n",
       "      <th>diff_myers</th>\n",
       "      <th>diff_histogram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>butterknife-sample/pom.xml</td>\n",
       "      <td>butterknife-sample/pom.xml</td>\n",
       "      <td>49ff3819f60cb11fe1505b13ec2dff6dae71022a</td>\n",
       "      <td>[8b971011893613245ab662450ee6555c30333c7f]</td>\n",
       "      <td>Jake Wharton</td>\n",
       "      <td>[maven-release-plugin] prepare release butterk...</td>\n",
       "      <td>pom.xml</td>\n",
       "      <td>MODIFY</td>\n",
       "      <td>diff --git a/butterknife-sample/pom.xml b/butt...</td>\n",
       "      <td>diff --git a/butterknife-sample/pom.xml b/butt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>butterknife/pom.xml</td>\n",
       "      <td>butterknife/pom.xml</td>\n",
       "      <td>49ff3819f60cb11fe1505b13ec2dff6dae71022a</td>\n",
       "      <td>[8b971011893613245ab662450ee6555c30333c7f]</td>\n",
       "      <td>Jake Wharton</td>\n",
       "      <td>[maven-release-plugin] prepare release butterk...</td>\n",
       "      <td>pom.xml</td>\n",
       "      <td>MODIFY</td>\n",
       "      <td>diff --git a/butterknife/pom.xml b/butterknife...</td>\n",
       "      <td>diff --git a/butterknife/pom.xml b/butterknife...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pom.xml</td>\n",
       "      <td>pom.xml</td>\n",
       "      <td>49ff3819f60cb11fe1505b13ec2dff6dae71022a</td>\n",
       "      <td>[8b971011893613245ab662450ee6555c30333c7f]</td>\n",
       "      <td>Jake Wharton</td>\n",
       "      <td>[maven-release-plugin] prepare release butterk...</td>\n",
       "      <td>pom.xml</td>\n",
       "      <td>MODIFY</td>\n",
       "      <td>diff --git a/pom.xml b/pom.xml\\nindex 9f49fcf....</td>\n",
       "      <td>diff --git a/pom.xml b/pom.xml\\nindex 9f49fcf....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>butterknife-sample/pom.xml</td>\n",
       "      <td>butterknife-sample/pom.xml</td>\n",
       "      <td>708cb2730e3726ec51df7025e3133093790c9353</td>\n",
       "      <td>[49ff3819f60cb11fe1505b13ec2dff6dae71022a]</td>\n",
       "      <td>Jake Wharton</td>\n",
       "      <td>[maven-release-plugin] prepare for next develo...</td>\n",
       "      <td>pom.xml</td>\n",
       "      <td>MODIFY</td>\n",
       "      <td>diff --git a/butterknife-sample/pom.xml b/butt...</td>\n",
       "      <td>diff --git a/butterknife-sample/pom.xml b/butt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>butterknife/pom.xml</td>\n",
       "      <td>butterknife/pom.xml</td>\n",
       "      <td>708cb2730e3726ec51df7025e3133093790c9353</td>\n",
       "      <td>[49ff3819f60cb11fe1505b13ec2dff6dae71022a]</td>\n",
       "      <td>Jake Wharton</td>\n",
       "      <td>[maven-release-plugin] prepare for next develo...</td>\n",
       "      <td>pom.xml</td>\n",
       "      <td>MODIFY</td>\n",
       "      <td>diff --git a/butterknife/pom.xml b/butterknife...</td>\n",
       "      <td>diff --git a/butterknife/pom.xml b/butterknife...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3127</th>\n",
       "      <td>CHANGELOG.md</td>\n",
       "      <td>CHANGELOG.md</td>\n",
       "      <td>888791b1c9943ade0823d295b3b7839ce5c0fe85</td>\n",
       "      <td>[442e6c23365426faa92c55c25a09309c4ad3dbf0]</td>\n",
       "      <td>Jake Wharton</td>\n",
       "      <td>Prepare version 10.2.3</td>\n",
       "      <td>CHANGELOG.md</td>\n",
       "      <td>MODIFY</td>\n",
       "      <td>diff --git a/CHANGELOG.md b/CHANGELOG.md\\ninde...</td>\n",
       "      <td>diff --git a/CHANGELOG.md b/CHANGELOG.md\\ninde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3128</th>\n",
       "      <td>README.md</td>\n",
       "      <td>README.md</td>\n",
       "      <td>888791b1c9943ade0823d295b3b7839ce5c0fe85</td>\n",
       "      <td>[442e6c23365426faa92c55c25a09309c4ad3dbf0]</td>\n",
       "      <td>Jake Wharton</td>\n",
       "      <td>Prepare version 10.2.3</td>\n",
       "      <td>README.md</td>\n",
       "      <td>MODIFY</td>\n",
       "      <td>diff --git a/README.md b/README.md\\nindex ebdb...</td>\n",
       "      <td>diff --git a/README.md b/README.md\\nindex ebdb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3129</th>\n",
       "      <td>gradle.properties</td>\n",
       "      <td>gradle.properties</td>\n",
       "      <td>888791b1c9943ade0823d295b3b7839ce5c0fe85</td>\n",
       "      <td>[442e6c23365426faa92c55c25a09309c4ad3dbf0]</td>\n",
       "      <td>Jake Wharton</td>\n",
       "      <td>Prepare version 10.2.3</td>\n",
       "      <td>gradle.properties</td>\n",
       "      <td>MODIFY</td>\n",
       "      <td>diff --git a/gradle.properties b/gradle.proper...</td>\n",
       "      <td>diff --git a/gradle.properties b/gradle.proper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3130</th>\n",
       "      <td>gradle.properties</td>\n",
       "      <td>gradle.properties</td>\n",
       "      <td>6dd38718417e3b50b64ac0a880b6bf9f2f932124</td>\n",
       "      <td>[888791b1c9943ade0823d295b3b7839ce5c0fe85]</td>\n",
       "      <td>Jake Wharton</td>\n",
       "      <td>Prepare next development version</td>\n",
       "      <td>gradle.properties</td>\n",
       "      <td>MODIFY</td>\n",
       "      <td>diff --git a/gradle.properties b/gradle.proper...</td>\n",
       "      <td>diff --git a/gradle.properties b/gradle.proper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3131</th>\n",
       "      <td>CHANGELOG.md</td>\n",
       "      <td>CHANGELOG.md</td>\n",
       "      <td>befdad6a48ede2e73c83323e81cb8d3d578fd69d</td>\n",
       "      <td>[6dd38718417e3b50b64ac0a880b6bf9f2f932124]</td>\n",
       "      <td>Zac Sweers</td>\n",
       "      <td>Fix changelog typo</td>\n",
       "      <td>CHANGELOG.md</td>\n",
       "      <td>MODIFY</td>\n",
       "      <td>diff --git a/CHANGELOG.md b/CHANGELOG.md\\ninde...</td>\n",
       "      <td>diff --git a/CHANGELOG.md b/CHANGELOG.md\\ninde...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3132 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   old_file_path               new_file_path  \\\n",
       "0     butterknife-sample/pom.xml  butterknife-sample/pom.xml   \n",
       "1            butterknife/pom.xml         butterknife/pom.xml   \n",
       "2                        pom.xml                     pom.xml   \n",
       "3     butterknife-sample/pom.xml  butterknife-sample/pom.xml   \n",
       "4            butterknife/pom.xml         butterknife/pom.xml   \n",
       "...                          ...                         ...   \n",
       "3127                CHANGELOG.md                CHANGELOG.md   \n",
       "3128                   README.md                   README.md   \n",
       "3129           gradle.properties           gradle.properties   \n",
       "3130           gradle.properties           gradle.properties   \n",
       "3131                CHANGELOG.md                CHANGELOG.md   \n",
       "\n",
       "                                    commit SHA  \\\n",
       "0     49ff3819f60cb11fe1505b13ec2dff6dae71022a   \n",
       "1     49ff3819f60cb11fe1505b13ec2dff6dae71022a   \n",
       "2     49ff3819f60cb11fe1505b13ec2dff6dae71022a   \n",
       "3     708cb2730e3726ec51df7025e3133093790c9353   \n",
       "4     708cb2730e3726ec51df7025e3133093790c9353   \n",
       "...                                        ...   \n",
       "3127  888791b1c9943ade0823d295b3b7839ce5c0fe85   \n",
       "3128  888791b1c9943ade0823d295b3b7839ce5c0fe85   \n",
       "3129  888791b1c9943ade0823d295b3b7839ce5c0fe85   \n",
       "3130  6dd38718417e3b50b64ac0a880b6bf9f2f932124   \n",
       "3131  befdad6a48ede2e73c83323e81cb8d3d578fd69d   \n",
       "\n",
       "                               parent commit SHA        author  \\\n",
       "0     [8b971011893613245ab662450ee6555c30333c7f]  Jake Wharton   \n",
       "1     [8b971011893613245ab662450ee6555c30333c7f]  Jake Wharton   \n",
       "2     [8b971011893613245ab662450ee6555c30333c7f]  Jake Wharton   \n",
       "3     [49ff3819f60cb11fe1505b13ec2dff6dae71022a]  Jake Wharton   \n",
       "4     [49ff3819f60cb11fe1505b13ec2dff6dae71022a]  Jake Wharton   \n",
       "...                                          ...           ...   \n",
       "3127  [442e6c23365426faa92c55c25a09309c4ad3dbf0]  Jake Wharton   \n",
       "3128  [442e6c23365426faa92c55c25a09309c4ad3dbf0]  Jake Wharton   \n",
       "3129  [442e6c23365426faa92c55c25a09309c4ad3dbf0]  Jake Wharton   \n",
       "3130  [888791b1c9943ade0823d295b3b7839ce5c0fe85]  Jake Wharton   \n",
       "3131  [6dd38718417e3b50b64ac0a880b6bf9f2f932124]    Zac Sweers   \n",
       "\n",
       "                                         commit message           filename  \\\n",
       "0     [maven-release-plugin] prepare release butterk...            pom.xml   \n",
       "1     [maven-release-plugin] prepare release butterk...            pom.xml   \n",
       "2     [maven-release-plugin] prepare release butterk...            pom.xml   \n",
       "3     [maven-release-plugin] prepare for next develo...            pom.xml   \n",
       "4     [maven-release-plugin] prepare for next develo...            pom.xml   \n",
       "...                                                 ...                ...   \n",
       "3127                             Prepare version 10.2.3       CHANGELOG.md   \n",
       "3128                             Prepare version 10.2.3          README.md   \n",
       "3129                             Prepare version 10.2.3  gradle.properties   \n",
       "3130                   Prepare next development version  gradle.properties   \n",
       "3131                                 Fix changelog typo       CHANGELOG.md   \n",
       "\n",
       "     change Type                                         diff_myers  \\\n",
       "0         MODIFY  diff --git a/butterknife-sample/pom.xml b/butt...   \n",
       "1         MODIFY  diff --git a/butterknife/pom.xml b/butterknife...   \n",
       "2         MODIFY  diff --git a/pom.xml b/pom.xml\\nindex 9f49fcf....   \n",
       "3         MODIFY  diff --git a/butterknife-sample/pom.xml b/butt...   \n",
       "4         MODIFY  diff --git a/butterknife/pom.xml b/butterknife...   \n",
       "...          ...                                                ...   \n",
       "3127      MODIFY  diff --git a/CHANGELOG.md b/CHANGELOG.md\\ninde...   \n",
       "3128      MODIFY  diff --git a/README.md b/README.md\\nindex ebdb...   \n",
       "3129      MODIFY  diff --git a/gradle.properties b/gradle.proper...   \n",
       "3130      MODIFY  diff --git a/gradle.properties b/gradle.proper...   \n",
       "3131      MODIFY  diff --git a/CHANGELOG.md b/CHANGELOG.md\\ninde...   \n",
       "\n",
       "                                         diff_histogram  \n",
       "0     diff --git a/butterknife-sample/pom.xml b/butt...  \n",
       "1     diff --git a/butterknife/pom.xml b/butterknife...  \n",
       "2     diff --git a/pom.xml b/pom.xml\\nindex 9f49fcf....  \n",
       "3     diff --git a/butterknife-sample/pom.xml b/butt...  \n",
       "4     diff --git a/butterknife/pom.xml b/butterknife...  \n",
       "...                                                 ...  \n",
       "3127  diff --git a/CHANGELOG.md b/CHANGELOG.md\\ninde...  \n",
       "3128  diff --git a/README.md b/README.md\\nindex ebdb...  \n",
       "3129  diff --git a/gradle.properties b/gradle.proper...  \n",
       "3130  diff --git a/gradle.properties b/gradle.proper...  \n",
       "3131  diff --git a/CHANGELOG.md b/CHANGELOG.md\\ninde...  \n",
       "\n",
       "[3132 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T09:40:11.301160Z",
     "iopub.status.busy": "2025-09-01T09:40:11.300580Z",
     "iopub.status.idle": "2025-09-01T09:40:12.104156Z",
     "shell.execute_reply": "2025-09-01T09:40:12.103537Z",
     "shell.execute_reply.started": "2025-09-01T09:40:11.301124Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diffs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diff --git a/pyproject.toml b/pyproject.toml\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>diff --git a/pyproject.toml b/pyproject.toml\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>diff --git a/unsloth/kernels/cross_entropy_los...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>diff --git a/unsloth/models/llama.py b/unsloth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>diff --git a/README.md b/README.md\\nindex 1f85...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>diff --git a/unsloth/kernels/cross_entropy_los...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>diff --git a/unsloth/models/dpo.py b/unsloth/m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>diff --git a/unsloth/chat_templates.py b/unslo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>diff --git a/unsloth/models/_utils.py b/unslot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>diff --git a/unsloth/models/llama.py b/unsloth...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>342 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 diffs\n",
       "0    diff --git a/pyproject.toml b/pyproject.toml\\n...\n",
       "1    diff --git a/pyproject.toml b/pyproject.toml\\n...\n",
       "2    diff --git a/unsloth/kernels/cross_entropy_los...\n",
       "3    diff --git a/unsloth/models/llama.py b/unsloth...\n",
       "4    diff --git a/README.md b/README.md\\nindex 1f85...\n",
       "..                                                 ...\n",
       "337  diff --git a/unsloth/kernels/cross_entropy_los...\n",
       "338  diff --git a/unsloth/models/dpo.py b/unsloth/m...\n",
       "339  diff --git a/unsloth/chat_templates.py b/unslo...\n",
       "340  diff --git a/unsloth/models/_utils.py b/unslot...\n",
       "341  diff --git a/unsloth/models/llama.py b/unsloth...\n",
       "\n",
       "[342 rows x 1 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/kaggle/input/stt-labs/diffs.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T09:41:45.477553Z",
     "iopub.status.busy": "2025-09-01T09:41:45.477305Z",
     "iopub.status.idle": "2025-09-01T09:41:45.481768Z",
     "shell.execute_reply": "2025-09-01T09:41:45.481014Z",
     "shell.execute_reply.started": "2025-09-01T09:41:45.477532Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "diffs = df['diffs'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T09:41:53.697960Z",
     "iopub.status.busy": "2025-09-01T09:41:53.697713Z",
     "iopub.status.idle": "2025-09-01T09:42:25.004955Z",
     "shell.execute_reply": "2025-09-01T09:42:25.001477Z",
     "shell.execute_reply.started": "2025-09-01T09:41:53.697938Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3d27ae696d043a695b3542112b04ba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d43d495df854e038274e1eb9e5c53dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92eef9c34a734b1886a64c92e0b8212a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d858145e780428982ff316c6a58b76d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/57.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85d6764f6b3e4fd9ab9a33f70d5b7c8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51371a11f77b4d25a014750162811eb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-01 09:42:07.714803: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1756719727.876666      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1756719727.926105      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56be09cb83fc49fda2e371c8eeefef07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15f7180d71ad4d348b84628183c51775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Load tokenizer (CPU is fine for this)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mamiksik/CommitPredictorT5\")\n",
    "\n",
    "# Load model and move it to GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"mamiksik/CommitPredictorT5\",device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T09:42:26.249030Z",
     "iopub.status.busy": "2025-09-01T09:42:26.247534Z",
     "iopub.status.idle": "2025-09-01T09:42:26.267323Z",
     "shell.execute_reply": "2025-09-01T09:42:26.262920Z",
     "shell.execute_reply.started": "2025-09-01T09:42:26.248990Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch, gc, time\n",
    "\n",
    "def predict(model, input_text, device=\"cuda\"):\n",
    "    # Tokenize (truncate to 512 tokens)\n",
    "    inputs = tokenizer(\n",
    "        input_text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    ).to(device)\n",
    "\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            num_beams=5,\n",
    "            do_sample=True,\n",
    "            top_p=0.9,\n",
    "            max_length=64,\n",
    "            early_stopping=True\n",
    "        )\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"Time taken:\", end_time - start_time, \"seconds.\")\n",
    "\n",
    "    # Move to CPU before decoding\n",
    "    prediction = tokenizer.decode(outputs[0].cpu(), skip_special_tokens=True)\n",
    "\n",
    "    # Free memory\n",
    "    del inputs, outputs\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T17:55:39.831681Z",
     "iopub.status.busy": "2025-08-22T17:55:39.831419Z",
     "iopub.status.idle": "2025-08-22T17:55:41.555510Z",
     "shell.execute_reply": "2025-08-22T17:55:41.554865Z",
     "shell.execute_reply.started": "2025-08-22T17:55:39.831657Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T18:04:53.728882Z",
     "iopub.status.busy": "2025-08-22T18:04:53.728452Z",
     "iopub.status.idle": "2025-08-22T18:04:55.678236Z",
     "shell.execute_reply": "2025-08-22T18:04:55.677392Z",
     "shell.execute_reply.started": "2025-08-22T18:04:53.728857Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Load tokenizer (CPU is fine for this)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mamiksik/CommitPredictorT5\")\n",
    "\n",
    "# Load model and move it to GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"mamiksik/CommitPredictorT5\",device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T18:02:41.981623Z",
     "iopub.status.busy": "2025-08-22T18:02:41.980782Z",
     "iopub.status.idle": "2025-08-22T18:02:41.987913Z",
     "shell.execute_reply": "2025-08-22T18:02:41.987043Z",
     "shell.execute_reply.started": "2025-08-22T18:02:41.981596Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch, gc, time\n",
    "def predict(model, input_text):\n",
    "    # Tokenize (truncate to 512 tokens)\n",
    "    inputs = tokenizer(\n",
    "        input_text,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    print(inputs['input_ids'].shape[1])\n",
    "    # Generate prediction\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "                    **inputs,\n",
    "                    num_beams=5,       # explore 5 candidate paths\n",
    "                    do_sample=True,    # enable randomness (sampling)\n",
    "                    top_p=0.9,         # nucleus sampling → consider only top tokens that cover 90% prob mass\n",
    "                    max_length=64,     # cap output length\n",
    "                    early_stopping=True  # stop when EOS is reached\n",
    "                )\n",
    "    end_time = time.time()\n",
    "    print(\"Time taken:\",end_time-start_time,\" seconds.\")\n",
    "\n",
    "    # Decode generated tokens\n",
    "    prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    del inputs, outputs\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    return prediction\n",
    "# def predict_batch(model, texts):\n",
    "    \n",
    "#     inputs = tokenizer(\n",
    "#         texts,\n",
    "#         return_tensors=\"pt\",\n",
    "#         padding=True\n",
    "#     ).to(model.device)   \n",
    "\n",
    "#     print(\"Batch size:\", len(texts))\n",
    "#     print(\"Tokenized shape:\", inputs['input_ids'].shape)\n",
    "\n",
    "#     start_time = time.time()\n",
    "    # with torch.no_grad():\n",
    "    #     outputs = model.generate(\n",
    "    #         **inputs,\n",
    "    #         num_beams=5,\n",
    "    #         do_sample=True,\n",
    "    #         top_p=0.9,\n",
    "    #         max_length=64,\n",
    "    #         early_stopping=True\n",
    "    #     )\n",
    "#     end_time = time.time()\n",
    "#     print(\"Time taken:\", end_time - start_time, \"seconds.\")\n",
    "\n",
    "#     predictions = [tokenizer.decode(out, skip_special_tokens=True) for out in outputs]\n",
    "\n",
    "#     # cleanup\n",
    "    # del inputs, outputs\n",
    "    # torch.cuda.empty_cache()\n",
    "    # gc.collect()\n",
    "\n",
    "#     return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T18:05:02.851329Z",
     "iopub.status.busy": "2025-08-22T18:05:02.850937Z",
     "iopub.status.idle": "2025-08-22T18:05:02.860530Z",
     "shell.execute_reply": "2025-08-22T18:05:02.859572Z",
     "shell.execute_reply.started": "2025-08-22T18:05:02.851298Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch, gc, time\n",
    "\n",
    "def predict(model, input_text, device=\"cuda\"):\n",
    "    # Tokenize (truncate to 512 tokens)\n",
    "    inputs = tokenizer(\n",
    "        input_text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    ).to(device)\n",
    "\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            num_beams=5,\n",
    "            do_sample=True,\n",
    "            top_p=0.9,\n",
    "            max_length=64,\n",
    "            early_stopping=True\n",
    "        )\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"Time taken:\", end_time - start_time, \"seconds.\")\n",
    "\n",
    "    # Move to CPU before decoding\n",
    "    prediction = tokenizer.decode(outputs[0].cpu(), skip_special_tokens=True)\n",
    "\n",
    "    # Free memory\n",
    "    del inputs, outputs\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-08-22T18:05:08.628518Z",
     "iopub.status.busy": "2025-08-22T18:05:08.627484Z",
     "iopub.status.idle": "2025-08-22T18:19:48.517925Z",
     "shell.execute_reply": "2025-08-22T18:19:48.517285Z",
     "shell.execute_reply.started": "2025-08-22T18:05:08.628490Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.5187051296234131 seconds.\n",
      "Time taken: 0.18166041374206543 seconds.\n",
      "Time taken: 0.21912765502929688 seconds.\n",
      "Time taken: 0.34227991104125977 seconds.\n",
      "Time taken: 0.3212544918060303 seconds.\n",
      "Time taken: 0.18470311164855957 seconds.\n",
      "Time taken: 0.2675161361694336 seconds.\n",
      "Time taken: 0.3125009536743164 seconds.\n",
      "Time taken: 0.25447559356689453 seconds.\n",
      "Time taken: 0.3766951560974121 seconds.\n",
      "Time taken: 0.3717341423034668 seconds.\n",
      "Time taken: 0.3642141819000244 seconds.\n",
      "Time taken: 0.4668254852294922 seconds.\n",
      "Time taken: 0.44625234603881836 seconds.\n",
      "Time taken: 0.4124479293823242 seconds.\n",
      "Time taken: 0.4482462406158447 seconds.\n",
      "Time taken: 0.4084956645965576 seconds.\n",
      "Time taken: 0.3338906764984131 seconds.\n",
      "Time taken: 0.1953294277191162 seconds.\n",
      "Time taken: 0.24558639526367188 seconds.\n",
      "Time taken: 0.4740924835205078 seconds.\n",
      "Time taken: 0.37832164764404297 seconds.\n",
      "Time taken: 0.33136534690856934 seconds.\n",
      "Time taken: 0.3968327045440674 seconds.\n",
      "Time taken: 0.38266682624816895 seconds.\n",
      "Time taken: 0.38973546028137207 seconds.\n",
      "Time taken: 0.4857966899871826 seconds.\n",
      "Time taken: 0.3389277458190918 seconds.\n",
      "Time taken: 0.27162981033325195 seconds.\n",
      "Time taken: 0.35215330123901367 seconds.\n",
      "Time taken: 0.5470540523529053 seconds.\n",
      "Time taken: 0.39535975456237793 seconds.\n",
      "Time taken: 0.316861629486084 seconds.\n",
      "Time taken: 0.3075237274169922 seconds.\n",
      "Time taken: 0.38516998291015625 seconds.\n",
      "Time taken: 0.4482555389404297 seconds.\n",
      "Time taken: 0.3603017330169678 seconds.\n",
      "Time taken: 0.24605751037597656 seconds.\n",
      "Time taken: 0.3797883987426758 seconds.\n",
      "Time taken: 0.3928077220916748 seconds.\n",
      "Time taken: 0.36358141899108887 seconds.\n",
      "Time taken: 0.26848697662353516 seconds.\n",
      "Time taken: 0.2766306400299072 seconds.\n",
      "Time taken: 0.2210087776184082 seconds.\n",
      "Time taken: 0.5134449005126953 seconds.\n",
      "Time taken: 0.39233970642089844 seconds.\n",
      "Time taken: 0.3850240707397461 seconds.\n",
      "Time taken: 0.3657376766204834 seconds.\n",
      "Time taken: 0.2781093120574951 seconds.\n",
      "Time taken: 0.35573267936706543 seconds.\n",
      "Time taken: 0.3380875587463379 seconds.\n",
      "Time taken: 0.38228273391723633 seconds.\n",
      "Time taken: 0.359760046005249 seconds.\n",
      "Time taken: 0.3336188793182373 seconds.\n",
      "Time taken: 0.24088835716247559 seconds.\n",
      "Time taken: 0.5459873676300049 seconds.\n",
      "Time taken: 0.36211133003234863 seconds.\n",
      "Time taken: 0.3250434398651123 seconds.\n",
      "Time taken: 0.42619824409484863 seconds.\n",
      "Time taken: 0.37046337127685547 seconds.\n",
      "Time taken: 0.26060056686401367 seconds.\n",
      "Time taken: 0.5188937187194824 seconds.\n",
      "Time taken: 0.3711235523223877 seconds.\n",
      "Time taken: 0.3711225986480713 seconds.\n",
      "Time taken: 0.36197781562805176 seconds.\n",
      "Time taken: 0.4052097797393799 seconds.\n",
      "Time taken: 0.28886985778808594 seconds.\n",
      "Time taken: 0.32308268547058105 seconds.\n",
      "Time taken: 0.3747115135192871 seconds.\n",
      "Time taken: 0.33968615531921387 seconds.\n",
      "Time taken: 0.31194305419921875 seconds.\n",
      "Time taken: 0.37511563301086426 seconds.\n",
      "Time taken: 0.38108086585998535 seconds.\n",
      "Time taken: 0.3833951950073242 seconds.\n",
      "Time taken: 0.33823132514953613 seconds.\n",
      "Time taken: 0.3247535228729248 seconds.\n",
      "Time taken: 0.2850911617279053 seconds.\n",
      "Time taken: 0.39992284774780273 seconds.\n",
      "Time taken: 0.3383674621582031 seconds.\n",
      "Time taken: 0.34759974479675293 seconds.\n",
      "Time taken: 0.4535977840423584 seconds.\n",
      "Time taken: 0.49700117111206055 seconds.\n",
      "Time taken: 0.24794316291809082 seconds.\n",
      "Time taken: 0.3934636116027832 seconds.\n",
      "Time taken: 0.3401937484741211 seconds.\n",
      "Time taken: 0.2676825523376465 seconds.\n",
      "Time taken: 0.35472917556762695 seconds.\n",
      "Time taken: 0.41716527938842773 seconds.\n",
      "Time taken: 0.3425107002258301 seconds.\n",
      "Time taken: 0.28849029541015625 seconds.\n",
      "Time taken: 0.3717927932739258 seconds.\n",
      "Time taken: 0.4023630619049072 seconds.\n",
      "Time taken: 0.3512766361236572 seconds.\n",
      "Time taken: 0.3011505603790283 seconds.\n",
      "Time taken: 0.40331459045410156 seconds.\n",
      "Time taken: 0.5826025009155273 seconds.\n",
      "Time taken: 0.3134610652923584 seconds.\n",
      "Time taken: 0.3808877468109131 seconds.\n",
      "Time taken: 0.3711414337158203 seconds.\n",
      "Time taken: 0.459857702255249 seconds.\n",
      "Time taken: 0.41445183753967285 seconds.\n",
      "Time taken: 0.5020625591278076 seconds.\n",
      "Time taken: 0.42163991928100586 seconds.\n",
      "Time taken: 0.35715723037719727 seconds.\n",
      "Time taken: 0.31154417991638184 seconds.\n",
      "Time taken: 0.2938864231109619 seconds.\n",
      "Time taken: 0.3754117488861084 seconds.\n",
      "Time taken: 0.49101781845092773 seconds.\n",
      "Time taken: 0.32997655868530273 seconds.\n",
      "Time taken: 0.4487636089324951 seconds.\n",
      "Time taken: 0.3376929759979248 seconds.\n",
      "Time taken: 0.26643872261047363 seconds.\n",
      "Time taken: 0.23974609375 seconds.\n",
      "Time taken: 0.2549433708190918 seconds.\n",
      "Time taken: 0.2467801570892334 seconds.\n",
      "Time taken: 0.5888292789459229 seconds.\n",
      "Time taken: 0.3296244144439697 seconds.\n",
      "Time taken: 0.21656513214111328 seconds.\n",
      "Time taken: 0.358126163482666 seconds.\n",
      "Time taken: 0.3676564693450928 seconds.\n",
      "Time taken: 0.3831658363342285 seconds.\n",
      "Time taken: 0.39283275604248047 seconds.\n",
      "Time taken: 0.44226956367492676 seconds.\n",
      "Time taken: 0.36028099060058594 seconds.\n",
      "Time taken: 0.5332975387573242 seconds.\n",
      "Time taken: 0.5481946468353271 seconds.\n",
      "Time taken: 0.3941671848297119 seconds.\n",
      "Time taken: 0.45308613777160645 seconds.\n",
      "Time taken: 0.3169732093811035 seconds.\n",
      "Time taken: 0.3409898281097412 seconds.\n",
      "Time taken: 0.39362311363220215 seconds.\n",
      "Time taken: 0.3858144283294678 seconds.\n",
      "Time taken: 0.34038329124450684 seconds.\n",
      "Time taken: 0.34382104873657227 seconds.\n",
      "Time taken: 0.4018290042877197 seconds.\n",
      "Time taken: 0.2727394104003906 seconds.\n",
      "Time taken: 0.5219440460205078 seconds.\n",
      "Time taken: 0.5057988166809082 seconds.\n",
      "Time taken: 0.4690864086151123 seconds.\n",
      "Time taken: 0.5139925479888916 seconds.\n",
      "Time taken: 0.430314302444458 seconds.\n",
      "Time taken: 0.403090238571167 seconds.\n",
      "Time taken: 0.3049154281616211 seconds.\n",
      "Time taken: 0.38681912422180176 seconds.\n",
      "Time taken: 0.4678304195404053 seconds.\n",
      "Time taken: 0.43625903129577637 seconds.\n",
      "Time taken: 0.3798549175262451 seconds.\n",
      "Time taken: 0.35721874237060547 seconds.\n",
      "Time taken: 0.25089454650878906 seconds.\n",
      "Time taken: 0.4925496578216553 seconds.\n",
      "Time taken: 0.30399441719055176 seconds.\n",
      "Time taken: 0.4245114326477051 seconds.\n",
      "Time taken: 0.4004397392272949 seconds.\n",
      "Time taken: 0.21286892890930176 seconds.\n",
      "Time taken: 0.307619571685791 seconds.\n",
      "Time taken: 0.37308526039123535 seconds.\n",
      "Time taken: 0.29845595359802246 seconds.\n",
      "Time taken: 0.3567178249359131 seconds.\n",
      "Time taken: 0.341677188873291 seconds.\n",
      "Time taken: 0.34131908416748047 seconds.\n",
      "Time taken: 0.2464745044708252 seconds.\n",
      "Time taken: 0.45885586738586426 seconds.\n",
      "Time taken: 0.37455058097839355 seconds.\n",
      "Time taken: 0.40212368965148926 seconds.\n",
      "Time taken: 0.3896901607513428 seconds.\n",
      "Time taken: 0.3615553379058838 seconds.\n",
      "Time taken: 0.38167762756347656 seconds.\n",
      "Time taken: 0.39442014694213867 seconds.\n",
      "Time taken: 0.33098864555358887 seconds.\n",
      "Time taken: 0.3298828601837158 seconds.\n",
      "Time taken: 0.3722844123840332 seconds.\n",
      "Time taken: 0.2893247604370117 seconds.\n",
      "Time taken: 0.3889913558959961 seconds.\n",
      "Time taken: 0.3390181064605713 seconds.\n",
      "Time taken: 0.3791327476501465 seconds.\n",
      "Time taken: 0.3491649627685547 seconds.\n",
      "Time taken: 0.32216548919677734 seconds.\n",
      "Time taken: 0.4127347469329834 seconds.\n",
      "Time taken: 0.2890784740447998 seconds.\n",
      "Time taken: 0.4532008171081543 seconds.\n",
      "Time taken: 0.42506957054138184 seconds.\n",
      "Time taken: 0.22234821319580078 seconds.\n",
      "Time taken: 0.3722264766693115 seconds.\n",
      "Time taken: 0.3627500534057617 seconds.\n",
      "Time taken: 0.26662540435791016 seconds.\n",
      "Time taken: 0.3519887924194336 seconds.\n",
      "Time taken: 0.40465259552001953 seconds.\n",
      "Time taken: 0.39978718757629395 seconds.\n",
      "Time taken: 0.25957775115966797 seconds.\n",
      "Time taken: 0.4951364994049072 seconds.\n",
      "Time taken: 0.30901288986206055 seconds.\n",
      "Time taken: 0.33737754821777344 seconds.\n",
      "Time taken: 0.3028419017791748 seconds.\n",
      "Time taken: 0.3327608108520508 seconds.\n",
      "Time taken: 0.32072877883911133 seconds.\n",
      "Time taken: 0.339890718460083 seconds.\n",
      "Time taken: 0.16819381713867188 seconds.\n",
      "Time taken: 0.3765373229980469 seconds.\n",
      "Time taken: 0.2944345474243164 seconds.\n",
      "Time taken: 0.39482569694519043 seconds.\n",
      "Time taken: 0.3852388858795166 seconds.\n",
      "Time taken: 0.3399994373321533 seconds.\n",
      "Time taken: 0.3813619613647461 seconds.\n",
      "Time taken: 0.4220876693725586 seconds.\n",
      "Time taken: 0.3549661636352539 seconds.\n",
      "Time taken: 0.295177698135376 seconds.\n",
      "Time taken: 0.20672369003295898 seconds.\n",
      "Time taken: 0.36894822120666504 seconds.\n",
      "Time taken: 0.36556124687194824 seconds.\n",
      "Time taken: 0.2840912342071533 seconds.\n",
      "Time taken: 0.2684035301208496 seconds.\n",
      "Time taken: 0.33668971061706543 seconds.\n",
      "Time taken: 0.37215447425842285 seconds.\n",
      "Time taken: 0.4951956272125244 seconds.\n",
      "Time taken: 0.4087257385253906 seconds.\n",
      "Time taken: 0.4412655830383301 seconds.\n",
      "Time taken: 0.3885655403137207 seconds.\n",
      "Time taken: 0.44748592376708984 seconds.\n",
      "Time taken: 0.4607417583465576 seconds.\n",
      "Time taken: 0.43965888023376465 seconds.\n",
      "Time taken: 0.42879748344421387 seconds.\n",
      "Time taken: 0.5265133380889893 seconds.\n",
      "Time taken: 0.4779953956604004 seconds.\n",
      "Time taken: 0.3129429817199707 seconds.\n",
      "Time taken: 0.3567969799041748 seconds.\n",
      "Time taken: 0.48506951332092285 seconds.\n",
      "Time taken: 0.27500057220458984 seconds.\n",
      "Time taken: 0.2926058769226074 seconds.\n",
      "Time taken: 0.42381834983825684 seconds.\n",
      "Time taken: 0.2895479202270508 seconds.\n",
      "Time taken: 0.38587093353271484 seconds.\n",
      "Time taken: 0.4288153648376465 seconds.\n",
      "Time taken: 0.3657505512237549 seconds.\n",
      "Time taken: 0.31305456161499023 seconds.\n",
      "Time taken: 0.4419252872467041 seconds.\n",
      "Time taken: 0.5519931316375732 seconds.\n",
      "Time taken: 0.3478274345397949 seconds.\n",
      "Time taken: 0.30974531173706055 seconds.\n",
      "Time taken: 0.3252842426300049 seconds.\n",
      "Time taken: 0.4253218173980713 seconds.\n",
      "Time taken: 0.4397003650665283 seconds.\n",
      "Time taken: 0.369342565536499 seconds.\n",
      "Time taken: 0.26502227783203125 seconds.\n",
      "Time taken: 0.47626304626464844 seconds.\n",
      "Time taken: 0.34360623359680176 seconds.\n",
      "Time taken: 0.24826765060424805 seconds.\n",
      "Time taken: 0.33704710006713867 seconds.\n",
      "Time taken: 0.29601025581359863 seconds.\n",
      "Time taken: 0.4296863079071045 seconds.\n",
      "Time taken: 0.6692824363708496 seconds.\n",
      "Time taken: 0.39601922035217285 seconds.\n",
      "Time taken: 0.3112049102783203 seconds.\n",
      "Time taken: 0.4134695529937744 seconds.\n",
      "Time taken: 0.4175708293914795 seconds.\n",
      "Time taken: 0.43944859504699707 seconds.\n",
      "Time taken: 0.4275228977203369 seconds.\n",
      "Time taken: 0.3981907367706299 seconds.\n",
      "Time taken: 0.3471357822418213 seconds.\n",
      "Time taken: 0.43921375274658203 seconds.\n",
      "Time taken: 0.4153885841369629 seconds.\n",
      "Time taken: 0.438002347946167 seconds.\n",
      "Time taken: 0.3843698501586914 seconds.\n",
      "Time taken: 0.37011289596557617 seconds.\n",
      "Time taken: 0.4711630344390869 seconds.\n",
      "Time taken: 0.34920549392700195 seconds.\n",
      "Time taken: 0.46567845344543457 seconds.\n",
      "Time taken: 0.2843146324157715 seconds.\n",
      "Time taken: 0.451887845993042 seconds.\n",
      "Time taken: 0.22693967819213867 seconds.\n",
      "Time taken: 0.49610471725463867 seconds.\n",
      "Time taken: 0.5203309059143066 seconds.\n",
      "Time taken: 0.4614591598510742 seconds.\n",
      "Time taken: 0.2975161075592041 seconds.\n",
      "Time taken: 0.39318180084228516 seconds.\n",
      "Time taken: 0.44561147689819336 seconds.\n",
      "Time taken: 0.4719719886779785 seconds.\n",
      "Time taken: 0.41892218589782715 seconds.\n",
      "Time taken: 0.43709444999694824 seconds.\n",
      "Time taken: 0.26630520820617676 seconds.\n",
      "Time taken: 0.24654650688171387 seconds.\n",
      "Time taken: 0.34897470474243164 seconds.\n",
      "Time taken: 0.32982540130615234 seconds.\n",
      "Time taken: 0.5405876636505127 seconds.\n",
      "Time taken: 0.4632914066314697 seconds.\n",
      "Time taken: 0.4436376094818115 seconds.\n",
      "Time taken: 0.4999239444732666 seconds.\n",
      "Time taken: 0.33742356300354004 seconds.\n",
      "Time taken: 0.44905614852905273 seconds.\n",
      "Time taken: 0.3538358211517334 seconds.\n",
      "Time taken: 0.33153724670410156 seconds.\n",
      "Time taken: 0.37609338760375977 seconds.\n",
      "Time taken: 0.5261693000793457 seconds.\n",
      "Time taken: 0.3340489864349365 seconds.\n",
      "Time taken: 0.32562875747680664 seconds.\n",
      "Time taken: 0.3046438694000244 seconds.\n",
      "Time taken: 0.32366490364074707 seconds.\n",
      "Time taken: 0.5217490196228027 seconds.\n",
      "Time taken: 0.514197587966919 seconds.\n",
      "Time taken: 0.27408504486083984 seconds.\n",
      "Time taken: 0.3626110553741455 seconds.\n",
      "Time taken: 0.39916276931762695 seconds.\n",
      "Time taken: 0.3180100917816162 seconds.\n",
      "Time taken: 0.4625818729400635 seconds.\n",
      "Time taken: 0.5477132797241211 seconds.\n",
      "Time taken: 0.32062816619873047 seconds.\n",
      "Time taken: 0.20332551002502441 seconds.\n",
      "Time taken: 0.2884538173675537 seconds.\n",
      "Time taken: 0.3716714382171631 seconds.\n",
      "Time taken: 0.5173614025115967 seconds.\n",
      "Time taken: 0.36377406120300293 seconds.\n",
      "Time taken: 0.3400740623474121 seconds.\n",
      "Time taken: 0.44730162620544434 seconds.\n",
      "Time taken: 0.4021334648132324 seconds.\n",
      "Time taken: 0.3571326732635498 seconds.\n",
      "Time taken: 0.3911247253417969 seconds.\n",
      "Time taken: 0.41475653648376465 seconds.\n",
      "Time taken: 0.41562485694885254 seconds.\n",
      "Time taken: 0.4273874759674072 seconds.\n",
      "Time taken: 0.3477907180786133 seconds.\n",
      "Time taken: 0.38091301918029785 seconds.\n",
      "Time taken: 0.42955827713012695 seconds.\n",
      "Time taken: 0.3792543411254883 seconds.\n",
      "Time taken: 0.3181612491607666 seconds.\n",
      "Time taken: 0.37979602813720703 seconds.\n",
      "Time taken: 0.4117772579193115 seconds.\n",
      "Time taken: 0.26723241806030273 seconds.\n",
      "Time taken: 0.2961905002593994 seconds.\n",
      "Time taken: 0.2423090934753418 seconds.\n",
      "Time taken: 0.46785497665405273 seconds.\n",
      "Time taken: 0.3497750759124756 seconds.\n",
      "Time taken: 0.3350648880004883 seconds.\n",
      "Time taken: 0.3085966110229492 seconds.\n",
      "Time taken: 0.38153624534606934 seconds.\n",
      "Time taken: 0.36279773712158203 seconds.\n",
      "Time taken: 0.4174175262451172 seconds.\n",
      "Time taken: 0.3668966293334961 seconds.\n",
      "Time taken: 0.34313344955444336 seconds.\n",
      "Time taken: 0.3049626350402832 seconds.\n",
      "Time taken: 0.4023897647857666 seconds.\n",
      "Time taken: 0.453904390335083 seconds.\n",
      "Time taken: 0.41747617721557617 seconds.\n",
      "Time taken: 0.3385007381439209 seconds.\n",
      "Time taken: 0.37093019485473633 seconds.\n",
      "Time taken: 0.3904135227203369 seconds.\n",
      "Time taken: 0.38429975509643555 seconds.\n",
      "Time taken: 0.37184953689575195 seconds.\n",
      "Time taken: 0.3379051685333252 seconds.\n",
      "Time taken: 0.33026742935180664 seconds.\n",
      "Time taken: 0.259141206741333 seconds.\n",
      "Time taken: 0.288496732711792 seconds.\n",
      "Time taken: 0.4004077911376953 seconds.\n",
      "Time taken: 0.42098426818847656 seconds.\n",
      "Time taken: 0.326552152633667 seconds.\n",
      "Time taken: 0.368988037109375 seconds.\n",
      "Time taken: 0.2194383144378662 seconds.\n",
      "Time taken: 0.4994685649871826 seconds.\n",
      "Time taken: 0.5352649688720703 seconds.\n",
      "Time taken: 0.29397130012512207 seconds.\n",
      "Time taken: 0.3373551368713379 seconds.\n",
      "Time taken: 0.33046722412109375 seconds.\n",
      "Time taken: 0.3477294445037842 seconds.\n",
      "Time taken: 0.21001338958740234 seconds.\n",
      "Time taken: 0.47714924812316895 seconds.\n",
      "Time taken: 0.23345375061035156 seconds.\n",
      "Time taken: 0.42438745498657227 seconds.\n",
      "Time taken: 0.28870177268981934 seconds.\n",
      "Time taken: 0.387162446975708 seconds.\n",
      "Time taken: 0.3503744602203369 seconds.\n",
      "Time taken: 0.15646076202392578 seconds.\n",
      "Time taken: 0.34952735900878906 seconds.\n",
      "Time taken: 0.4000372886657715 seconds.\n",
      "Time taken: 0.3941361904144287 seconds.\n",
      "Time taken: 0.36000871658325195 seconds.\n",
      "Time taken: 0.3801250457763672 seconds.\n",
      "Time taken: 0.33461594581604004 seconds.\n",
      "Time taken: 0.3645894527435303 seconds.\n",
      "Time taken: 0.30760908126831055 seconds.\n",
      "Time taken: 0.2532813549041748 seconds.\n",
      "Time taken: 0.6058940887451172 seconds.\n",
      "Time taken: 0.4487013816833496 seconds.\n",
      "Time taken: 0.36809706687927246 seconds.\n",
      "Time taken: 0.31089234352111816 seconds.\n",
      "Time taken: 0.2928907871246338 seconds.\n",
      "Time taken: 0.34012675285339355 seconds.\n",
      "Time taken: 0.27746129035949707 seconds.\n",
      "Time taken: 0.3290870189666748 seconds.\n",
      "Time taken: 0.3619418144226074 seconds.\n",
      "Time taken: 0.2584800720214844 seconds.\n",
      "Time taken: 0.20817041397094727 seconds.\n",
      "Time taken: 0.29180216789245605 seconds.\n",
      "Time taken: 0.2839980125427246 seconds.\n",
      "Time taken: 0.3876032829284668 seconds.\n",
      "Time taken: 0.2494668960571289 seconds.\n",
      "Time taken: 0.3739633560180664 seconds.\n",
      "Time taken: 0.3375101089477539 seconds.\n",
      "Time taken: 0.3935427665710449 seconds.\n",
      "Time taken: 0.3912651538848877 seconds.\n",
      "Time taken: 0.37195515632629395 seconds.\n",
      "Time taken: 0.33897995948791504 seconds.\n",
      "Time taken: 0.31987953186035156 seconds.\n",
      "Time taken: 0.6342942714691162 seconds.\n",
      "Time taken: 0.23639655113220215 seconds.\n",
      "Time taken: 0.41782140731811523 seconds.\n",
      "Time taken: 0.40091848373413086 seconds.\n",
      "Time taken: 0.33934879302978516 seconds.\n",
      "Time taken: 0.40488314628601074 seconds.\n",
      "Time taken: 0.39481139183044434 seconds.\n",
      "Time taken: 0.45368528366088867 seconds.\n",
      "Time taken: 0.30264997482299805 seconds.\n",
      "Time taken: 0.32161378860473633 seconds.\n",
      "Time taken: 0.37576985359191895 seconds.\n",
      "Time taken: 0.37360382080078125 seconds.\n",
      "Time taken: 0.23656296730041504 seconds.\n",
      "Time taken: 0.3744792938232422 seconds.\n",
      "Time taken: 0.36040210723876953 seconds.\n",
      "Time taken: 0.4276156425476074 seconds.\n",
      "Time taken: 0.43378186225891113 seconds.\n",
      "Time taken: 0.43213343620300293 seconds.\n",
      "Time taken: 0.3057882785797119 seconds.\n",
      "Time taken: 0.32891345024108887 seconds.\n",
      "Time taken: 0.45769524574279785 seconds.\n",
      "Time taken: 0.2796669006347656 seconds.\n",
      "Time taken: 0.3186147212982178 seconds.\n",
      "Time taken: 0.4236462116241455 seconds.\n",
      "Time taken: 0.5338883399963379 seconds.\n",
      "Time taken: 0.36049747467041016 seconds.\n",
      "Time taken: 0.34021973609924316 seconds.\n",
      "Time taken: 0.3564453125 seconds.\n",
      "Time taken: 0.32140040397644043 seconds.\n",
      "Time taken: 0.3920888900756836 seconds.\n",
      "Time taken: 0.5133934020996094 seconds.\n",
      "Time taken: 0.3661918640136719 seconds.\n",
      "Time taken: 0.2917211055755615 seconds.\n",
      "Time taken: 0.30796098709106445 seconds.\n",
      "Time taken: 0.2657737731933594 seconds.\n",
      "Time taken: 0.33698296546936035 seconds.\n",
      "Time taken: 0.31481361389160156 seconds.\n",
      "Time taken: 0.31353092193603516 seconds.\n",
      "Time taken: 0.36435365676879883 seconds.\n",
      "Time taken: 0.33962321281433105 seconds.\n",
      "Time taken: 0.47890734672546387 seconds.\n",
      "Time taken: 0.368450403213501 seconds.\n",
      "Time taken: 0.42169904708862305 seconds.\n",
      "Time taken: 0.5017266273498535 seconds.\n",
      "Time taken: 0.26387834548950195 seconds.\n",
      "Time taken: 0.4675898551940918 seconds.\n",
      "Time taken: 0.4605269432067871 seconds.\n",
      "Time taken: 0.3406360149383545 seconds.\n",
      "Time taken: 0.26406121253967285 seconds.\n",
      "Time taken: 0.39731669425964355 seconds.\n",
      "Time taken: 0.3968327045440674 seconds.\n",
      "Time taken: 0.2604715824127197 seconds.\n",
      "Time taken: 0.4577031135559082 seconds.\n",
      "Time taken: 0.5369312763214111 seconds.\n",
      "Time taken: 0.30858492851257324 seconds.\n",
      "Time taken: 0.34154510498046875 seconds.\n",
      "Time taken: 0.390425443649292 seconds.\n",
      "Time taken: 0.2814364433288574 seconds.\n",
      "Time taken: 0.5093667507171631 seconds.\n",
      "Time taken: 0.3356513977050781 seconds.\n",
      "Time taken: 0.36661481857299805 seconds.\n",
      "Time taken: 0.3962748050689697 seconds.\n",
      "Time taken: 0.387861967086792 seconds.\n",
      "Time taken: 0.27188611030578613 seconds.\n",
      "Time taken: 0.3223292827606201 seconds.\n",
      "Time taken: 0.47412967681884766 seconds.\n",
      "Time taken: 0.4264957904815674 seconds.\n",
      "Time taken: 0.36869072914123535 seconds.\n",
      "Time taken: 0.3429081439971924 seconds.\n",
      "Time taken: 0.3730950355529785 seconds.\n",
      "Time taken: 0.6164343357086182 seconds.\n",
      "Time taken: 0.4628934860229492 seconds.\n",
      "Time taken: 0.3400118350982666 seconds.\n",
      "Time taken: 0.4392871856689453 seconds.\n",
      "Time taken: 0.36168408393859863 seconds.\n",
      "Time taken: 0.5172998905181885 seconds.\n",
      "Time taken: 0.4105346202850342 seconds.\n",
      "Time taken: 0.2714364528656006 seconds.\n",
      "Time taken: 0.3612515926361084 seconds.\n",
      "Time taken: 0.3263063430786133 seconds.\n",
      "Time taken: 0.35849547386169434 seconds.\n",
      "Time taken: 0.344470739364624 seconds.\n",
      "Time taken: 0.339918851852417 seconds.\n",
      "Time taken: 0.3328125476837158 seconds.\n",
      "Time taken: 0.26282310485839844 seconds.\n",
      "Time taken: 0.44497060775756836 seconds.\n",
      "Time taken: 0.31037354469299316 seconds.\n",
      "Time taken: 0.39695191383361816 seconds.\n",
      "Time taken: 0.3021667003631592 seconds.\n",
      "Time taken: 0.6067156791687012 seconds.\n",
      "Time taken: 0.2845742702484131 seconds.\n",
      "Time taken: 0.3177461624145508 seconds.\n",
      "Time taken: 0.33483457565307617 seconds.\n",
      "Time taken: 0.3720874786376953 seconds.\n",
      "Time taken: 0.3585677146911621 seconds.\n",
      "Time taken: 0.4460012912750244 seconds.\n",
      "Time taken: 0.4471886157989502 seconds.\n",
      "Time taken: 0.3907339572906494 seconds.\n",
      "Time taken: 0.35025811195373535 seconds.\n",
      "Time taken: 0.3906059265136719 seconds.\n",
      "Time taken: 0.5142664909362793 seconds.\n",
      "Time taken: 0.20785737037658691 seconds.\n",
      "Time taken: 0.33333563804626465 seconds.\n",
      "Time taken: 0.3419673442840576 seconds.\n",
      "Time taken: 0.39421653747558594 seconds.\n",
      "Time taken: 0.3371858596801758 seconds.\n",
      "Time taken: 0.26151108741760254 seconds.\n",
      "Time taken: 0.2897951602935791 seconds.\n",
      "Time taken: 0.3412001132965088 seconds.\n",
      "Time taken: 0.3489971160888672 seconds.\n",
      "Time taken: 0.3333454132080078 seconds.\n",
      "Time taken: 0.36274027824401855 seconds.\n",
      "Time taken: 0.26171064376831055 seconds.\n",
      "Time taken: 0.31513452529907227 seconds.\n",
      "Time taken: 0.3408381938934326 seconds.\n",
      "Time taken: 0.4817633628845215 seconds.\n",
      "Time taken: 0.3933100700378418 seconds.\n",
      "Time taken: 0.2643625736236572 seconds.\n",
      "Time taken: 0.3493990898132324 seconds.\n",
      "Time taken: 0.30086779594421387 seconds.\n",
      "Time taken: 0.4325127601623535 seconds.\n",
      "Time taken: 0.2784125804901123 seconds.\n",
      "Time taken: 0.2877521514892578 seconds.\n",
      "Time taken: 0.309490442276001 seconds.\n",
      "Time taken: 0.5365514755249023 seconds.\n",
      "Time taken: 0.31890225410461426 seconds.\n",
      "Time taken: 0.2693455219268799 seconds.\n",
      "Time taken: 0.31491589546203613 seconds.\n",
      "Time taken: 0.3676583766937256 seconds.\n",
      "Time taken: 0.3832859992980957 seconds.\n",
      "Time taken: 0.3440821170806885 seconds.\n",
      "Time taken: 0.339519739151001 seconds.\n",
      "Time taken: 0.45229530334472656 seconds.\n",
      "Time taken: 0.38930273056030273 seconds.\n",
      "Time taken: 0.30427074432373047 seconds.\n",
      "Time taken: 0.2864973545074463 seconds.\n",
      "Time taken: 0.2872495651245117 seconds.\n",
      "Time taken: 0.3196847438812256 seconds.\n",
      "Time taken: 0.353013277053833 seconds.\n",
      "Time taken: 0.40102553367614746 seconds.\n",
      "Time taken: 0.33242201805114746 seconds.\n",
      "Time taken: 0.43935537338256836 seconds.\n",
      "Time taken: 0.42237329483032227 seconds.\n",
      "Time taken: 0.26732635498046875 seconds.\n",
      "Time taken: 0.36339330673217773 seconds.\n",
      "Time taken: 0.41741085052490234 seconds.\n",
      "Time taken: 0.4404582977294922 seconds.\n",
      "Time taken: 0.3061659336090088 seconds.\n",
      "Time taken: 0.308732271194458 seconds.\n",
      "Time taken: 0.32717156410217285 seconds.\n",
      "Time taken: 0.3747122287750244 seconds.\n",
      "Time taken: 0.3352322578430176 seconds.\n",
      "Time taken: 0.31754326820373535 seconds.\n",
      "Time taken: 0.3707137107849121 seconds.\n",
      "Time taken: 0.36171412467956543 seconds.\n",
      "Time taken: 0.36385440826416016 seconds.\n",
      "Time taken: 0.335237979888916 seconds.\n",
      "Time taken: 0.3472607135772705 seconds.\n",
      "Time taken: 0.3871896266937256 seconds.\n",
      "Time taken: 0.363602876663208 seconds.\n",
      "Time taken: 0.40416741371154785 seconds.\n",
      "Time taken: 0.3671119213104248 seconds.\n",
      "Time taken: 0.42310571670532227 seconds.\n",
      "Time taken: 0.5015013217926025 seconds.\n",
      "Time taken: 0.2876155376434326 seconds.\n",
      "Time taken: 0.42586541175842285 seconds.\n",
      "Time taken: 0.3632690906524658 seconds.\n",
      "Time taken: 0.5804178714752197 seconds.\n",
      "Time taken: 0.33919501304626465 seconds.\n",
      "Time taken: 0.2799720764160156 seconds.\n",
      "Time taken: 0.32553839683532715 seconds.\n",
      "Time taken: 0.472137451171875 seconds.\n",
      "Time taken: 0.37237119674682617 seconds.\n",
      "Time taken: 0.26125240325927734 seconds.\n",
      "Time taken: 0.29676055908203125 seconds.\n",
      "Time taken: 0.39798927307128906 seconds.\n",
      "Time taken: 0.20549726486206055 seconds.\n",
      "Time taken: 0.31674718856811523 seconds.\n",
      "Time taken: 0.2922196388244629 seconds.\n",
      "Time taken: 0.38057994842529297 seconds.\n",
      "Time taken: 0.3844618797302246 seconds.\n",
      "Time taken: 0.31119847297668457 seconds.\n",
      "Time taken: 0.3217289447784424 seconds.\n",
      "Time taken: 0.311460018157959 seconds.\n",
      "Time taken: 0.3662393093109131 seconds.\n",
      "Time taken: 0.2995431423187256 seconds.\n",
      "Time taken: 0.4685029983520508 seconds.\n",
      "Time taken: 0.375352144241333 seconds.\n",
      "Time taken: 0.17522954940795898 seconds.\n",
      "Time taken: 0.3399324417114258 seconds.\n",
      "Time taken: 0.3606870174407959 seconds.\n",
      "Time taken: 0.36683177947998047 seconds.\n",
      "Time taken: 0.3845527172088623 seconds.\n",
      "Time taken: 0.30591487884521484 seconds.\n",
      "Time taken: 0.43972325325012207 seconds.\n",
      "Time taken: 0.35549497604370117 seconds.\n",
      "Time taken: 0.3830876350402832 seconds.\n",
      "Time taken: 0.27220606803894043 seconds.\n",
      "Time taken: 0.29742980003356934 seconds.\n",
      "Time taken: 0.3358478546142578 seconds.\n",
      "Time taken: 0.289811372756958 seconds.\n",
      "Time taken: 0.44872450828552246 seconds.\n",
      "Time taken: 0.2998678684234619 seconds.\n",
      "Time taken: 0.26786112785339355 seconds.\n",
      "Time taken: 0.33988332748413086 seconds.\n",
      "Time taken: 0.28926897048950195 seconds.\n",
      "Time taken: 0.2350599765777588 seconds.\n",
      "Time taken: 0.3114321231842041 seconds.\n",
      "Time taken: 0.3916952610015869 seconds.\n",
      "Time taken: 0.3226604461669922 seconds.\n",
      "Time taken: 0.46163415908813477 seconds.\n",
      "Time taken: 0.23485326766967773 seconds.\n",
      "Time taken: 0.3880937099456787 seconds.\n",
      "Time taken: 0.24201607704162598 seconds.\n",
      "Time taken: 0.3740546703338623 seconds.\n",
      "Time taken: 0.30172252655029297 seconds.\n",
      "Time taken: 0.25717592239379883 seconds.\n",
      "Time taken: 0.3504598140716553 seconds.\n",
      "Time taken: 0.434401273727417 seconds.\n",
      "Time taken: 0.2962169647216797 seconds.\n",
      "Time taken: 0.3141508102416992 seconds.\n",
      "Time taken: 0.3693509101867676 seconds.\n",
      "Time taken: 0.46901702880859375 seconds.\n",
      "Time taken: 0.3435218334197998 seconds.\n",
      "Time taken: 0.38927531242370605 seconds.\n",
      "Time taken: 0.4003009796142578 seconds.\n",
      "Time taken: 0.26434850692749023 seconds.\n",
      "Time taken: 0.36560750007629395 seconds.\n",
      "Time taken: 0.4031040668487549 seconds.\n",
      "Time taken: 0.36042332649230957 seconds.\n",
      "Time taken: 0.3857297897338867 seconds.\n",
      "Time taken: 0.29962873458862305 seconds.\n",
      "Time taken: 0.3537909984588623 seconds.\n",
      "Time taken: 0.3648524284362793 seconds.\n",
      "Time taken: 0.44937610626220703 seconds.\n",
      "Time taken: 0.263824462890625 seconds.\n",
      "Time taken: 0.34087538719177246 seconds.\n",
      "Time taken: 0.43899059295654297 seconds.\n",
      "Time taken: 0.5439944267272949 seconds.\n",
      "Time taken: 0.28654026985168457 seconds.\n",
      "Time taken: 0.28574419021606445 seconds.\n",
      "Time taken: 0.36443209648132324 seconds.\n",
      "Time taken: 0.21054553985595703 seconds.\n",
      "Time taken: 0.3934023380279541 seconds.\n",
      "Time taken: 0.40074992179870605 seconds.\n",
      "Time taken: 0.4284329414367676 seconds.\n",
      "Time taken: 0.49097371101379395 seconds.\n",
      "Time taken: 0.3026552200317383 seconds.\n",
      "Time taken: 0.31328415870666504 seconds.\n",
      "Time taken: 0.3161344528198242 seconds.\n",
      "Time taken: 0.34258222579956055 seconds.\n",
      "Time taken: 0.37706518173217773 seconds.\n",
      "Time taken: 0.3324604034423828 seconds.\n",
      "Time taken: 0.23334598541259766 seconds.\n",
      "Time taken: 0.4522440433502197 seconds.\n",
      "Time taken: 0.41651105880737305 seconds.\n",
      "Time taken: 0.33516931533813477 seconds.\n",
      "Time taken: 0.35541439056396484 seconds.\n",
      "Time taken: 0.27518582344055176 seconds.\n",
      "Time taken: 0.3938572406768799 seconds.\n",
      "Time taken: 0.368680477142334 seconds.\n",
      "Time taken: 0.43816518783569336 seconds.\n",
      "Time taken: 0.3433246612548828 seconds.\n",
      "Time taken: 0.45537376403808594 seconds.\n",
      "Time taken: 0.3128011226654053 seconds.\n",
      "Time taken: 0.3941993713378906 seconds.\n",
      "Time taken: 0.33800625801086426 seconds.\n",
      "Time taken: 0.3888366222381592 seconds.\n",
      "Time taken: 0.3623833656311035 seconds.\n",
      "Time taken: 0.3082616329193115 seconds.\n",
      "Time taken: 0.4116401672363281 seconds.\n",
      "Time taken: 0.42529869079589844 seconds.\n",
      "Time taken: 0.3095242977142334 seconds.\n",
      "Time taken: 0.42734551429748535 seconds.\n",
      "Time taken: 0.4225425720214844 seconds.\n",
      "Time taken: 0.4572768211364746 seconds.\n",
      "Time taken: 0.44765663146972656 seconds.\n",
      "Time taken: 0.40954113006591797 seconds.\n",
      "Time taken: 0.3022017478942871 seconds.\n",
      "Time taken: 0.32186102867126465 seconds.\n",
      "Time taken: 0.4138798713684082 seconds.\n",
      "Time taken: 0.37383508682250977 seconds.\n",
      "Time taken: 0.3743407726287842 seconds.\n",
      "Time taken: 0.31239867210388184 seconds.\n",
      "Time taken: 0.44367194175720215 seconds.\n",
      "Time taken: 0.36194634437561035 seconds.\n",
      "Time taken: 0.44505763053894043 seconds.\n",
      "Time taken: 0.26331043243408203 seconds.\n",
      "Time taken: 0.28501200675964355 seconds.\n",
      "Time taken: 0.4524211883544922 seconds.\n",
      "Time taken: 0.257673978805542 seconds.\n",
      "Time taken: 0.264904260635376 seconds.\n",
      "Time taken: 0.180802583694458 seconds.\n",
      "Time taken: 0.33559131622314453 seconds.\n",
      "Time taken: 0.3593292236328125 seconds.\n",
      "Time taken: 0.2999718189239502 seconds.\n",
      "Time taken: 0.26942896842956543 seconds.\n",
      "Time taken: 0.31559014320373535 seconds.\n",
      "Time taken: 0.37946510314941406 seconds.\n",
      "Time taken: 0.3055751323699951 seconds.\n",
      "Time taken: 0.37871694564819336 seconds.\n",
      "Time taken: 0.4025309085845947 seconds.\n",
      "Time taken: 0.26195359230041504 seconds.\n",
      "Time taken: 0.37601256370544434 seconds.\n",
      "Time taken: 0.364086389541626 seconds.\n",
      "Time taken: 0.5116040706634521 seconds.\n",
      "Time taken: 0.48262834548950195 seconds.\n",
      "Time taken: 0.31432509422302246 seconds.\n",
      "Time taken: 0.3708164691925049 seconds.\n",
      "Time taken: 0.4149465560913086 seconds.\n",
      "Time taken: 0.33885741233825684 seconds.\n",
      "Time taken: 0.20444416999816895 seconds.\n",
      "Time taken: 0.3566856384277344 seconds.\n",
      "Time taken: 0.4578256607055664 seconds.\n",
      "Time taken: 0.37096285820007324 seconds.\n",
      "Time taken: 0.4469764232635498 seconds.\n",
      "Time taken: 0.339247465133667 seconds.\n",
      "Time taken: 0.40265560150146484 seconds.\n",
      "Time taken: 0.3952147960662842 seconds.\n",
      "Time taken: 0.529412031173706 seconds.\n",
      "Time taken: 0.257892370223999 seconds.\n",
      "Time taken: 0.18407535552978516 seconds.\n",
      "Time taken: 0.3604743480682373 seconds.\n",
      "Time taken: 0.33327817916870117 seconds.\n",
      "Time taken: 0.42110157012939453 seconds.\n",
      "Time taken: 0.3668205738067627 seconds.\n",
      "Time taken: 0.39305830001831055 seconds.\n",
      "Time taken: 0.3941810131072998 seconds.\n",
      "Time taken: 0.17835140228271484 seconds.\n",
      "Time taken: 0.32855939865112305 seconds.\n",
      "Time taken: 0.4213874340057373 seconds.\n",
      "Time taken: 0.3113996982574463 seconds.\n",
      "Time taken: 0.3776829242706299 seconds.\n",
      "Time taken: 0.3659036159515381 seconds.\n",
      "Time taken: 0.3270556926727295 seconds.\n",
      "Time taken: 0.4708831310272217 seconds.\n",
      "Time taken: 0.41526269912719727 seconds.\n",
      "Time taken: 0.25328898429870605 seconds.\n",
      "Time taken: 0.3704533576965332 seconds.\n",
      "Time taken: 0.27316880226135254 seconds.\n",
      "Time taken: 0.35053110122680664 seconds.\n",
      "Time taken: 0.27741289138793945 seconds.\n",
      "Time taken: 0.330197811126709 seconds.\n",
      "Time taken: 0.38111257553100586 seconds.\n",
      "Time taken: 0.2906928062438965 seconds.\n",
      "Time taken: 0.3747267723083496 seconds.\n",
      "Time taken: 0.47058582305908203 seconds.\n",
      "Time taken: 0.40128278732299805 seconds.\n",
      "Time taken: 0.3679046630859375 seconds.\n",
      "Time taken: 0.3360872268676758 seconds.\n",
      "Time taken: 0.26001763343811035 seconds.\n",
      "Time taken: 0.4172654151916504 seconds.\n",
      "Time taken: 0.29011011123657227 seconds.\n",
      "Time taken: 0.30330824851989746 seconds.\n",
      "Time taken: 0.3450136184692383 seconds.\n",
      "Time taken: 0.4104313850402832 seconds.\n",
      "Time taken: 0.5027945041656494 seconds.\n",
      "Time taken: 0.2624070644378662 seconds.\n",
      "Time taken: 0.23568511009216309 seconds.\n",
      "Time taken: 0.3912689685821533 seconds.\n",
      "Time taken: 0.34584832191467285 seconds.\n",
      "Time taken: 0.2766587734222412 seconds.\n",
      "Time taken: 0.4121425151824951 seconds.\n",
      "Time taken: 0.4456746578216553 seconds.\n",
      "Time taken: 0.3595564365386963 seconds.\n",
      "Time taken: 0.3405287265777588 seconds.\n",
      "Time taken: 0.28284430503845215 seconds.\n",
      "Time taken: 0.3176548480987549 seconds.\n",
      "Time taken: 0.33139824867248535 seconds.\n",
      "Time taken: 0.22127747535705566 seconds.\n",
      "Time taken: 0.33049917221069336 seconds.\n",
      "Time taken: 0.33631253242492676 seconds.\n",
      "Time taken: 0.5211367607116699 seconds.\n",
      "Time taken: 0.3655586242675781 seconds.\n",
      "Time taken: 0.2752518653869629 seconds.\n",
      "Time taken: 0.34094786643981934 seconds.\n",
      "Time taken: 0.363879919052124 seconds.\n",
      "Time taken: 0.42586517333984375 seconds.\n",
      "Time taken: 0.30695247650146484 seconds.\n",
      "Time taken: 0.3453667163848877 seconds.\n",
      "Time taken: 0.3729691505432129 seconds.\n",
      "Time taken: 0.3598954677581787 seconds.\n",
      "Time taken: 0.5385918617248535 seconds.\n",
      "Time taken: 0.48780059814453125 seconds.\n",
      "Time taken: 0.3634157180786133 seconds.\n",
      "Time taken: 0.5006177425384521 seconds.\n",
      "Time taken: 0.37243127822875977 seconds.\n",
      "Time taken: 0.38492369651794434 seconds.\n",
      "Time taken: 0.29279208183288574 seconds.\n",
      "Time taken: 0.35192227363586426 seconds.\n",
      "Time taken: 0.3259449005126953 seconds.\n",
      "Time taken: 0.39705920219421387 seconds.\n",
      "Time taken: 0.24047470092773438 seconds.\n",
      "Time taken: 0.3981797695159912 seconds.\n",
      "Time taken: 0.17986202239990234 seconds.\n",
      "Time taken: 0.2880401611328125 seconds.\n",
      "Time taken: 0.3309187889099121 seconds.\n",
      "Time taken: 0.27909421920776367 seconds.\n",
      "Time taken: 0.30037951469421387 seconds.\n",
      "Time taken: 0.18187594413757324 seconds.\n",
      "Time taken: 0.28757381439208984 seconds.\n",
      "Time taken: 0.33109283447265625 seconds.\n",
      "Time taken: 0.3689861297607422 seconds.\n",
      "Time taken: 0.39988112449645996 seconds.\n",
      "Time taken: 0.36902308464050293 seconds.\n",
      "Time taken: 0.36801695823669434 seconds.\n",
      "Time taken: 0.3348212242126465 seconds.\n",
      "Time taken: 0.30956101417541504 seconds.\n",
      "Time taken: 0.44713830947875977 seconds.\n",
      "Time taken: 0.31519532203674316 seconds.\n",
      "Time taken: 0.41477513313293457 seconds.\n",
      "Time taken: 0.22806930541992188 seconds.\n",
      "Time taken: 0.25214195251464844 seconds.\n",
      "Time taken: 0.4324660301208496 seconds.\n",
      "Time taken: 0.37308692932128906 seconds.\n",
      "Time taken: 0.328810453414917 seconds.\n",
      "Time taken: 0.3668045997619629 seconds.\n",
      "Time taken: 0.2440805435180664 seconds.\n",
      "Time taken: 0.35712575912475586 seconds.\n",
      "Time taken: 0.42285776138305664 seconds.\n",
      "Time taken: 0.4280555248260498 seconds.\n",
      "Time taken: 0.29396915435791016 seconds.\n",
      "Time taken: 0.3768494129180908 seconds.\n",
      "Time taken: 0.308056116104126 seconds.\n",
      "Time taken: 0.29070353507995605 seconds.\n",
      "Time taken: 0.3595297336578369 seconds.\n",
      "Time taken: 0.4029858112335205 seconds.\n",
      "Time taken: 0.1808769702911377 seconds.\n",
      "Time taken: 0.4456348419189453 seconds.\n",
      "Time taken: 0.3047165870666504 seconds.\n",
      "Time taken: 0.39946889877319336 seconds.\n",
      "Time taken: 0.34201478958129883 seconds.\n",
      "Time taken: 0.3970315456390381 seconds.\n",
      "Time taken: 0.18331098556518555 seconds.\n",
      "Time taken: 0.2929368019104004 seconds.\n",
      "Time taken: 0.30795741081237793 seconds.\n",
      "Time taken: 0.375652551651001 seconds.\n",
      "Time taken: 0.4337141513824463 seconds.\n",
      "Time taken: 0.31141018867492676 seconds.\n",
      "Time taken: 0.2856557369232178 seconds.\n",
      "Time taken: 0.414536714553833 seconds.\n",
      "Time taken: 0.21718239784240723 seconds.\n",
      "Time taken: 0.41257715225219727 seconds.\n",
      "Time taken: 0.4736759662628174 seconds.\n",
      "Time taken: 0.3469264507293701 seconds.\n",
      "Time taken: 0.4818689823150635 seconds.\n",
      "Time taken: 0.4181056022644043 seconds.\n",
      "Time taken: 0.35330963134765625 seconds.\n",
      "Time taken: 0.4162251949310303 seconds.\n",
      "Time taken: 0.37646913528442383 seconds.\n",
      "Time taken: 0.4395291805267334 seconds.\n",
      "Time taken: 0.30658483505249023 seconds.\n",
      "Time taken: 0.4163801670074463 seconds.\n",
      "Time taken: 0.46630191802978516 seconds.\n",
      "Time taken: 0.41487693786621094 seconds.\n",
      "Time taken: 0.3810155391693115 seconds.\n",
      "Time taken: 0.4201929569244385 seconds.\n",
      "Time taken: 0.48506855964660645 seconds.\n",
      "Time taken: 0.38655543327331543 seconds.\n",
      "Time taken: 0.6009128093719482 seconds.\n",
      "Time taken: 0.27124953269958496 seconds.\n",
      "Time taken: 0.3935399055480957 seconds.\n",
      "Time taken: 0.4124484062194824 seconds.\n",
      "Time taken: 0.3979315757751465 seconds.\n",
      "Time taken: 0.4711923599243164 seconds.\n",
      "Time taken: 0.31914544105529785 seconds.\n",
      "Time taken: 0.3899562358856201 seconds.\n",
      "Time taken: 0.36674976348876953 seconds.\n",
      "Time taken: 0.36356449127197266 seconds.\n",
      "Time taken: 0.296889066696167 seconds.\n",
      "Time taken: 0.37360119819641113 seconds.\n",
      "Time taken: 0.3656497001647949 seconds.\n",
      "Time taken: 0.20963549613952637 seconds.\n",
      "Time taken: 0.2977004051208496 seconds.\n",
      "Time taken: 0.3655374050140381 seconds.\n",
      "Time taken: 0.2598721981048584 seconds.\n",
      "Time taken: 0.4404749870300293 seconds.\n",
      "Time taken: 0.36887192726135254 seconds.\n",
      "Time taken: 0.39875340461730957 seconds.\n",
      "Time taken: 0.306549072265625 seconds.\n",
      "Time taken: 0.3000624179840088 seconds.\n",
      "Time taken: 0.4063708782196045 seconds.\n",
      "Time taken: 0.4636209011077881 seconds.\n",
      "Time taken: 0.3980545997619629 seconds.\n",
      "Time taken: 0.36455535888671875 seconds.\n",
      "Time taken: 0.3661623001098633 seconds.\n",
      "Time taken: 0.3035900592803955 seconds.\n",
      "Time taken: 0.40151000022888184 seconds.\n",
      "Time taken: 0.40655088424682617 seconds.\n",
      "Time taken: 0.3113210201263428 seconds.\n",
      "Time taken: 0.3146708011627197 seconds.\n",
      "Time taken: 0.35997772216796875 seconds.\n",
      "Time taken: 0.2596907615661621 seconds.\n",
      "Time taken: 0.27469968795776367 seconds.\n",
      "Time taken: 0.318148136138916 seconds.\n",
      "Time taken: 0.3625376224517822 seconds.\n",
      "Time taken: 0.33368873596191406 seconds.\n",
      "Time taken: 0.3182108402252197 seconds.\n",
      "Time taken: 0.40313720703125 seconds.\n",
      "Time taken: 0.2968761920928955 seconds.\n",
      "Time taken: 0.31595897674560547 seconds.\n",
      "Time taken: 0.43486499786376953 seconds.\n",
      "Time taken: 0.34085917472839355 seconds.\n",
      "Time taken: 0.39746928215026855 seconds.\n",
      "Time taken: 0.3658275604248047 seconds.\n",
      "Time taken: 0.28793859481811523 seconds.\n",
      "Time taken: 0.330247163772583 seconds.\n",
      "Time taken: 0.4141051769256592 seconds.\n",
      "Time taken: 0.28836679458618164 seconds.\n",
      "Time taken: 0.31604528427124023 seconds.\n",
      "Time taken: 0.36822009086608887 seconds.\n",
      "Time taken: 0.35515475273132324 seconds.\n",
      "Time taken: 0.35082125663757324 seconds.\n",
      "Time taken: 0.3602170944213867 seconds.\n",
      "Time taken: 0.4809563159942627 seconds.\n",
      "Time taken: 0.31609654426574707 seconds.\n",
      "Time taken: 0.2295093536376953 seconds.\n",
      "Time taken: 0.3400280475616455 seconds.\n",
      "Time taken: 0.36763548851013184 seconds.\n",
      "Time taken: 0.3761305809020996 seconds.\n",
      "Time taken: 0.3640618324279785 seconds.\n",
      "Time taken: 0.43156957626342773 seconds.\n",
      "Time taken: 0.31137967109680176 seconds.\n",
      "Time taken: 0.3661468029022217 seconds.\n",
      "Time taken: 0.41548919677734375 seconds.\n",
      "Time taken: 0.34166693687438965 seconds.\n",
      "Time taken: 0.39052391052246094 seconds.\n",
      "Time taken: 0.35909295082092285 seconds.\n",
      "Time taken: 0.31615233421325684 seconds.\n",
      "Time taken: 0.3180403709411621 seconds.\n",
      "Time taken: 0.33737778663635254 seconds.\n",
      "Time taken: 0.31090593338012695 seconds.\n",
      "Time taken: 0.32622313499450684 seconds.\n",
      "Time taken: 0.3270285129547119 seconds.\n",
      "Time taken: 0.36146068572998047 seconds.\n",
      "Time taken: 0.35365796089172363 seconds.\n",
      "Time taken: 0.4700920581817627 seconds.\n",
      "Time taken: 0.35046887397766113 seconds.\n",
      "Time taken: 0.2934274673461914 seconds.\n",
      "Time taken: 0.6318647861480713 seconds.\n",
      "Time taken: 0.37582993507385254 seconds.\n",
      "Time taken: 0.3860433101654053 seconds.\n",
      "Time taken: 0.34050798416137695 seconds.\n",
      "Time taken: 0.40042972564697266 seconds.\n",
      "Time taken: 0.3666825294494629 seconds.\n",
      "Time taken: 0.3442699909210205 seconds.\n",
      "Time taken: 0.26030635833740234 seconds.\n",
      "Time taken: 0.23795819282531738 seconds.\n",
      "Time taken: 0.2710685729980469 seconds.\n",
      "Time taken: 0.2698831558227539 seconds.\n",
      "Time taken: 0.18299317359924316 seconds.\n",
      "Time taken: 0.26035094261169434 seconds.\n",
      "Time taken: 0.27559876441955566 seconds.\n",
      "Time taken: 0.23392486572265625 seconds.\n",
      "Time taken: 0.20935726165771484 seconds.\n",
      "Time taken: 0.39263224601745605 seconds.\n",
      "Time taken: 0.31154489517211914 seconds.\n",
      "Time taken: 0.3523998260498047 seconds.\n",
      "Time taken: 0.26612138748168945 seconds.\n",
      "Time taken: 0.4590950012207031 seconds.\n",
      "Time taken: 0.36972546577453613 seconds.\n",
      "Time taken: 0.3878333568572998 seconds.\n",
      "Time taken: 0.4734382629394531 seconds.\n",
      "Time taken: 0.30121898651123047 seconds.\n",
      "Time taken: 0.3607215881347656 seconds.\n",
      "Time taken: 0.35669541358947754 seconds.\n",
      "Time taken: 0.3253188133239746 seconds.\n",
      "Time taken: 0.40189218521118164 seconds.\n",
      "Time taken: 0.41209840774536133 seconds.\n",
      "Time taken: 0.3703014850616455 seconds.\n",
      "Time taken: 0.4826843738555908 seconds.\n",
      "Time taken: 0.15816664695739746 seconds.\n",
      "Time taken: 0.36733508110046387 seconds.\n",
      "Time taken: 0.39460301399230957 seconds.\n",
      "Time taken: 0.3931732177734375 seconds.\n",
      "Time taken: 0.30462193489074707 seconds.\n",
      "Time taken: 0.18616628646850586 seconds.\n",
      "Time taken: 0.260159969329834 seconds.\n",
      "Time taken: 0.41948413848876953 seconds.\n",
      "Time taken: 0.39211177825927734 seconds.\n",
      "Time taken: 0.42110371589660645 seconds.\n",
      "Time taken: 0.3616769313812256 seconds.\n",
      "Time taken: 0.3910045623779297 seconds.\n",
      "Time taken: 0.30145931243896484 seconds.\n",
      "Time taken: 0.32852721214294434 seconds.\n",
      "Time taken: 0.3011481761932373 seconds.\n",
      "Time taken: 0.6087384223937988 seconds.\n",
      "Time taken: 0.3860137462615967 seconds.\n",
      "Time taken: 0.15070128440856934 seconds.\n",
      "Time taken: 0.3620738983154297 seconds.\n",
      "Time taken: 0.2640664577484131 seconds.\n",
      "Time taken: 0.4025092124938965 seconds.\n",
      "Time taken: 0.23518705368041992 seconds.\n",
      "Time taken: 0.29596495628356934 seconds.\n",
      "Time taken: 0.3949391841888428 seconds.\n",
      "Time taken: 0.3389909267425537 seconds.\n",
      "Time taken: 0.18424630165100098 seconds.\n",
      "Time taken: 0.36129260063171387 seconds.\n",
      "Time taken: 0.33985042572021484 seconds.\n",
      "Time taken: 0.420943021774292 seconds.\n",
      "Time taken: 0.3342006206512451 seconds.\n",
      "Time taken: 0.28596043586730957 seconds.\n",
      "Time taken: 0.31298351287841797 seconds.\n",
      "Time taken: 0.3145003318786621 seconds.\n",
      "Time taken: 0.3567943572998047 seconds.\n",
      "Time taken: 0.2803323268890381 seconds.\n",
      "Time taken: 0.4830639362335205 seconds.\n",
      "Time taken: 0.18224501609802246 seconds.\n",
      "Time taken: 0.35367822647094727 seconds.\n",
      "Time taken: 0.3982992172241211 seconds.\n",
      "Time taken: 0.34531378746032715 seconds.\n",
      "Time taken: 0.33249354362487793 seconds.\n",
      "Time taken: 0.29691529273986816 seconds.\n",
      "Time taken: 0.1797497272491455 seconds.\n",
      "Time taken: 0.3337271213531494 seconds.\n",
      "Time taken: 0.465867280960083 seconds.\n",
      "Time taken: 0.3364264965057373 seconds.\n",
      "Time taken: 0.29873037338256836 seconds.\n",
      "Time taken: 0.24025821685791016 seconds.\n",
      "Time taken: 0.3516054153442383 seconds.\n",
      "Time taken: 0.23228096961975098 seconds.\n",
      "Time taken: 0.34201502799987793 seconds.\n",
      "Time taken: 0.3027665615081787 seconds.\n",
      "Time taken: 0.31275463104248047 seconds.\n",
      "Time taken: 0.3465259075164795 seconds.\n",
      "Time taken: 0.41155314445495605 seconds.\n",
      "Time taken: 0.29650115966796875 seconds.\n",
      "Time taken: 0.32202887535095215 seconds.\n",
      "Time taken: 0.33725500106811523 seconds.\n",
      "Time taken: 0.29055237770080566 seconds.\n",
      "Time taken: 0.5082974433898926 seconds.\n",
      "Time taken: 0.40516114234924316 seconds.\n",
      "Time taken: 0.4060981273651123 seconds.\n",
      "Time taken: 0.401195764541626 seconds.\n",
      "Time taken: 0.31563711166381836 seconds.\n",
      "Time taken: 0.18300747871398926 seconds.\n",
      "Time taken: 0.3800637722015381 seconds.\n",
      "Time taken: 0.3238790035247803 seconds.\n",
      "Time taken: 0.2823348045349121 seconds.\n",
      "Time taken: 0.3222839832305908 seconds.\n",
      "Time taken: 0.17555570602416992 seconds.\n",
      "Time taken: 0.35425496101379395 seconds.\n",
      "Time taken: 0.2606353759765625 seconds.\n",
      "Time taken: 0.27137041091918945 seconds.\n",
      "Time taken: 0.3316652774810791 seconds.\n",
      "Time taken: 0.2582681179046631 seconds.\n",
      "Time taken: 0.28667521476745605 seconds.\n",
      "Time taken: 0.4239509105682373 seconds.\n",
      "Time taken: 0.34911465644836426 seconds.\n",
      "Time taken: 0.3968322277069092 seconds.\n",
      "Time taken: 0.35018229484558105 seconds.\n",
      "Time taken: 0.4310486316680908 seconds.\n",
      "Time taken: 0.3473317623138428 seconds.\n",
      "Time taken: 0.3393409252166748 seconds.\n",
      "Time taken: 0.3375866413116455 seconds.\n",
      "Time taken: 0.29741859436035156 seconds.\n",
      "Time taken: 0.3604543209075928 seconds.\n",
      "Time taken: 0.31005406379699707 seconds.\n",
      "Time taken: 0.36043810844421387 seconds.\n",
      "Time taken: 0.30382847785949707 seconds.\n",
      "Time taken: 0.37532997131347656 seconds.\n",
      "Time taken: 0.4469320774078369 seconds.\n",
      "Time taken: 0.4092566967010498 seconds.\n",
      "Time taken: 0.33013248443603516 seconds.\n",
      "Time taken: 0.28868722915649414 seconds.\n",
      "Time taken: 0.4434037208557129 seconds.\n",
      "Time taken: 0.38318490982055664 seconds.\n",
      "Time taken: 0.35936737060546875 seconds.\n",
      "Time taken: 0.35845518112182617 seconds.\n",
      "Time taken: 0.31124043464660645 seconds.\n",
      "Time taken: 0.368863582611084 seconds.\n",
      "Time taken: 0.292572021484375 seconds.\n",
      "Time taken: 0.39699578285217285 seconds.\n",
      "Time taken: 0.3144986629486084 seconds.\n",
      "Time taken: 0.458158016204834 seconds.\n",
      "Time taken: 0.2860727310180664 seconds.\n",
      "Time taken: 0.31427836418151855 seconds.\n",
      "Time taken: 0.2716836929321289 seconds.\n",
      "Time taken: 0.38135862350463867 seconds.\n",
      "Time taken: 0.3770935535430908 seconds.\n",
      "Time taken: 0.30768895149230957 seconds.\n",
      "Time taken: 0.4573373794555664 seconds.\n",
      "Time taken: 0.3892934322357178 seconds.\n",
      "Time taken: 0.377885103225708 seconds.\n",
      "Time taken: 0.2994258403778076 seconds.\n",
      "Time taken: 0.2623262405395508 seconds.\n",
      "Time taken: 0.46075963973999023 seconds.\n",
      "Time taken: 0.25350189208984375 seconds.\n",
      "Time taken: 0.41024136543273926 seconds.\n",
      "Time taken: 0.3153219223022461 seconds.\n",
      "Time taken: 0.3051285743713379 seconds.\n",
      "Time taken: 0.46478915214538574 seconds.\n",
      "Time taken: 0.2615628242492676 seconds.\n",
      "Time taken: 0.5823442935943604 seconds.\n",
      "Time taken: 0.4183993339538574 seconds.\n",
      "Time taken: 0.3410227298736572 seconds.\n",
      "Time taken: 0.3337831497192383 seconds.\n",
      "Time taken: 0.4182469844818115 seconds.\n",
      "Time taken: 0.446124792098999 seconds.\n",
      "Time taken: 0.3514871597290039 seconds.\n",
      "Time taken: 0.26452159881591797 seconds.\n",
      "Time taken: 0.3818366527557373 seconds.\n",
      "Time taken: 0.31447458267211914 seconds.\n",
      "Time taken: 0.35886120796203613 seconds.\n",
      "Time taken: 0.4777231216430664 seconds.\n",
      "Time taken: 0.16441702842712402 seconds.\n",
      "Time taken: 0.3316018581390381 seconds.\n",
      "Time taken: 0.2864384651184082 seconds.\n",
      "Time taken: 0.38658857345581055 seconds.\n",
      "Time taken: 0.31701183319091797 seconds.\n",
      "Time taken: 0.3346371650695801 seconds.\n",
      "Time taken: 0.4091832637786865 seconds.\n",
      "Time taken: 0.3883967399597168 seconds.\n",
      "Time taken: 0.25416016578674316 seconds.\n",
      "Time taken: 0.24156498908996582 seconds.\n",
      "Time taken: 0.19085240364074707 seconds.\n",
      "Time taken: 0.31667041778564453 seconds.\n",
      "Time taken: 0.4158759117126465 seconds.\n",
      "Time taken: 0.45261645317077637 seconds.\n",
      "Time taken: 0.2546834945678711 seconds.\n",
      "Time taken: 0.43352627754211426 seconds.\n",
      "Time taken: 0.4413771629333496 seconds.\n",
      "Time taken: 0.42131781578063965 seconds.\n",
      "Time taken: 0.4651305675506592 seconds.\n",
      "Time taken: 0.30954647064208984 seconds.\n",
      "Time taken: 0.2644660472869873 seconds.\n",
      "Time taken: 0.4005415439605713 seconds.\n",
      "Time taken: 0.45107460021972656 seconds.\n",
      "Time taken: 0.5080530643463135 seconds.\n",
      "Time taken: 0.36766982078552246 seconds.\n",
      "Time taken: 0.3595700263977051 seconds.\n",
      "Time taken: 0.42060327529907227 seconds.\n",
      "Time taken: 0.3913273811340332 seconds.\n",
      "Time taken: 0.39263367652893066 seconds.\n",
      "Time taken: 0.38674068450927734 seconds.\n",
      "Time taken: 0.41228365898132324 seconds.\n",
      "Time taken: 0.438046932220459 seconds.\n",
      "Time taken: 0.4243960380554199 seconds.\n",
      "Time taken: 0.38571858406066895 seconds.\n",
      "Time taken: 0.42883944511413574 seconds.\n",
      "Time taken: 0.33278369903564453 seconds.\n",
      "Time taken: 0.2564406394958496 seconds.\n",
      "Time taken: 0.2589077949523926 seconds.\n",
      "Time taken: 0.4454829692840576 seconds.\n",
      "Time taken: 0.23573827743530273 seconds.\n",
      "Time taken: 0.17951750755310059 seconds.\n",
      "Time taken: 0.4367673397064209 seconds.\n",
      "Time taken: 0.43466997146606445 seconds.\n",
      "Time taken: 0.39026927947998047 seconds.\n",
      "Time taken: 0.29619908332824707 seconds.\n",
      "Time taken: 0.2909972667694092 seconds.\n",
      "Time taken: 0.20513367652893066 seconds.\n",
      "Time taken: 0.3694479465484619 seconds.\n",
      "Time taken: 0.3853909969329834 seconds.\n",
      "Time taken: 0.39769864082336426 seconds.\n",
      "Time taken: 0.26225900650024414 seconds.\n",
      "Time taken: 0.33150529861450195 seconds.\n",
      "Time taken: 0.38099050521850586 seconds.\n",
      "Time taken: 0.4137389659881592 seconds.\n",
      "Time taken: 0.39847850799560547 seconds.\n",
      "Time taken: 0.3524491786956787 seconds.\n",
      "Time taken: 0.31483912467956543 seconds.\n",
      "Time taken: 0.3439905643463135 seconds.\n",
      "Time taken: 0.3478398323059082 seconds.\n",
      "Time taken: 0.38268399238586426 seconds.\n",
      "Time taken: 0.44209861755371094 seconds.\n",
      "Time taken: 0.3429906368255615 seconds.\n",
      "Time taken: 0.18148493766784668 seconds.\n",
      "Time taken: 0.37267088890075684 seconds.\n",
      "Time taken: 0.38291382789611816 seconds.\n",
      "Time taken: 0.3197481632232666 seconds.\n",
      "Time taken: 0.17729830741882324 seconds.\n",
      "Time taken: 0.36794447898864746 seconds.\n",
      "Time taken: 0.45574402809143066 seconds.\n",
      "Time taken: 0.24207711219787598 seconds.\n",
      "Time taken: 0.25991034507751465 seconds.\n",
      "Time taken: 0.39486241340637207 seconds.\n",
      "Time taken: 0.3381078243255615 seconds.\n",
      "Time taken: 0.35335659980773926 seconds.\n",
      "Time taken: 0.32989072799682617 seconds.\n",
      "Time taken: 0.33591341972351074 seconds.\n",
      "Time taken: 0.26358628273010254 seconds.\n",
      "Time taken: 0.4167051315307617 seconds.\n",
      "Time taken: 0.2850666046142578 seconds.\n",
      "Time taken: 0.6696991920471191 seconds.\n",
      "Time taken: 0.41534996032714844 seconds.\n",
      "Time taken: 0.28861498832702637 seconds.\n",
      "Time taken: 0.2626814842224121 seconds.\n",
      "Time taken: 0.31166791915893555 seconds.\n",
      "Time taken: 0.3715035915374756 seconds.\n",
      "Time taken: 0.31823039054870605 seconds.\n",
      "Time taken: 0.3679823875427246 seconds.\n",
      "Time taken: 0.28663063049316406 seconds.\n",
      "Time taken: 0.39278101921081543 seconds.\n",
      "Time taken: 0.29474377632141113 seconds.\n",
      "Time taken: 0.500962495803833 seconds.\n",
      "Time taken: 0.447068452835083 seconds.\n",
      "Time taken: 0.2594492435455322 seconds.\n",
      "Time taken: 0.3437540531158447 seconds.\n",
      "Time taken: 0.4308891296386719 seconds.\n",
      "Time taken: 0.2703516483306885 seconds.\n",
      "Time taken: 0.2906985282897949 seconds.\n",
      "Time taken: 0.353762149810791 seconds.\n",
      "Time taken: 0.18007636070251465 seconds.\n",
      "Time taken: 0.3052346706390381 seconds.\n",
      "Time taken: 0.2663538455963135 seconds.\n",
      "Time taken: 0.5256116390228271 seconds.\n",
      "Time taken: 0.34380221366882324 seconds.\n",
      "Time taken: 0.3388857841491699 seconds.\n",
      "Time taken: 0.3090951442718506 seconds.\n",
      "Time taken: 0.4634735584259033 seconds.\n",
      "Time taken: 0.3141496181488037 seconds.\n",
      "Time taken: 0.2912485599517822 seconds.\n",
      "Time taken: 0.3458230495452881 seconds.\n",
      "Time taken: 0.35262560844421387 seconds.\n",
      "Time taken: 0.40622735023498535 seconds.\n",
      "Time taken: 0.4461064338684082 seconds.\n",
      "Time taken: 0.3783755302429199 seconds.\n",
      "Time taken: 0.25096583366394043 seconds.\n",
      "Time taken: 0.3223893642425537 seconds.\n",
      "Time taken: 0.48645758628845215 seconds.\n",
      "Time taken: 0.1791243553161621 seconds.\n",
      "Time taken: 0.39716053009033203 seconds.\n",
      "Time taken: 0.3912951946258545 seconds.\n",
      "Time taken: 0.45252299308776855 seconds.\n",
      "Time taken: 0.29776453971862793 seconds.\n",
      "Time taken: 0.315720796585083 seconds.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "predictions = []\n",
    "for i in range(0, len(df2)):   # start from 0, step by batch\n",
    "    pred = predict(model, df2.iloc[i]['Diff'])   # list of predictions\n",
    "    predictions.append(pred)\n",
    "df2['LLM_inference'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T18:24:34.289404Z",
     "iopub.status.busy": "2025-08-22T18:24:34.289048Z",
     "iopub.status.idle": "2025-08-22T18:24:36.583014Z",
     "shell.execute_reply": "2025-08-22T18:24:36.582209Z",
     "shell.execute_reply.started": "2025-08-22T18:24:34.289380Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df2.to_csv('assgn2_analysis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-08-22T17:55:54.561830Z",
     "iopub.status.idle": "2025-08-22T17:55:54.562063Z",
     "shell.execute_reply": "2025-08-22T17:55:54.561964Z",
     "shell.execute_reply.started": "2025-08-22T17:55:54.561953Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(df2['Message'].iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-08-22T17:55:54.563325Z",
     "iopub.status.idle": "2025-08-22T17:55:54.563593Z",
     "shell.execute_reply": "2025-08-22T17:55:54.563494Z",
     "shell.execute_reply.started": "2025-08-22T17:55:54.563485Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "response = predict(model,df2['Diff'].iloc[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-08-22T17:55:54.564904Z",
     "iopub.status.idle": "2025-08-22T17:55:54.565123Z",
     "shell.execute_reply": "2025-08-22T17:55:54.565032Z",
     "shell.execute_reply.started": "2025-08-22T17:55:54.565024Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df2['Diff'].iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-08-22T17:55:54.565931Z",
     "iopub.status.idle": "2025-08-22T17:55:54.566241Z",
     "shell.execute_reply": "2025-08-22T17:55:54.566102Z",
     "shell.execute_reply.started": "2025-08-22T17:55:54.566091Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-08-22T17:55:54.567011Z",
     "iopub.status.idle": "2025-08-22T17:55:54.567280Z",
     "shell.execute_reply": "2025-08-22T17:55:54.567146Z",
     "shell.execute_reply.started": "2025-08-22T17:55:54.567136Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "predict(model,df2['Diff'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8181547,
     "sourceId": 12977521,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
