{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7308f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1235"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "analysis_df = pd.read_csv('final_analysis (1).csv')\n",
    "len(analysis_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c643be47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hash</th>\n",
       "      <th>Author</th>\n",
       "      <th>Message</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Change Type</th>\n",
       "      <th>Source Code (before)</th>\n",
       "      <th>Source Code (current)</th>\n",
       "      <th>Diff</th>\n",
       "      <th>LLM_inference</th>\n",
       "      <th>Overall_diff</th>\n",
       "      <th>Rectified Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4b97a810b509c93f44be4c037c7aa18fb8922884</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Pre-release 2023 December version (Mistral, Pr...</td>\n",
       "      <td>README.md</td>\n",
       "      <td>MODIFY</td>\n",
       "      <td>&lt;div class=\"align-center\"&gt;\\n  &lt;img src=\"./imag...</td>\n",
       "      <td>&lt;div class=\"align-center\"&gt;\\n  &lt;img src=\"./imag...</td>\n",
       "      <td>@@ -1,23 +1,25 @@\\n &lt;div class=\"align-center\"&gt;...</td>\n",
       "      <td>add more info about nvidia gpus</td>\n",
       "      <td>@@ -1,23 +1,25 @@\\n &lt;div class=\"align-center\"&gt;...</td>\n",
       "      <td>add more info about nvidia gpus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4b97a810b509c93f44be4c037c7aa18fb8922884</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Pre-release 2023 December version (Mistral, Pr...</td>\n",
       "      <td>Discord.png</td>\n",
       "      <td>MODIFY</td>\n",
       "      <td>PNG\\r\\n\u001a\\n</td>\n",
       "      <td>PNG\\r\\n\u001a\\n</td>\n",
       "      <td>Binary files a/images/Discord.png and b/images...</td>\n",
       "      <td>distro binary files</td>\n",
       "      <td>@@ -1,23 +1,25 @@\\n &lt;div class=\"align-center\"&gt;...</td>\n",
       "      <td>add more info about nvidia gpus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4b97a810b509c93f44be4c037c7aa18fb8922884</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Pre-release 2023 December version (Mistral, Pr...</td>\n",
       "      <td>LAION 2GPU.png</td>\n",
       "      <td>ADD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PNG\\r\\n\u001a\\n</td>\n",
       "      <td>Binary files /dev/null and b/images/LAION 2GPU...</td>\n",
       "      <td>distinguish 2gpu image from null</td>\n",
       "      <td>@@ -1,23 +1,25 @@\\n &lt;div class=\"align-center\"&gt;...</td>\n",
       "      <td>add more info about nvidia gpus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4b97a810b509c93f44be4c037c7aa18fb8922884</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Pre-release 2023 December version (Mistral, Pr...</td>\n",
       "      <td>LAION 2GPU.svg</td>\n",
       "      <td>DELETE</td>\n",
       "      <td>&lt;?xml version=\"1.0\" encoding=\"utf-8\" standalon...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@@ -1,1518 +0,0 @@\\n-&lt;?xml version=\"1.0\" encod...</td>\n",
       "      <td>add missing missing nodes in skeleton skeleton</td>\n",
       "      <td>@@ -1,23 +1,25 @@\\n &lt;div class=\"align-center\"&gt;...</td>\n",
       "      <td>add more info about nvidia gpus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4b97a810b509c93f44be4c037c7aa18fb8922884</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Pre-release 2023 December version (Mistral, Pr...</td>\n",
       "      <td>SlimOrca 1GPU.svg</td>\n",
       "      <td>DELETE</td>\n",
       "      <td>&lt;?xml version=\"1.0\" encoding=\"utf-8\" standalon...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@@ -1,1424 +0,0 @@\\n-&lt;?xml version=\"1.0\" encod...</td>\n",
       "      <td>add missing missing svg elements</td>\n",
       "      <td>@@ -1,23 +1,25 @@\\n &lt;div class=\"align-center\"&gt;...</td>\n",
       "      <td>add more info about nvidia gpus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>9050d6f5278e2373e66d17fc9ac8c2ec4f986e7e</td>\n",
       "      <td>Roland Tannous</td>\n",
       "      <td>tests for mxfp4 and quantized models merge fix...</td>\n",
       "      <td>run_test.sh</td>\n",
       "      <td>ADD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#!/bin/bash\\nset -e\\n\\necho \"=================...</td>\n",
       "      <td>@@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...</td>\n",
       "      <td>add missing line</td>\n",
       "      <td>@@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...</td>\n",
       "      <td>add test for merged model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>9050d6f5278e2373e66d17fc9ac8c2ec4f986e7e</td>\n",
       "      <td>Roland Tannous</td>\n",
       "      <td>tests for mxfp4 and quantized models merge fix...</td>\n",
       "      <td>test_merged_model.py</td>\n",
       "      <td>ADD</td>\n",
       "      <td>NaN</td>\n",
       "      <td># inference_on_merged.py\\nfrom unsloth import ...</td>\n",
       "      <td>@@ -0,0 +1,55 @@\\n+# inference_on_merged.py\\n+...</td>\n",
       "      <td>add test for merge</td>\n",
       "      <td>@@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...</td>\n",
       "      <td>add test for merged model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>9050d6f5278e2373e66d17fc9ac8c2ec4f986e7e</td>\n",
       "      <td>Roland Tannous</td>\n",
       "      <td>tests for mxfp4 and quantized models merge fix...</td>\n",
       "      <td>train_and_merge.py</td>\n",
       "      <td>ADD</td>\n",
       "      <td>NaN</td>\n",
       "      <td># train_and_merge.py\\nfrom unsloth import Fast...</td>\n",
       "      <td>@@ -0,0 +1,71 @@\\n+# train_and_merge.py\\n+from...</td>\n",
       "      <td>add examples to train_and_merge</td>\n",
       "      <td>@@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...</td>\n",
       "      <td>add test for merged model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>9050d6f5278e2373e66d17fc9ac8c2ec4f986e7e</td>\n",
       "      <td>Roland Tannous</td>\n",
       "      <td>tests for mxfp4 and quantized models merge fix...</td>\n",
       "      <td>test_merge_4bit_validation.py</td>\n",
       "      <td>ADD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>from unsloth import FastLanguageModel\\nfrom un...</td>\n",
       "      <td>@@ -0,0 +1,223 @@\\n+from unsloth import FastLa...</td>\n",
       "      <td>add test case for formatting prompts</td>\n",
       "      <td>@@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...</td>\n",
       "      <td>add test for merged model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>12737e503d32fc1464f8e38536be96d92db4f7d8</td>\n",
       "      <td>stevenxdavis</td>\n",
       "      <td>Fix incorrect function call in test_qwen3_grpo...</td>\n",
       "      <td>test_qwen3_grpo.py</td>\n",
       "      <td>MODIFY</td>\n",
       "      <td>from unsloth import FastLanguageModel\\nimport ...</td>\n",
       "      <td>from unsloth import FastLanguageModel\\nimport ...</td>\n",
       "      <td>@@ -415,7 +415,8 @@ sampling_params = Sampling...</td>\n",
       "      <td>update sample_params.rb</td>\n",
       "      <td>@@ -415,7 +415,8 @@ sampling_params = Sampling...</td>\n",
       "      <td>fast_generate example</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1235 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Hash          Author  \\\n",
       "0     4b97a810b509c93f44be4c037c7aa18fb8922884      Daniel Han   \n",
       "1     4b97a810b509c93f44be4c037c7aa18fb8922884      Daniel Han   \n",
       "2     4b97a810b509c93f44be4c037c7aa18fb8922884      Daniel Han   \n",
       "3     4b97a810b509c93f44be4c037c7aa18fb8922884      Daniel Han   \n",
       "4     4b97a810b509c93f44be4c037c7aa18fb8922884      Daniel Han   \n",
       "...                                        ...             ...   \n",
       "1230  9050d6f5278e2373e66d17fc9ac8c2ec4f986e7e  Roland Tannous   \n",
       "1231  9050d6f5278e2373e66d17fc9ac8c2ec4f986e7e  Roland Tannous   \n",
       "1232  9050d6f5278e2373e66d17fc9ac8c2ec4f986e7e  Roland Tannous   \n",
       "1233  9050d6f5278e2373e66d17fc9ac8c2ec4f986e7e  Roland Tannous   \n",
       "1234  12737e503d32fc1464f8e38536be96d92db4f7d8    stevenxdavis   \n",
       "\n",
       "                                                Message  \\\n",
       "0     Pre-release 2023 December version (Mistral, Pr...   \n",
       "1     Pre-release 2023 December version (Mistral, Pr...   \n",
       "2     Pre-release 2023 December version (Mistral, Pr...   \n",
       "3     Pre-release 2023 December version (Mistral, Pr...   \n",
       "4     Pre-release 2023 December version (Mistral, Pr...   \n",
       "...                                                 ...   \n",
       "1230  tests for mxfp4 and quantized models merge fix...   \n",
       "1231  tests for mxfp4 and quantized models merge fix...   \n",
       "1232  tests for mxfp4 and quantized models merge fix...   \n",
       "1233  tests for mxfp4 and quantized models merge fix...   \n",
       "1234  Fix incorrect function call in test_qwen3_grpo...   \n",
       "\n",
       "                           Filename Change Type  \\\n",
       "0                         README.md      MODIFY   \n",
       "1                       Discord.png      MODIFY   \n",
       "2                    LAION 2GPU.png         ADD   \n",
       "3                    LAION 2GPU.svg      DELETE   \n",
       "4                 SlimOrca 1GPU.svg      DELETE   \n",
       "...                             ...         ...   \n",
       "1230                    run_test.sh         ADD   \n",
       "1231           test_merged_model.py         ADD   \n",
       "1232             train_and_merge.py         ADD   \n",
       "1233  test_merge_4bit_validation.py         ADD   \n",
       "1234             test_qwen3_grpo.py      MODIFY   \n",
       "\n",
       "                                   Source Code (before)  \\\n",
       "0     <div class=\"align-center\">\\n  <img src=\"./imag...   \n",
       "1                                            PNG\\r\\n\u001a\\n   \n",
       "2                                                   NaN   \n",
       "3     <?xml version=\"1.0\" encoding=\"utf-8\" standalon...   \n",
       "4     <?xml version=\"1.0\" encoding=\"utf-8\" standalon...   \n",
       "...                                                 ...   \n",
       "1230                                                NaN   \n",
       "1231                                                NaN   \n",
       "1232                                                NaN   \n",
       "1233                                                NaN   \n",
       "1234  from unsloth import FastLanguageModel\\nimport ...   \n",
       "\n",
       "                                  Source Code (current)  \\\n",
       "0     <div class=\"align-center\">\\n  <img src=\"./imag...   \n",
       "1                                            PNG\\r\\n\u001a\\n   \n",
       "2                                            PNG\\r\\n\u001a\\n   \n",
       "3                                                   NaN   \n",
       "4                                                   NaN   \n",
       "...                                                 ...   \n",
       "1230  #!/bin/bash\\nset -e\\n\\necho \"=================...   \n",
       "1231  # inference_on_merged.py\\nfrom unsloth import ...   \n",
       "1232  # train_and_merge.py\\nfrom unsloth import Fast...   \n",
       "1233  from unsloth import FastLanguageModel\\nfrom un...   \n",
       "1234  from unsloth import FastLanguageModel\\nimport ...   \n",
       "\n",
       "                                                   Diff  \\\n",
       "0     @@ -1,23 +1,25 @@\\n <div class=\"align-center\">...   \n",
       "1     Binary files a/images/Discord.png and b/images...   \n",
       "2     Binary files /dev/null and b/images/LAION 2GPU...   \n",
       "3     @@ -1,1518 +0,0 @@\\n-<?xml version=\"1.0\" encod...   \n",
       "4     @@ -1,1424 +0,0 @@\\n-<?xml version=\"1.0\" encod...   \n",
       "...                                                 ...   \n",
       "1230  @@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...   \n",
       "1231  @@ -0,0 +1,55 @@\\n+# inference_on_merged.py\\n+...   \n",
       "1232  @@ -0,0 +1,71 @@\\n+# train_and_merge.py\\n+from...   \n",
       "1233  @@ -0,0 +1,223 @@\\n+from unsloth import FastLa...   \n",
       "1234  @@ -415,7 +415,8 @@ sampling_params = Sampling...   \n",
       "\n",
       "                                       LLM_inference  \\\n",
       "0                    add more info about nvidia gpus   \n",
       "1                                distro binary files   \n",
       "2                   distinguish 2gpu image from null   \n",
       "3     add missing missing nodes in skeleton skeleton   \n",
       "4                   add missing missing svg elements   \n",
       "...                                              ...   \n",
       "1230                                add missing line   \n",
       "1231                              add test for merge   \n",
       "1232                 add examples to train_and_merge   \n",
       "1233            add test case for formatting prompts   \n",
       "1234                         update sample_params.rb   \n",
       "\n",
       "                                           Overall_diff  \\\n",
       "0     @@ -1,23 +1,25 @@\\n <div class=\"align-center\">...   \n",
       "1     @@ -1,23 +1,25 @@\\n <div class=\"align-center\">...   \n",
       "2     @@ -1,23 +1,25 @@\\n <div class=\"align-center\">...   \n",
       "3     @@ -1,23 +1,25 @@\\n <div class=\"align-center\">...   \n",
       "4     @@ -1,23 +1,25 @@\\n <div class=\"align-center\">...   \n",
       "...                                                 ...   \n",
       "1230  @@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...   \n",
       "1231  @@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...   \n",
       "1232  @@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...   \n",
       "1233  @@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...   \n",
       "1234  @@ -415,7 +415,8 @@ sampling_params = Sampling...   \n",
       "\n",
       "                    Rectified Message  \n",
       "0     add more info about nvidia gpus  \n",
       "1     add more info about nvidia gpus  \n",
       "2     add more info about nvidia gpus  \n",
       "3     add more info about nvidia gpus  \n",
       "4     add more info about nvidia gpus  \n",
       "...                               ...  \n",
       "1230        add test for merged model  \n",
       "1231        add test for merged model  \n",
       "1232        add test for merged model  \n",
       "1233        add test for merged model  \n",
       "1234            fast_generate example  \n",
       "\n",
       "[1235 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea37a735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "radon_df = pd.read_csv('radon_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81f8886c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@ -19,6 +19,14 @@ import warnings\n",
      " import gc\n",
      " warnings.filterwarnings(action = \"ignore\", category = UserWarning, module = \"torch\")\n",
      " import bitsandbytes as bnb\n",
      "+from transformers.models.llama.modeling_llama import logger\n",
      "+\n",
      "+__version__ = \"2023.12\"\n",
      "+__all__ = [\n",
      "+    \"prepare_model_for_kbit_training\",\n",
      "+    \"patch_tokenizer\",\n",
      "+    \"print_unsloth_message\",\n",
      "+]\n",
      " \n",
      " \n",
      " def prepare_model_for_kbit_training(\n",
      "@@ -59,3 +67,38 @@ def prepare_model_for_kbit_training(\n",
      " \n",
      "     return model\n",
      " pass\n",
      "+\n",
      "+\n",
      "+def patch_tokenizer(model, tokenizer):\n",
      "+    if not hasattr(tokenizer, \"pad_token\") or tokenizer.pad_token is None:\n",
      "+        # Fixes https://github.com/unslothai/unsloth/issues/5\n",
      "+        if hasattr(tokenizer, \"unk_token\"):\n",
      "+            tokenizer.add_special_tokens({\"pad_token\" : tokenizer.unk_token})\n",
      "+            tokenizer.pad_token = tokenizer.unk_token\n",
      "+        else:\n",
      "+            logger.warning_one(\n",
      "+                f\"{model.config._name_or_path} does not have a padding or unknown token!\\n\"\\\n",
      "+                f\"Will use the EOS token of id {tokenizer.eos_token_id} as padding.\"\n",
      "+            )\n",
      "+            assert(hasattr(tokenizer, \"eos_token\"))\n",
      "+            tokenizer.add_special_tokens({\"pad_token\" : tokenizer.eos_token})\n",
      "+            tokenizer.pad_token = tokenizer.eos_token\n",
      "+        config = model.config.update({\"pad_token_id\" : tokenizer.eos_token_id})\n",
      "+    pass\n",
      "+    return model, tokenizer\n",
      "+pass\n",
      "+\n",
      "+\n",
      "+def print_unsloth_message(name):\n",
      "+    SUPPORTS_BFLOAT16 = torch.cuda.is_bf16_supported()\n",
      "+    gpu_stats = torch.cuda.get_device_properties(0)\n",
      "+    max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
      "+\n",
      "+    statistics = \\\n",
      "+       f\"==((====))==  Unsloth: Fast {name} patching release {__version__}\\n\"\\\n",
      "+       f\"   \\\\\\   /|    GPU: {gpu_stats.name}. Max memory: {max_memory} GB\\n\"\\\n",
      "+       f\"O^O/ \\_/ \\\\    CUDA compute capability = {gpu_stats.major}.{gpu_stats.minor}\\n\"\\\n",
      "+       f\"\\        /    Pytorch version: {torch.__version__}. CUDA Toolkit = {torch.version.cuda}\\n\"\\\n",
      "+       f' \"-____-\"     bfloat16 support = {str(SUPPORTS_BFLOAT16).upper()}\\n'\n",
      "+    print(statistics)\n",
      "+pass\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(req_df.iloc[1]['Diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f437522f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03c6a200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hash                              2d5d88487463e76f75002be3b2704267ec96e68a\n",
      "Author                                                     Daniel Han-Chen\n",
      "Message                                                  tokenizer pad fix\n",
      "Filename                                                         _utils.py\n",
      "Change Type                                                         MODIFY\n",
      "Source Code (before)     # Copyright 2023-present Daniel Han-Chen & the...\n",
      "Source Code (current)    # Copyright 2023-present Daniel Han-Chen & the...\n",
      "Diff                     @@ -19,6 +19,14 @@ import warnings\\n import gc...\n",
      "LLM_inference                                          add fix for unsloth\n",
      "Overall_diff             @@ -19,6 +19,14 @@ import warnings\\n import gc...\n",
      "Rectified Message                                      add fix for unsloth\n",
      "MI_Before                                                            100.0\n",
      "MI_After                                                         78.270117\n",
      "CC_Before                                                              5.0\n",
      "CC_After                                                              11.0\n",
      "LOC_Before                                                            61.0\n",
      "LOC_After                                                            104.0\n",
      "MI_Change                                                       -21.729883\n",
      "CC_Change                                                              6.0\n",
      "LOC_Change                                                            43.0\n",
      "Name: 12, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(req_df.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c151ce7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "504862c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@ -0,0 +1,33 @@\n",
      "+# Copyright 2023-present Daniel Han-Chen & the Unsloth team. All rights reserved.\n",
      "+#\n",
      "+# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      "+# you may not use this file except in compliance with the License.\n",
      "+# You may obtain a copy of the License at\n",
      "+#\n",
      "+#     http://www.apache.org/licenses/LICENSE-2.0\n",
      "+#\n",
      "+# Unless required by applicable law or agreed to in writing, software\n",
      "+# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
      "+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      "+# See the License for the specific language governing permissions and\n",
      "+# limitations under the License.\n",
      "+\n",
      "+import time\n",
      "+from contextlib import contextmanager\n",
      "+\n",
      "+\n",
      "+@contextmanager\n",
      "+def timer(name):\n",
      "+    start = time.time()\n",
      "+    yield\n",
      "+    end = time.time()\n",
      "+    print(f\"{name} took {end - start:.2f} seconds\")\n",
      "+\n",
      "+\n",
      "+@contextmanager\n",
      "+def header_footer_context(title: str, char=\"-\"):\n",
      "+    print()\n",
      "+    print(f\"{char}\" * 50 + f\" {title} \" + f\"{char}\" * 50)\n",
      "+    yield\n",
      "+    print(f\"{char}\" * (100 + len(title) + 2))\n",
      "+    print()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(req_df.iloc[0]['Diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582f6b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "from radon.raw import analyze\n",
    "raw_metrics = analyze(\"\"\"def _split_tokens(tokens, token, value):\n",
    "    '''Split a list of tokens on the specified token pair (token, value),\n",
    "    where *token* is the token type (i.e. its code) and *value* its actual\n",
    "    value in the code.\n",
    "    '''\n",
    "    res = [[]]\n",
    "    for token_values in tokens:\n",
    "        if (token, value) == token_values[:2]:\n",
    "            res.append([])\n",
    "            continue\n",
    "        res[-1].append(token_values)\n",
    "    return res\n",
    "\"\"\")\n",
    "print(raw_metrics.loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "26fc0f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CC score: 3.0\n",
      "CC Rank A\n",
      "MI score: 68.2206039600699\n",
      "MI Rank: A\n"
     ]
    }
   ],
   "source": [
    "from radon.complexity import cc_visit, cc_rank\n",
    "from radon.metrics import mi_visit, mi_rank\n",
    "\n",
    "code = '''\n",
    "class A(object):\n",
    "    def meth(self):\n",
    "        return sum(i for i in range(10) if i - 2 < 5)\n",
    "\n",
    "def fib(n):\n",
    "    if n < 2: return 1\n",
    "    return fib(n - 1) + fib(n - 2)\n",
    "'''\n",
    "cc_blocks = cc_visit(code)\n",
    "mi_score = mi_visit(code, True)  # True = return float instead of string\n",
    "cc_score = sum(block.complexity for block in cc_blocks)/len(cc_blocks)\n",
    "print(\"CC score:\", cc_score)\n",
    "print(\"CC Rank\",cc_rank(cc_score))\n",
    "print(\"MI score:\", mi_score)\n",
    "print(\"MI Rank:\", mi_rank(mi_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac59ca8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_processed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_processed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSemantic_Similarity\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_processed\u001b[49m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m row: semantic_similarity(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSource Code (before)\u001b[39m\u001b[38;5;124m\"\u001b[39m], row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSource Code (current)\u001b[39m\u001b[38;5;124m\"\u001b[39m]), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      3\u001b[0m )\n\u001b[0;32m      4\u001b[0m df_processed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToken_Similarity\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df_processed\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m row: token_similarity_bleu(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSource Code (before)\u001b[39m\u001b[38;5;124m\"\u001b[39m], row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSource Code (current)\u001b[39m\u001b[38;5;124m\"\u001b[39m]), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclassify_semantic\u001b[39m(sim):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_processed' is not defined"
     ]
    }
   ],
   "source": [
    "df_processed[\"Semantic_Similarity\"] = df_processed.apply(\n",
    "    lambda row: semantic_similarity(str(row[\"Source Code (before)\"]),str(row[\"Source Code (current)\"])), axis=1\n",
    ")\n",
    "df_processed[\"Token_Similarity\"] = df_processed.apply(\n",
    "    lambda row: token_similarity_bleu(str(row[\"Source Code (before)\"]), str(row[\"Source Code (current)\"])), axis=1\n",
    ")\n",
    "def classify_semantic(sim):\n",
    "    return \"Minor\" if sim >= 0.80 else \"Major\"\n",
    "\n",
    "def classify_token(sim):\n",
    "    return \"Minor\" if sim >= 0.75 else \"Major\"\n",
    "df_processed[\"Semantic_Class\"] = df[\"Semantic_Similarity\"].apply(classify_semantic)\n",
    "df_processed[\"Token_Class\"] = df[\"Token_Similarity\"].apply(classify_token)\n",
    "df_processed[\"Classes_Agree\"] = df_processed.apply(\n",
    "    lambda row: \"YES\" if row[\"Semantic_Class\"] == row[\"Token_Class\"] else \"NO\", axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dfa7d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d44dd2ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Function(name='fib', lineno=6, col_offset=0, endline=8, is_method=False, classname=None, closures=[], complexity=2),\n",
       " Class(name='A', lineno=2, col_offset=0, endline=4, methods=[Function(name='meth', lineno=3, col_offset=4, endline=4, is_method=True, classname='A', closures=[], complexity=3)], inner_classes=[], real_complexity=4),\n",
       " Function(name='meth', lineno=3, col_offset=4, endline=4, is_method=True, classname='A', closures=[], complexity=3)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d6b1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F 6:0->8 fib - 2\n",
      "C 2:0->4 A - 4\n",
      "M 3:4->4 A.meth - 3\n"
     ]
    }
   ],
   "source": [
    "for block in cc_blocks:\n",
    "    print(block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa119f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "10b43c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n",
      "nan\n",
      "# Copyright 2023-present Daniel Han-Chen & the Unsloth team. All rights reserved.\n",
      "#\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      "# you may not use this file except in compliance with the License.\n",
      "# You may obtain a copy of the License at\n",
      "#\n",
      "#     http://www.apache.org/licenses/LICENSE-2.0\n",
      "#\n",
      "# Unless required by applicable law or agreed to in writing, software\n",
      "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
      "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      "# See the License for the specific language governing permissions and\n",
      "# limitations under the License.\n",
      "\n",
      "import time\n",
      "from contextlib import contextmanager\n",
      "\n",
      "\n",
      "@contextmanager\n",
      "def timer(name):\n",
      "    start = time.time()\n",
      "    yield\n",
      "    end = time.time()\n",
      "    print(f\"{name} took {end - start:.2f} seconds\")\n",
      "\n",
      "\n",
      "@contextmanager\n",
      "def header_footer_context(title: str, char=\"-\"):\n",
      "    print()\n",
      "    print(f\"{char}\" * 50 + f\" {title} \" + f\"{char}\" * 50)\n",
      "    yield\n",
      "    print(f\"{char}\" * (100 + len(title) + 2))\n",
      "    print()\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hash</th>\n",
       "      <th>Author</th>\n",
       "      <th>Message</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Change Type</th>\n",
       "      <th>Source Code (before)</th>\n",
       "      <th>Source Code (current)</th>\n",
       "      <th>Diff</th>\n",
       "      <th>LLM_inference</th>\n",
       "      <th>Overall_diff</th>\n",
       "      <th>Rectified Message</th>\n",
       "      <th>MI_Before</th>\n",
       "      <th>MI_After</th>\n",
       "      <th>CC_Before</th>\n",
       "      <th>CC_After</th>\n",
       "      <th>LOC_Before</th>\n",
       "      <th>LOC_After</th>\n",
       "      <th>MI_Change</th>\n",
       "      <th>CC_Change</th>\n",
       "      <th>LOC_Change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>05baf282c780961176987eb907d4d9dd7f95fbf0</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Fix Transformers 4.45 (#2151)\\n\\n* Update pypr...</td>\n",
       "      <td>__init__.py</td>\n",
       "      <td>ADD</td>\n",
       "      <td>NaN</td>\n",
       "      <td># Copyright 2023-present Daniel Han-Chen &amp; the...</td>\n",
       "      <td>@@ -0,0 +1,33 @@\\n+# Copyright 2023-present Da...</td>\n",
       "      <td>add contextmanager_context.py</td>\n",
       "      <td>@@ -29,7 +29,7 @@ version = {attr = \"unsloth.m...</td>\n",
       "      <td>add docs for unsloth qlora and merge tests</td>\n",
       "      <td>100.0</td>\n",
       "      <td>87.587742</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>-12.412258</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Hash      Author  \\\n",
       "923  05baf282c780961176987eb907d4d9dd7f95fbf0  Daniel Han   \n",
       "\n",
       "                                               Message     Filename  \\\n",
       "923  Fix Transformers 4.45 (#2151)\\n\\n* Update pypr...  __init__.py   \n",
       "\n",
       "    Change Type Source Code (before)  \\\n",
       "923         ADD                  NaN   \n",
       "\n",
       "                                 Source Code (current)  \\\n",
       "923  # Copyright 2023-present Daniel Han-Chen & the...   \n",
       "\n",
       "                                                  Diff  \\\n",
       "923  @@ -0,0 +1,33 @@\\n+# Copyright 2023-present Da...   \n",
       "\n",
       "                     LLM_inference  \\\n",
       "923  add contextmanager_context.py   \n",
       "\n",
       "                                          Overall_diff  \\\n",
       "923  @@ -29,7 +29,7 @@ version = {attr = \"unsloth.m...   \n",
       "\n",
       "                              Rectified Message  MI_Before   MI_After  \\\n",
       "923  add docs for unsloth qlora and merge tests      100.0  87.587742   \n",
       "\n",
       "     CC_Before  CC_After  LOC_Before  LOC_After  MI_Change  CC_Change  \\\n",
       "923        0.0       2.0         1.0       33.0 -12.412258        2.0   \n",
       "\n",
       "     LOC_Change  \n",
       "923        32.0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "req_df = radon_df[(radon_df['CC_Change']!=0) & (radon_df['LOC_Change'].notna()) & (radon_df['LOC_After']<=40) & (radon_df['LOC_Before']<=30) ]\n",
    "print(req_df.iloc[0]['CC_Change'])\n",
    "print(req_df.iloc[0]['Source Code (before)'])\n",
    "print(req_df.iloc[0]['Source Code (current)'])\n",
    "req_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91004c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module(\n",
      "    body=[\n",
      "        FunctionDef(\n",
      "            lineno=2,\n",
      "            col_offset=0,\n",
      "            end_lineno=9,\n",
      "            end_col_offset=29,\n",
      "            name='example',\n",
      "            args=arguments(\n",
      "                posonlyargs=[],\n",
      "                args=[arg(lineno=2, col_offset=12, end_lineno=2, end_col_offset=13, arg='x', annotation=None, type_comment=None)],\n",
      "                vararg=None,\n",
      "                kwonlyargs=[],\n",
      "                kw_defaults=[],\n",
      "                kwarg=None,\n",
      "                defaults=[],\n",
      "            ),\n",
      "            body=[\n",
      "                If(\n",
      "                    lineno=3,\n",
      "                    col_offset=4,\n",
      "                    end_lineno=9,\n",
      "                    end_col_offset=29,\n",
      "                    test=Compare(\n",
      "                        lineno=3,\n",
      "                        col_offset=7,\n",
      "                        end_lineno=3,\n",
      "                        end_col_offset=12,\n",
      "                        left=Name(lineno=3, col_offset=7, end_lineno=3, end_col_offset=8, id='x', ctx=Load()),\n",
      "                        ops=[Gt()],\n",
      "                        comparators=[Constant(lineno=3, col_offset=11, end_lineno=3, end_col_offset=12, value=0, kind=None)],\n",
      "                    ),\n",
      "                    body=[\n",
      "                        Expr(\n",
      "                            lineno=4,\n",
      "                            col_offset=8,\n",
      "                            end_lineno=4,\n",
      "                            end_col_offset=25,\n",
      "                            value=Call(\n",
      "                                lineno=4,\n",
      "                                col_offset=8,\n",
      "                                end_lineno=4,\n",
      "                                end_col_offset=25,\n",
      "                                func=Name(lineno=4, col_offset=8, end_lineno=4, end_col_offset=13, id='print', ctx=Load()),\n",
      "                                args=[Constant(lineno=4, col_offset=14, end_lineno=4, end_col_offset=24, value='Positive', kind=None)],\n",
      "                                keywords=[],\n",
      "                            ),\n",
      "                        ),\n",
      "                    ],\n",
      "                    orelse=[\n",
      "                        If(\n",
      "                            lineno=6,\n",
      "                            col_offset=8,\n",
      "                            end_lineno=9,\n",
      "                            end_col_offset=29,\n",
      "                            test=Compare(\n",
      "                                lineno=6,\n",
      "                                col_offset=11,\n",
      "                                end_lineno=6,\n",
      "                                end_col_offset=17,\n",
      "                                left=Name(lineno=6, col_offset=11, end_lineno=6, end_col_offset=12, id='x', ctx=Load()),\n",
      "                                ops=[Eq()],\n",
      "                                comparators=[Constant(lineno=6, col_offset=16, end_lineno=6, end_col_offset=17, value=0, kind=None)],\n",
      "                            ),\n",
      "                            body=[\n",
      "                                Expr(\n",
      "                                    lineno=7,\n",
      "                                    col_offset=12,\n",
      "                                    end_lineno=7,\n",
      "                                    end_col_offset=25,\n",
      "                                    value=Call(\n",
      "                                        lineno=7,\n",
      "                                        col_offset=12,\n",
      "                                        end_lineno=7,\n",
      "                                        end_col_offset=25,\n",
      "                                        func=Name(lineno=7, col_offset=12, end_lineno=7, end_col_offset=17, id='print', ctx=Load()),\n",
      "                                        args=[Constant(lineno=7, col_offset=18, end_lineno=7, end_col_offset=24, value='Zero', kind=None)],\n",
      "                                        keywords=[],\n",
      "                                    ),\n",
      "                                ),\n",
      "                            ],\n",
      "                            orelse=[\n",
      "                                Expr(\n",
      "                                    lineno=9,\n",
      "                                    col_offset=12,\n",
      "                                    end_lineno=9,\n",
      "                                    end_col_offset=29,\n",
      "                                    value=Call(\n",
      "                                        lineno=9,\n",
      "                                        col_offset=12,\n",
      "                                        end_lineno=9,\n",
      "                                        end_col_offset=29,\n",
      "                                        func=Name(lineno=9, col_offset=12, end_lineno=9, end_col_offset=17, id='print', ctx=Load()),\n",
      "                                        args=[Constant(lineno=9, col_offset=18, end_lineno=9, end_col_offset=28, value='Negative', kind=None)],\n",
      "                                        keywords=[],\n",
      "                                    ),\n",
      "                                ),\n",
      "                            ],\n",
      "                        ),\n",
      "                    ],\n",
      "                ),\n",
      "            ],\n",
      "            decorator_list=[],\n",
      "            returns=None,\n",
      "            type_comment=None,\n",
      "        ),\n",
      "    ],\n",
      "    type_ignores=[],\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import astpretty\n",
    "\n",
    "code = \"\"\"\n",
    "def example(x):\n",
    "    if x > 0:\n",
    "        print(\"Positive\")\n",
    "    else:\n",
    "        if x == 0:\n",
    "            print(\"Zero\")\n",
    "        else:\n",
    "            print(\"Negative\")\n",
    "\"\"\"\n",
    "\n",
    "tree = ast.parse(code)\n",
    "astpretty.pprint(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6951d241",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02bcf298",
   "metadata": {},
   "source": [
    "- To calculate cyclomatic complexity(CC) radon traverses AST(Abstract Syntax Tree) and calculates number of decision blocks\n",
    "- single comments -> the line contain only that comment\n",
    "- docstring isn't counted in multi, its in SLOC and LLOC\n",
    "The following are the definitions employed by Radon:\n",
    "\n",
    "- LOC: The total number of lines of code. It does not necessarily correspond to the number of lines in the file.\n",
    "- LLOC: The number of logical lines of code. Every logical line of code contains exactly one statement.\n",
    "- SLOC: The number of source lines of code - not necessarily corresponding to the LLOC.\n",
    "- Comments: The number of comment lines. Multi-line strings are not counted as comment since, to the Python interpreter, they are just strings.\n",
    "- Multi: The number of lines which represent multi-line strings.\n",
    "- Blanks: The number of blank lines (or whitespace-only ones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9358b7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting astpretty\n",
      "  Downloading astpretty-3.0.0-py2.py3-none-any.whl.metadata (5.5 kB)\n",
      "Downloading astpretty-3.0.0-py2.py3-none-any.whl (4.9 kB)\n",
      "Installing collected packages: astpretty\n",
      "Successfully installed astpretty-3.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~andas (C:\\Users\\Vedant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~andas (C:\\Users\\Vedant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~andas (C:\\Users\\Vedant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~andas (C:\\Users\\Vedant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install astpretty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25525b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hash</th>\n",
       "      <th>Message</th>\n",
       "      <th>Source Code (before)</th>\n",
       "      <th>Source Code (current)</th>\n",
       "      <th>Diff</th>\n",
       "      <th>LLM_inference</th>\n",
       "      <th>Rectified Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4b97a810b509c93f44be4c037c7aa18fb8922884</td>\n",
       "      <td>Pre-release 2023 December version (Mistral, Pr...</td>\n",
       "      <td>&lt;div class=\"align-center\"&gt;\\n  &lt;img src=\"./imag...</td>\n",
       "      <td>&lt;div class=\"align-center\"&gt;\\n  &lt;img src=\"./imag...</td>\n",
       "      <td>@@ -1,23 +1,25 @@\\n &lt;div class=\"align-center\"&gt;...</td>\n",
       "      <td>add more info about nvidia gpus</td>\n",
       "      <td>Pre-release 2023 December version (Mistral, Pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4b97a810b509c93f44be4c037c7aa18fb8922884</td>\n",
       "      <td>Pre-release 2023 December version (Mistral, Pr...</td>\n",
       "      <td>PNG\\r\\n\u001a\\n</td>\n",
       "      <td>PNG\\r\\n\u001a\\n</td>\n",
       "      <td>Binary files a/images/Discord.png and b/images...</td>\n",
       "      <td>distro binary files</td>\n",
       "      <td>Pre-release 2023 December version (Mistral, Pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4b97a810b509c93f44be4c037c7aa18fb8922884</td>\n",
       "      <td>Pre-release 2023 December version (Mistral, Pr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PNG\\r\\n\u001a\\n</td>\n",
       "      <td>Binary files /dev/null and b/images/LAION 2GPU...</td>\n",
       "      <td>distinguish 2gpu image from null</td>\n",
       "      <td>Pre-release 2023 December version (Mistral, Pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4b97a810b509c93f44be4c037c7aa18fb8922884</td>\n",
       "      <td>Pre-release 2023 December version (Mistral, Pr...</td>\n",
       "      <td>&lt;?xml version=\"1.0\" encoding=\"utf-8\" standalon...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@@ -1,1518 +0,0 @@\\n-&lt;?xml version=\"1.0\" encod...</td>\n",
       "      <td>add missing missing nodes in skeleton skeleton</td>\n",
       "      <td>Pre-release 2023 December version (Mistral, Pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4b97a810b509c93f44be4c037c7aa18fb8922884</td>\n",
       "      <td>Pre-release 2023 December version (Mistral, Pr...</td>\n",
       "      <td>&lt;?xml version=\"1.0\" encoding=\"utf-8\" standalon...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@@ -1,1424 +0,0 @@\\n-&lt;?xml version=\"1.0\" encod...</td>\n",
       "      <td>add missing missing svg elements</td>\n",
       "      <td>Pre-release 2023 December version (Mistral, Pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Hash  \\\n",
       "0  4b97a810b509c93f44be4c037c7aa18fb8922884   \n",
       "1  4b97a810b509c93f44be4c037c7aa18fb8922884   \n",
       "2  4b97a810b509c93f44be4c037c7aa18fb8922884   \n",
       "3  4b97a810b509c93f44be4c037c7aa18fb8922884   \n",
       "4  4b97a810b509c93f44be4c037c7aa18fb8922884   \n",
       "\n",
       "                                             Message  \\\n",
       "0  Pre-release 2023 December version (Mistral, Pr...   \n",
       "1  Pre-release 2023 December version (Mistral, Pr...   \n",
       "2  Pre-release 2023 December version (Mistral, Pr...   \n",
       "3  Pre-release 2023 December version (Mistral, Pr...   \n",
       "4  Pre-release 2023 December version (Mistral, Pr...   \n",
       "\n",
       "                                Source Code (before)  \\\n",
       "0  <div class=\"align-center\">\\n  <img src=\"./imag...   \n",
       "1                                         PNG\\r\\n\u001a\\n   \n",
       "2                                                NaN   \n",
       "3  <?xml version=\"1.0\" encoding=\"utf-8\" standalon...   \n",
       "4  <?xml version=\"1.0\" encoding=\"utf-8\" standalon...   \n",
       "\n",
       "                               Source Code (current)  \\\n",
       "0  <div class=\"align-center\">\\n  <img src=\"./imag...   \n",
       "1                                         PNG\\r\\n\u001a\\n   \n",
       "2                                         PNG\\r\\n\u001a\\n   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                                Diff  \\\n",
       "0  @@ -1,23 +1,25 @@\\n <div class=\"align-center\">...   \n",
       "1  Binary files a/images/Discord.png and b/images...   \n",
       "2  Binary files /dev/null and b/images/LAION 2GPU...   \n",
       "3  @@ -1,1518 +0,0 @@\\n-<?xml version=\"1.0\" encod...   \n",
       "4  @@ -1,1424 +0,0 @@\\n-<?xml version=\"1.0\" encod...   \n",
       "\n",
       "                                    LLM_inference  \\\n",
       "0                 add more info about nvidia gpus   \n",
       "1                             distro binary files   \n",
       "2                distinguish 2gpu image from null   \n",
       "3  add missing missing nodes in skeleton skeleton   \n",
       "4                add missing missing svg elements   \n",
       "\n",
       "                                   Rectified Message  \n",
       "0  Pre-release 2023 December version (Mistral, Pr...  \n",
       "1  Pre-release 2023 December version (Mistral, Pr...  \n",
       "2  Pre-release 2023 December version (Mistral, Pr...  \n",
       "3  Pre-release 2023 December version (Mistral, Pr...  \n",
       "4  Pre-release 2023 December version (Mistral, Pr...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "analysis_df = pd.read_csv('Lab_2_analysis.csv')\n",
    "final_df = analysis_df[['Hash','Message','Source Code (before)','Source Code (current)','Diff','LLM_inference','New Rectified Message']]\n",
    "final_df = final_df.rename(columns={'New Rectified Message':'Rectified Message'})\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45832d02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1e949fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total commits: 346\n",
      "Total files: 119\n",
      "Average modified files per commit: 3.53\n",
      "\n",
      "Fix type distribution:\n",
      "                                 Fix type  Count\n",
      "0                    add missing version     33\n",
      "1                     add missing import     32\n",
      "2                      update unsloth.py     18\n",
      "3                 add missing docstrings     16\n",
      "4                  add tests for unsloth     16\n",
      "..                                   ...    ...\n",
      "898    add tf.jit.approx_backward_kernel      1\n",
      "899         add docs for _rope_embedding      1\n",
      "900                   add libdevice.tanh      1\n",
      "901  add missing log message for unsloth      1\n",
      "902              update sample_params.rb      1\n",
      "\n",
      "[903 rows x 2 columns]\n",
      "\n",
      "Most frequently modified files:\n",
      "              Filename  Count\n",
      "0            llama.py    158\n",
      "1           _utils.py    146\n",
      "2         __init__.py     83\n",
      "3           loader.py     78\n",
      "4      pyproject.toml     76\n",
      "5             save.py     71\n",
      "6          mistral.py     51\n",
      "7           mapper.py     48\n",
      "8           vision.py     45\n",
      "9  tokenizer_utils.py     41\n",
      "\n",
      "Most frequently modified extensions:\n",
      "    Extension  Count\n",
      "0         py   1063\n",
      "1       toml     76\n",
      "2         md     73\n",
      "3        png     14\n",
      "4        txt      4\n",
      "5        svg      2\n",
      "6  gitignore      1\n",
      "7    LICENSE      1\n",
      "8         sh      1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "analysis_df = pd.read_csv('Lab_2_analysis.csv')\n",
    "\n",
    "# 1. Total number of commits and files\n",
    "total_commits = analysis_df[\"Hash\"].nunique()\n",
    "total_files = analysis_df[\"Filename\"].nunique()\n",
    "\n",
    "# 2. Average number of modified files per commit\n",
    "files_per_commit = analysis_df.groupby(\"Hash\")[\"Filename\"].nunique()\n",
    "avg_files_per_commit = files_per_commit.mean()\n",
    "\n",
    "fix_type_distribution = analysis_df[\"LLM_inference\"].value_counts().reset_index()\n",
    "fix_type_distribution.columns = ['Fix type','Count']\n",
    "top_files = analysis_df[\"Filename\"].value_counts().reset_index()\n",
    "top_files.columns = ['Filename','Count']\n",
    "analysis_df[\"Extension\"] = analysis_df[\"Filename\"].str.split(\".\").str[-1]\n",
    "top_extensions = analysis_df[\"Extension\"].value_counts().reset_index()\n",
    "top_extensions.columns = ['Extension','Count']\n",
    "\n",
    "# Display results\n",
    "print(\"Total commits:\", total_commits)\n",
    "print(\"Total files:\", total_files)\n",
    "print(\"Average modified files per commit:\", round(avg_files_per_commit,2))\n",
    "print(\"\\nFix type distribution:\\n\", fix_type_distribution)\n",
    "print(\"\\nMost frequently modified files:\\n\", top_files.head(10))\n",
    "print(\"\\nMost frequently modified extensions:\\n\", top_extensions.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd9c5758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>llama.py</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_utils.py</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__init__.py</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>loader.py</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pyproject.toml</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Filename  Count\n",
       "0        llama.py    158\n",
       "1       _utils.py    146\n",
       "2     __init__.py     83\n",
       "3       loader.py     78\n",
       "4  pyproject.toml     76"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_files.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8d60799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Extension</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>py</td>\n",
       "      <td>1063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>toml</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>md</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>png</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>txt</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>svg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gitignore</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LICENSE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sh</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Extension  Count\n",
       "0         py   1063\n",
       "1       toml     76\n",
       "2         md     73\n",
       "3        png     14\n",
       "4        txt      4\n",
       "5        svg      2\n",
       "6  gitignore      1\n",
       "7    LICENSE      1\n",
       "8         sh      1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d161573e",
   "metadata": {},
   "source": [
    "$$\n",
    "MI = \\max \\left[ 0,\\ 100 \\cdot \\frac{171 - 5.2 \\ln V - 0.23 G - 16.2 \\ln L + 50 \\sin(\\sqrt{2.4 C})}{171} \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ede54d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fix type</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>add missing version</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>add missing import</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>update unsloth.py</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>add missing docstrings</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>add tests for unsloth</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>add tf.jit.approx_backward_kernel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>add docs for _rope_embedding</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>add libdevice.tanh</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>add missing log message for unsloth</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>update sample_params.rb</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>903 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Fix type  Count\n",
       "0                    add missing version     33\n",
       "1                     add missing import     32\n",
       "2                      update unsloth.py     18\n",
       "3                 add missing docstrings     16\n",
       "4                  add tests for unsloth     16\n",
       "..                                   ...    ...\n",
       "898    add tf.jit.approx_backward_kernel      1\n",
       "899         add docs for _rope_embedding      1\n",
       "900                   add libdevice.tanh      1\n",
       "901  add missing log message for unsloth      1\n",
       "902              update sample_params.rb      1\n",
       "\n",
       "[903 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = fix_type_distribution.reset_index()\n",
    "df.columns = ['Fix type','Count']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f40b0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting radon\n",
      "  Downloading radon-6.0.1-py2.py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting mando<0.8,>=0.6 (from radon)\n",
      "  Downloading mando-0.7.1-py2.py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: colorama>=0.4.1 in c:\\users\\vedant\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from radon) (0.4.6)\n",
      "Requirement already satisfied: six in c:\\users\\vedant\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from mando<0.8,>=0.6->radon) (1.16.0)\n",
      "Downloading radon-6.0.1-py2.py3-none-any.whl (52 kB)\n",
      "Downloading mando-0.7.1-py2.py3-none-any.whl (28 kB)\n",
      "Installing collected packages: mando, radon\n",
      "\n",
      "   ---------------------------------------- 0/2 [mando]\n",
      "   ---------------------------------------- 0/2 [mando]\n",
      "   -------------------- ------------------- 1/2 [radon]\n",
      "   -------------------- ------------------- 1/2 [radon]\n",
      "   -------------------- ------------------- 1/2 [radon]\n",
      "   -------------------- ------------------- 1/2 [radon]\n",
      "   -------------------- ------------------- 1/2 [radon]\n",
      "   ---------------------------------------- 2/2 [radon]\n",
      "\n",
      "Successfully installed mando-0.7.1 radon-6.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~andas (C:\\Users\\Vedant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~andas (C:\\Users\\Vedant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~andas (C:\\Users\\Vedant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~andas (C:\\Users\\Vedant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install radon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3de57c7b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 52\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mconcat([df, pd\u001b[38;5;241m.\u001b[39mDataFrame(results)], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# df = pd.read_csv(\"your_dataset.csv\")\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m df_processed \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43manalysis_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Save results\u001b[39;00m\n\u001b[0;32m     55\u001b[0m df_processed\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mradon_results.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[5], line 31\u001b[0m, in \u001b[0;36mprocess_dataframe\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     28\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m---> 31\u001b[0m     mi_before, cc_before, loc_before \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_code\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSource Code (before)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m     mi_after, cc_after, loc_after \u001b[38;5;241m=\u001b[39m analyze_code(\u001b[38;5;28mstr\u001b[39m(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSource Code (current)\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[0;32m     34\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     35\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMI_Before\u001b[39m\u001b[38;5;124m\"\u001b[39m: mi_before,\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMI_After\u001b[39m\u001b[38;5;124m\"\u001b[39m: mi_after,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLOC_Change\u001b[39m\u001b[38;5;124m\"\u001b[39m: (loc_after \u001b[38;5;241m-\u001b[39m loc_before) \u001b[38;5;28;01mif\u001b[39;00m loc_before \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m loc_after \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     })\n",
      "Cell \u001b[1;32mIn[5], line 11\u001b[0m, in \u001b[0;36manalyze_code\u001b[1;34m(source_code)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Extract MI, CC, and LOC from given source code string.\"\"\"\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# Maintainability Index\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m     mi_score \u001b[38;5;241m=\u001b[39m \u001b[43mmi_visit\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# Cyclomatic Complexity (sum across all blocks)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     cc_blocks \u001b[38;5;241m=\u001b[39m cc_visit(source_code)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\radon\\metrics.py:147\u001b[0m, in \u001b[0;36mmi_visit\u001b[1;34m(code, multi)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmi_visit\u001b[39m(code, multi):\n\u001b[0;32m    146\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Visit the code and compute the Maintainability Index (MI) from it.'''\u001b[39;00m\n\u001b[1;32m--> 147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mi_compute(\u001b[38;5;241m*\u001b[39m\u001b[43mmi_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\radon\\metrics.py:134\u001b[0m, in \u001b[0;36mmi_parameters\u001b[1;34m(code, count_multi)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''Given a source code snippet, compute the necessary parameters to\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;124;03mcompute the Maintainability Index metric. These include:\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;124;03m    always docstrings.\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m    133\u001b[0m ast_node \u001b[38;5;241m=\u001b[39m ast\u001b[38;5;241m.\u001b[39mparse(code)\n\u001b[1;32m--> 134\u001b[0m raw \u001b[38;5;241m=\u001b[39m \u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m comments_lines \u001b[38;5;241m=\u001b[39m raw\u001b[38;5;241m.\u001b[39mcomments \u001b[38;5;241m+\u001b[39m (raw\u001b[38;5;241m.\u001b[39mmulti \u001b[38;5;28;01mif\u001b[39;00m count_multi \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    136\u001b[0m comments \u001b[38;5;241m=\u001b[39m comments_lines \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(raw\u001b[38;5;241m.\u001b[39msloc) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m raw\u001b[38;5;241m.\u001b[39msloc \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\radon\\raw.py:210\u001b[0m, in \u001b[0;36manalyze\u001b[1;34m(source)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m         \u001b[38;5;66;03m# Get a syntactically complete set of tokens that spans a set of\u001b[39;00m\n\u001b[0;32m    209\u001b[0m         \u001b[38;5;66;03m# lines\u001b[39;00m\n\u001b[1;32m--> 210\u001b[0m         tokens, parsed_lines \u001b[38;5;241m=\u001b[39m \u001b[43m_get_all_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlines\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    212\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mSyntaxError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSyntaxError at line: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(lineno))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\radon\\raw.py:107\u001b[0m, in \u001b[0;36m_get_all_tokens\u001b[1;34m(line, lines)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 107\u001b[0m         tokens \u001b[38;5;241m=\u001b[39m \u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m tokenize\u001b[38;5;241m.\u001b[39mTokenError:\n\u001b[0;32m    109\u001b[0m         \u001b[38;5;66;03m# A multi-line string or statement has been encountered:\u001b[39;00m\n\u001b[0;32m    110\u001b[0m         \u001b[38;5;66;03m# start adding lines and stop when tokenize stops complaining\u001b[39;00m\n\u001b[0;32m    111\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\radon\\raw.py:59\u001b[0m, in \u001b[0;36m_generate\u001b[1;34m(code)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''Pass the code into `tokenize.generate_tokens` and convert the result\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;124;03minto a list.\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# tokenize.generate_tokens is an undocumented function accepting text\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(tokenize\u001b[38;5;241m.\u001b[39mgenerate_tokens(io\u001b[38;5;241m.\u001b[39mStringIO(code)\u001b[38;5;241m.\u001b[39mreadline))\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\tokenize.py:531\u001b[0m, in \u001b[0;36m_tokenize\u001b[1;34m(readline, encoding)\u001b[0m\n\u001b[0;32m    529\u001b[0m pseudomatch \u001b[38;5;241m=\u001b[39m _compile(PseudoToken)\u001b[38;5;241m.\u001b[39mmatch(line, pos)\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pseudomatch:                                \u001b[38;5;66;03m# scan for tokens\u001b[39;00m\n\u001b[1;32m--> 531\u001b[0m     start, end \u001b[38;5;241m=\u001b[39m pseudomatch\u001b[38;5;241m.\u001b[39mspan(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    532\u001b[0m     spos, epos, pos \u001b[38;5;241m=\u001b[39m (lnum, start), (lnum, end), end\n\u001b[0;32m    533\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m start \u001b[38;5;241m==\u001b[39m end:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from radon.complexity import cc_visit\n",
    "from radon.metrics import mi_visit\n",
    "from radon.raw import analyze\n",
    "\n",
    "\n",
    "def analyze_code(source_code: str):\n",
    "    \"\"\"Extract MI, CC, and LOC from given source code string.\"\"\"\n",
    "    try:\n",
    "        # Maintainability Index\n",
    "        mi_score = mi_visit(source_code, True)\n",
    "\n",
    "        # Cyclomatic Complexity (sum across all blocks)\n",
    "        cc_blocks = cc_visit(source_code)\n",
    "        cc_score = sum(block.complexity for block in cc_blocks)\n",
    "\n",
    "        # Lines of Code\n",
    "        raw_metrics = analyze(source_code)\n",
    "        loc = raw_metrics.loc\n",
    "\n",
    "        return mi_score, cc_score, loc\n",
    "    except Exception:\n",
    "        return None, None, None\n",
    "\n",
    "\n",
    "def process_dataframe(df: pd.DataFrame):\n",
    "    \"\"\"Run radon analysis on Source Code (before/current) for each row.\"\"\"\n",
    "    results = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        mi_before, cc_before, loc_before = analyze_code(str(row[\"Source Code (before)\"]))\n",
    "        mi_after, cc_after, loc_after = analyze_code(str(row[\"Source Code (current)\"]))\n",
    "\n",
    "        results.append({\n",
    "            \"MI_Before\": mi_before,\n",
    "            \"MI_After\": mi_after,\n",
    "            \"CC_Before\": cc_before,\n",
    "            \"CC_After\": cc_after,\n",
    "            \"LOC_Before\": loc_before,\n",
    "            \"LOC_After\": loc_after,\n",
    "            \"MI_Change\": (mi_after - mi_before) if mi_before is not None and mi_after is not None else None,\n",
    "            \"CC_Change\": (cc_after - cc_before) if cc_before is not None and cc_after is not None else None,\n",
    "            \"LOC_Change\": (loc_after - loc_before) if loc_before is not None and loc_after is not None else None\n",
    "        })\n",
    "\n",
    "    # Merge with original dataframe\n",
    "    return pd.concat([df, pd.DataFrame(results)], axis=1)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# df = pd.read_csv(\"your_dataset.csv\")\n",
    "df_processed = process_dataframe(analysis_df)\n",
    "\n",
    "# Save results\n",
    "df_processed.to_csv(\"radon_results.csv\", index=False)\n",
    "print(df_processed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dec2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from radon.complexity import cc_visit\n",
    "from radon.metrics import mi_visit\n",
    "from radon.raw import analyze\n",
    "\n",
    "\n",
    "def analyze_code(source_code: str):\n",
    "    \"\"\"Extract MI, CC, and LOC from given source code string.\"\"\"\n",
    "    try:\n",
    "        # Maintainability Index\n",
    "        mi_score = mi_visit(source_code, True)\n",
    "\n",
    "        # Average Cyclomatic Complexity\n",
    "        cc_blocks = cc_visit(source_code)\n",
    "        cc_score =  sum(block.complexity for block in cc_blocks)/len(cc_blocks)\n",
    "\n",
    "        # Lines of Code\n",
    "        raw_metrics = analyze(source_code)\n",
    "        loc = raw_metrics.loc\n",
    "\n",
    "        return mi_score, cc_score, loc\n",
    "    except Exception:\n",
    "        return None, None, None\n",
    "\n",
    "\n",
    "def process_dataframe(df: pd.DataFrame):\n",
    "    \"\"\"Run radon analysis on Source Code (before/current) for each row.\"\"\"\n",
    "    results = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        mi_before, cc_before, loc_before = analyze_code(str(row[\"Source Code (before)\"]))\n",
    "        mi_after, cc_after, loc_after = analyze_code(str(row[\"Source Code (current)\"]))\n",
    "\n",
    "        results.append({\n",
    "            \"MI_Change\": (mi_after - mi_before) if mi_before is not None and mi_after is not None else None,\n",
    "            \"CC_Change\": (cc_after - cc_before) if cc_before is not None and cc_after is not None else None,\n",
    "            \"LOC_Change\": (loc_after - loc_before) if loc_before is not None and loc_after is not None else None\n",
    "        })\n",
    "\n",
    "    # Merging with original dataframe\n",
    "    return pd.concat([df, pd.DataFrame(results)], axis=1)\n",
    "\n",
    "\n",
    "df_processed = process_dataframe(final_df)\n",
    "df_processed.to_csv(\"radon_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1564a324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sacrebleu\n",
      "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
      "Collecting portalocker (from sacrebleu)\n",
      "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: regex in c:\\users\\vedant\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sacrebleu) (2024.11.6)\n",
      "Collecting tabulate>=0.8.9 (from sacrebleu)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\vedant\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sacrebleu) (1.26.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\vedant\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sacrebleu) (0.4.6)\n",
      "Collecting lxml (from sacrebleu)\n",
      "  Downloading lxml-6.0.1-cp311-cp311-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\vedant\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from portalocker->sacrebleu) (308)\n",
      "Downloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading lxml-6.0.1-cp311-cp311-win_amd64.whl (4.0 MB)\n",
      "   ---------------------------------------- 0.0/4.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.3/4.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 1.0/4.0 MB 2.4 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 1.6/4.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.8/4.0 MB 2.1 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 2.6/4.0 MB 2.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 3.1/4.0 MB 2.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 3.9/4.0 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.0/4.0 MB 2.6 MB/s  0:00:01\n",
      "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: tabulate, portalocker, lxml, sacrebleu\n",
      "\n",
      "   ---------------------------------------- 0/4 [tabulate]\n",
      "   ---------- ----------------------------- 1/4 [portalocker]\n",
      "   ---------- ----------------------------- 1/4 [portalocker]\n",
      "   -------------------- ------------------- 2/4 [lxml]\n",
      "   -------------------- ------------------- 2/4 [lxml]\n",
      "   -------------------- ------------------- 2/4 [lxml]\n",
      "   -------------------- ------------------- 2/4 [lxml]\n",
      "   -------------------- ------------------- 2/4 [lxml]\n",
      "   -------------------- ------------------- 2/4 [lxml]\n",
      "   ------------------------------ --------- 3/4 [sacrebleu]\n",
      "   ------------------------------ --------- 3/4 [sacrebleu]\n",
      "   ------------------------------ --------- 3/4 [sacrebleu]\n",
      "   ------------------------------ --------- 3/4 [sacrebleu]\n",
      "   ------------------------------ --------- 3/4 [sacrebleu]\n",
      "   ------------------------------ --------- 3/4 [sacrebleu]\n",
      "   ------------------------------ --------- 3/4 [sacrebleu]\n",
      "   ---------------------------------------- 4/4 [sacrebleu]\n",
      "\n",
      "Successfully installed lxml-6.0.1 portalocker-3.2.0 sacrebleu-2.5.1 tabulate-0.9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~andas (C:\\Users\\Vedant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~andas (C:\\Users\\Vedant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~andas (C:\\Users\\Vedant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~andas (C:\\Users\\Vedant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0393f0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sacrebleu.metrics import BLEU\n",
    "\n",
    "# Initialize BLEU scorer\n",
    "bleu = BLEU()\n",
    "\n",
    "def token_similarity_bleu(before_code, after_code):\n",
    "    sys = [after_code]\n",
    "    refs = [[before_code]]\n",
    "    \n",
    "    score = bleu.corpus_score(sys, refs)\n",
    "    return score.score / 100.0      # sacrebleu returns score out of 100, normalize to [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c778623b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = df_processed.dropna(subset=[\"Source Code (before)\", \"Source Code (current)\"])\n",
    "results_df[\"Semantic_Similarity\"] = results_df.progress_apply(\n",
    "    lambda row: semantic_similarity(str(row[\"Source Code (before)\"]), str(row[\"Source Code (current)\"])), axis=1\n",
    ")\n",
    "\n",
    "results_df[\"Token_Similarity\"] = results_df.progress_apply(\n",
    "    lambda row: token_similarity_bleu(str(row[\"Source Code (before)\"]), str(row[\"Source Code (current)\"])), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398dbc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235a57cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "model = AutoModel.from_pretrained(\"microsoft/codebert-base\",device_map=\"auto\")\n",
    "\n",
    "def semantic_similarity(code1, code2):\n",
    "    inputs = tokenizer([code1, code2], return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Mean pooling over tokens\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "\n",
    "    # Cosine similarity\n",
    "    sim = cosine_similarity([embeddings[0].numpy()], [embeddings[1].numpy()])[0][0]\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9f72d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = df_processed.dropna(subset=[\"Source Code (before)\", \"Source Code (current)\"])\n",
    "results_df[\"Semantic_Similarity\"] = results_df.progress_apply(\n",
    "    lambda row: semantic_similarity(str(row[\"Source Code (before)\"]), str(row[\"Source Code (current)\"])), axis=1\n",
    ")\n",
    "\n",
    "results_df[\"Token_Similarity\"] = results_df.progress_apply(\n",
    "    lambda row: token_similarity_bleu(str(row[\"Source Code (before)\"]), str(row[\"Source Code (current)\"])), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20263b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_semantic(sim):\n",
    "    return \"Minor\" if sim >= 0.80 else \"Major\"\n",
    "\n",
    "def classify_token(sim):\n",
    "    return \"Minor\" if sim >= 0.75 else \"Major\"\n",
    "\n",
    "results_df[\"Semantic_Class\"] = results_df[\"Semantic_Similarity\"].apply(classify_semantic)\n",
    "results_df[\"Token_Class\"] = results_df[\"Token_Similarity\"].apply(classify_token)\n",
    "results_df[\"Classes_Agree\"] = results_df.apply(\n",
    "    lambda row: \"YES\" if row[\"Semantic_Class\"] == row[\"Token_Class\"] else \"NO\", axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f44fbc02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hash</th>\n",
       "      <th>Author</th>\n",
       "      <th>Message</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Change Type</th>\n",
       "      <th>Source Code (before)</th>\n",
       "      <th>Source Code (current)</th>\n",
       "      <th>Diff</th>\n",
       "      <th>LLM_inference</th>\n",
       "      <th>Overall_diff</th>\n",
       "      <th>Rectified Message</th>\n",
       "      <th>MI_Before</th>\n",
       "      <th>MI_After</th>\n",
       "      <th>CC_Before</th>\n",
       "      <th>CC_After</th>\n",
       "      <th>LOC_Before</th>\n",
       "      <th>LOC_After</th>\n",
       "      <th>MI_Change</th>\n",
       "      <th>CC_Change</th>\n",
       "      <th>LOC_Change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4b97a810b509c93f44be4c037c7aa18fb8922884</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Pre-release 2023 December version (Mistral, Pr...</td>\n",
       "      <td>README.md</td>\n",
       "      <td>MODIFY</td>\n",
       "      <td>&lt;div class=\"align-center\"&gt;\\n  &lt;img src=\"./imag...</td>\n",
       "      <td>&lt;div class=\"align-center\"&gt;\\n  &lt;img src=\"./imag...</td>\n",
       "      <td>@@ -1,23 +1,25 @@\\n &lt;div class=\"align-center\"&gt;...</td>\n",
       "      <td>add more info about nvidia gpus</td>\n",
       "      <td>@@ -1,23 +1,25 @@\\n &lt;div class=\"align-center\"&gt;...</td>\n",
       "      <td>add more info about nvidia gpus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4b97a810b509c93f44be4c037c7aa18fb8922884</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Pre-release 2023 December version (Mistral, Pr...</td>\n",
       "      <td>Discord.png</td>\n",
       "      <td>MODIFY</td>\n",
       "      <td>PNG\\r\\n\u001a\\n</td>\n",
       "      <td>PNG\\r\\n\u001a\\n</td>\n",
       "      <td>Binary files a/images/Discord.png and b/images...</td>\n",
       "      <td>distro binary files</td>\n",
       "      <td>@@ -1,23 +1,25 @@\\n &lt;div class=\"align-center\"&gt;...</td>\n",
       "      <td>add more info about nvidia gpus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4b97a810b509c93f44be4c037c7aa18fb8922884</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Pre-release 2023 December version (Mistral, Pr...</td>\n",
       "      <td>LAION 2GPU.png</td>\n",
       "      <td>ADD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PNG\\r\\n\u001a\\n</td>\n",
       "      <td>Binary files /dev/null and b/images/LAION 2GPU...</td>\n",
       "      <td>distinguish 2gpu image from null</td>\n",
       "      <td>@@ -1,23 +1,25 @@\\n &lt;div class=\"align-center\"&gt;...</td>\n",
       "      <td>add more info about nvidia gpus</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4b97a810b509c93f44be4c037c7aa18fb8922884</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Pre-release 2023 December version (Mistral, Pr...</td>\n",
       "      <td>LAION 2GPU.svg</td>\n",
       "      <td>DELETE</td>\n",
       "      <td>&lt;?xml version=\"1.0\" encoding=\"utf-8\" standalon...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@@ -1,1518 +0,0 @@\\n-&lt;?xml version=\"1.0\" encod...</td>\n",
       "      <td>add missing missing nodes in skeleton skeleton</td>\n",
       "      <td>@@ -1,23 +1,25 @@\\n &lt;div class=\"align-center\"&gt;...</td>\n",
       "      <td>add more info about nvidia gpus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4b97a810b509c93f44be4c037c7aa18fb8922884</td>\n",
       "      <td>Daniel Han</td>\n",
       "      <td>Pre-release 2023 December version (Mistral, Pr...</td>\n",
       "      <td>SlimOrca 1GPU.svg</td>\n",
       "      <td>DELETE</td>\n",
       "      <td>&lt;?xml version=\"1.0\" encoding=\"utf-8\" standalon...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@@ -1,1424 +0,0 @@\\n-&lt;?xml version=\"1.0\" encod...</td>\n",
       "      <td>add missing missing svg elements</td>\n",
       "      <td>@@ -1,23 +1,25 @@\\n &lt;div class=\"align-center\"&gt;...</td>\n",
       "      <td>add more info about nvidia gpus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>9050d6f5278e2373e66d17fc9ac8c2ec4f986e7e</td>\n",
       "      <td>Roland Tannous</td>\n",
       "      <td>tests for mxfp4 and quantized models merge fix...</td>\n",
       "      <td>run_test.sh</td>\n",
       "      <td>ADD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#!/bin/bash\\nset -e\\n\\necho \"=================...</td>\n",
       "      <td>@@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...</td>\n",
       "      <td>add missing line</td>\n",
       "      <td>@@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...</td>\n",
       "      <td>add test for merged model</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>9050d6f5278e2373e66d17fc9ac8c2ec4f986e7e</td>\n",
       "      <td>Roland Tannous</td>\n",
       "      <td>tests for mxfp4 and quantized models merge fix...</td>\n",
       "      <td>test_merged_model.py</td>\n",
       "      <td>ADD</td>\n",
       "      <td>NaN</td>\n",
       "      <td># inference_on_merged.py\\nfrom unsloth import ...</td>\n",
       "      <td>@@ -0,0 +1,55 @@\\n+# inference_on_merged.py\\n+...</td>\n",
       "      <td>add test for merge</td>\n",
       "      <td>@@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...</td>\n",
       "      <td>add test for merged model</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>79.770172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>-20.229828</td>\n",
       "      <td>4.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>9050d6f5278e2373e66d17fc9ac8c2ec4f986e7e</td>\n",
       "      <td>Roland Tannous</td>\n",
       "      <td>tests for mxfp4 and quantized models merge fix...</td>\n",
       "      <td>train_and_merge.py</td>\n",
       "      <td>ADD</td>\n",
       "      <td>NaN</td>\n",
       "      <td># train_and_merge.py\\nfrom unsloth import Fast...</td>\n",
       "      <td>@@ -0,0 +1,71 @@\\n+# train_and_merge.py\\n+from...</td>\n",
       "      <td>add examples to train_and_merge</td>\n",
       "      <td>@@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...</td>\n",
       "      <td>add test for merged model</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>77.081798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>-22.918202</td>\n",
       "      <td>6.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>9050d6f5278e2373e66d17fc9ac8c2ec4f986e7e</td>\n",
       "      <td>Roland Tannous</td>\n",
       "      <td>tests for mxfp4 and quantized models merge fix...</td>\n",
       "      <td>test_merge_4bit_validation.py</td>\n",
       "      <td>ADD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>from unsloth import FastLanguageModel\\nfrom un...</td>\n",
       "      <td>@@ -0,0 +1,223 @@\\n+from unsloth import FastLa...</td>\n",
       "      <td>add test case for formatting prompts</td>\n",
       "      <td>@@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...</td>\n",
       "      <td>add test for merged model</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>54.395556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>-45.604444</td>\n",
       "      <td>2.0</td>\n",
       "      <td>222.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>12737e503d32fc1464f8e38536be96d92db4f7d8</td>\n",
       "      <td>stevenxdavis</td>\n",
       "      <td>Fix incorrect function call in test_qwen3_grpo...</td>\n",
       "      <td>test_qwen3_grpo.py</td>\n",
       "      <td>MODIFY</td>\n",
       "      <td>from unsloth import FastLanguageModel\\nimport ...</td>\n",
       "      <td>from unsloth import FastLanguageModel\\nimport ...</td>\n",
       "      <td>@@ -415,7 +415,8 @@ sampling_params = Sampling...</td>\n",
       "      <td>update sample_params.rb</td>\n",
       "      <td>@@ -415,7 +415,8 @@ sampling_params = Sampling...</td>\n",
       "      <td>fast_generate example</td>\n",
       "      <td>26.248657</td>\n",
       "      <td>26.303577</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>429.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>0.054920</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1235 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Hash          Author  \\\n",
       "0     4b97a810b509c93f44be4c037c7aa18fb8922884      Daniel Han   \n",
       "1     4b97a810b509c93f44be4c037c7aa18fb8922884      Daniel Han   \n",
       "2     4b97a810b509c93f44be4c037c7aa18fb8922884      Daniel Han   \n",
       "3     4b97a810b509c93f44be4c037c7aa18fb8922884      Daniel Han   \n",
       "4     4b97a810b509c93f44be4c037c7aa18fb8922884      Daniel Han   \n",
       "...                                        ...             ...   \n",
       "1230  9050d6f5278e2373e66d17fc9ac8c2ec4f986e7e  Roland Tannous   \n",
       "1231  9050d6f5278e2373e66d17fc9ac8c2ec4f986e7e  Roland Tannous   \n",
       "1232  9050d6f5278e2373e66d17fc9ac8c2ec4f986e7e  Roland Tannous   \n",
       "1233  9050d6f5278e2373e66d17fc9ac8c2ec4f986e7e  Roland Tannous   \n",
       "1234  12737e503d32fc1464f8e38536be96d92db4f7d8    stevenxdavis   \n",
       "\n",
       "                                                Message  \\\n",
       "0     Pre-release 2023 December version (Mistral, Pr...   \n",
       "1     Pre-release 2023 December version (Mistral, Pr...   \n",
       "2     Pre-release 2023 December version (Mistral, Pr...   \n",
       "3     Pre-release 2023 December version (Mistral, Pr...   \n",
       "4     Pre-release 2023 December version (Mistral, Pr...   \n",
       "...                                                 ...   \n",
       "1230  tests for mxfp4 and quantized models merge fix...   \n",
       "1231  tests for mxfp4 and quantized models merge fix...   \n",
       "1232  tests for mxfp4 and quantized models merge fix...   \n",
       "1233  tests for mxfp4 and quantized models merge fix...   \n",
       "1234  Fix incorrect function call in test_qwen3_grpo...   \n",
       "\n",
       "                           Filename Change Type  \\\n",
       "0                         README.md      MODIFY   \n",
       "1                       Discord.png      MODIFY   \n",
       "2                    LAION 2GPU.png         ADD   \n",
       "3                    LAION 2GPU.svg      DELETE   \n",
       "4                 SlimOrca 1GPU.svg      DELETE   \n",
       "...                             ...         ...   \n",
       "1230                    run_test.sh         ADD   \n",
       "1231           test_merged_model.py         ADD   \n",
       "1232             train_and_merge.py         ADD   \n",
       "1233  test_merge_4bit_validation.py         ADD   \n",
       "1234             test_qwen3_grpo.py      MODIFY   \n",
       "\n",
       "                                   Source Code (before)  \\\n",
       "0     <div class=\"align-center\">\\n  <img src=\"./imag...   \n",
       "1                                            PNG\\r\\n\u001a\\n   \n",
       "2                                                   NaN   \n",
       "3     <?xml version=\"1.0\" encoding=\"utf-8\" standalon...   \n",
       "4     <?xml version=\"1.0\" encoding=\"utf-8\" standalon...   \n",
       "...                                                 ...   \n",
       "1230                                                NaN   \n",
       "1231                                                NaN   \n",
       "1232                                                NaN   \n",
       "1233                                                NaN   \n",
       "1234  from unsloth import FastLanguageModel\\nimport ...   \n",
       "\n",
       "                                  Source Code (current)  \\\n",
       "0     <div class=\"align-center\">\\n  <img src=\"./imag...   \n",
       "1                                            PNG\\r\\n\u001a\\n   \n",
       "2                                            PNG\\r\\n\u001a\\n   \n",
       "3                                                   NaN   \n",
       "4                                                   NaN   \n",
       "...                                                 ...   \n",
       "1230  #!/bin/bash\\nset -e\\n\\necho \"=================...   \n",
       "1231  # inference_on_merged.py\\nfrom unsloth import ...   \n",
       "1232  # train_and_merge.py\\nfrom unsloth import Fast...   \n",
       "1233  from unsloth import FastLanguageModel\\nfrom un...   \n",
       "1234  from unsloth import FastLanguageModel\\nimport ...   \n",
       "\n",
       "                                                   Diff  \\\n",
       "0     @@ -1,23 +1,25 @@\\n <div class=\"align-center\">...   \n",
       "1     Binary files a/images/Discord.png and b/images...   \n",
       "2     Binary files /dev/null and b/images/LAION 2GPU...   \n",
       "3     @@ -1,1518 +0,0 @@\\n-<?xml version=\"1.0\" encod...   \n",
       "4     @@ -1,1424 +0,0 @@\\n-<?xml version=\"1.0\" encod...   \n",
       "...                                                 ...   \n",
       "1230  @@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...   \n",
       "1231  @@ -0,0 +1,55 @@\\n+# inference_on_merged.py\\n+...   \n",
       "1232  @@ -0,0 +1,71 @@\\n+# train_and_merge.py\\n+from...   \n",
       "1233  @@ -0,0 +1,223 @@\\n+from unsloth import FastLa...   \n",
       "1234  @@ -415,7 +415,8 @@ sampling_params = Sampling...   \n",
       "\n",
       "                                       LLM_inference  \\\n",
       "0                    add more info about nvidia gpus   \n",
       "1                                distro binary files   \n",
       "2                   distinguish 2gpu image from null   \n",
       "3     add missing missing nodes in skeleton skeleton   \n",
       "4                   add missing missing svg elements   \n",
       "...                                              ...   \n",
       "1230                                add missing line   \n",
       "1231                              add test for merge   \n",
       "1232                 add examples to train_and_merge   \n",
       "1233            add test case for formatting prompts   \n",
       "1234                         update sample_params.rb   \n",
       "\n",
       "                                           Overall_diff  \\\n",
       "0     @@ -1,23 +1,25 @@\\n <div class=\"align-center\">...   \n",
       "1     @@ -1,23 +1,25 @@\\n <div class=\"align-center\">...   \n",
       "2     @@ -1,23 +1,25 @@\\n <div class=\"align-center\">...   \n",
       "3     @@ -1,23 +1,25 @@\\n <div class=\"align-center\">...   \n",
       "4     @@ -1,23 +1,25 @@\\n <div class=\"align-center\">...   \n",
       "...                                                 ...   \n",
       "1230  @@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...   \n",
       "1231  @@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...   \n",
       "1232  @@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...   \n",
       "1233  @@ -0,0 +1,18 @@\\n+#!/bin/bash\\n+set -e\\n+\\n+e...   \n",
       "1234  @@ -415,7 +415,8 @@ sampling_params = Sampling...   \n",
       "\n",
       "                    Rectified Message   MI_Before    MI_After  CC_Before  \\\n",
       "0     add more info about nvidia gpus         NaN         NaN        NaN   \n",
       "1     add more info about nvidia gpus         NaN         NaN        NaN   \n",
       "2     add more info about nvidia gpus  100.000000         NaN        0.0   \n",
       "3     add more info about nvidia gpus         NaN  100.000000        NaN   \n",
       "4     add more info about nvidia gpus         NaN  100.000000        NaN   \n",
       "...                               ...         ...         ...        ...   \n",
       "1230        add test for merged model  100.000000         NaN        0.0   \n",
       "1231        add test for merged model  100.000000   79.770172        0.0   \n",
       "1232        add test for merged model  100.000000   77.081798        0.0   \n",
       "1233        add test for merged model  100.000000   54.395556        0.0   \n",
       "1234            fast_generate example   26.248657   26.303577       32.0   \n",
       "\n",
       "      CC_After  LOC_Before  LOC_After  MI_Change  CC_Change  LOC_Change  \n",
       "0          NaN         NaN        NaN        NaN        NaN         NaN  \n",
       "1          NaN         NaN        NaN        NaN        NaN         NaN  \n",
       "2          NaN         1.0        NaN        NaN        NaN         NaN  \n",
       "3          0.0         NaN        1.0        NaN        NaN         NaN  \n",
       "4          0.0         NaN        1.0        NaN        NaN         NaN  \n",
       "...        ...         ...        ...        ...        ...         ...  \n",
       "1230       NaN         1.0        NaN        NaN        NaN         NaN  \n",
       "1231       4.0         1.0       55.0 -20.229828        4.0        54.0  \n",
       "1232       6.0         1.0       71.0 -22.918202        6.0        70.0  \n",
       "1233       2.0         1.0      223.0 -45.604444        2.0       222.0  \n",
       "1234      32.0       429.0      430.0   0.054920        0.0         1.0  \n",
       "\n",
       "[1235 rows x 20 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv('radon_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acdd44d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
